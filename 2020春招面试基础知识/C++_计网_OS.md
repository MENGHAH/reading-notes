# 一、C++高频

## 内存管理

　　在C++中，内存分成5个区，他们分别是**堆、栈、自由存储区、全局/静态存储区和常量存储区**。

　　**栈**，在执行函数时，函数内局部变量的存储单元都可以在栈上创建，函数执行结束时这些存储单元自动被释放。栈内存分配运算内置于处理器的指令集中，效率很高，但是分配的内存容量有限。

　　**自由存储区**，（自由存储区也是堆上分出的一块内存，只不过在C++中称为自由存储区）就是那些由new分配的内存块，他们的释放编译器不去管，由我们的应用程序去控制，一般一个new就要对应一个delete。如果程序员没有释放掉，那么在程序结束后，操作系统会自动回收。

　　**堆**，就是那些由malloc等分配的内存块，他和堆是十分相似的，不过它是用free来结束自己的生命的。

　　**全局/静态存储区**，全局变量和静态变量被分配到同一块内存中，在以前的C语言中，全局变量又分为初始化的和未初始化的，在C++里面没有这个区分了，他们共同占用同一块内存区。

　　**常量存储区**，这是一块比较特殊的存储区，他们里面存放的是常量，不允许修改。

## 1. 指针和引用的区别

- 定义一个指针时可以先声明或者初始化为NULL； 但是引用在声明时就必须初始化;
- 指针的大小一般为4个字节，引用的大小取决于被引用对象的大小
- 指针可以有多级，但是引用不可以
- 传参的时候，使用指针的话需要解引用才能对参数进行修改，而使用引用可以直接对参数进行修改
- 指针是一个新的变量，指向另一个变量的地址，我们可以通过访问这个地址来修改另一个变量；而引用是一个别名，对引用的操作就是对变量的本身进行操作

## 2. static和const

**static**（在全局/静态存储区申请空间）

- **静态变量**：被static修饰的变量就是静态变量，它会在程序运行期间一直存在，会被放在静态存储区。局部静态变量的作用域在函数体中，全局静态变量的作用域在整个文件。

- **静态函数**：被static修饰的函数就是静态函数，静态函数只能在本文件中使用，不能被其他文件调用，也不会和其他文件中的同名函数冲突。

- **类中的静态成员**：而在类中，被static修饰的成员变量是类静态成员，这个静态成员属于类而不是属于谋改革对象。被static修饰的成员函数也属于静态成员，也是属于类而不是属于某个对象。(访问这个静态函数不需要引用对象名，而是通过引用类名来访问)

**const**

- 由const修饰的变量不可修改；
- 由const修饰的函数，在其内部不可对变量进行修改。
- 定义的const的变量是可以被其他源文件访问的，但是要用extern

**const和static在类中使用的注意事项（定义、初始化和使用)**

- 非const变量默认为extern。要使const变量能够在其他文件中访问，必须在文件中显式地指定它为extern。
- 由于声明为static的变量只被初始化一次，因为它们在单独的静态存储中分配了空间，因此类中的静态变量**由对象共享。**对于不同的对象，不能有相同静态变量的多个副本。也是因为这个原因，静态变量不能使用构造函数初始化。

**C++中的const类成员函数（用法和意义）**

- const成员函数可以访问非const对象的非const数据成员、const数据成员，也可以访问const对象内的所有数据成员；
- 非const成员函数可以访问非const对象的非const数据成员、const数据成员，但不可以访问const对象的任意数据成员；

## 3. new/delete 和malloc/free的区别

> new是如何实现的：在new一个对象的时候，首先会调用malloc为对象分配内存空间，然后调用对象的构造函数。delete会调用对象的析构函数，然后调用free回收内存。

- new/delete是关键字，而malloc/free是库函数；
- new在自由存储区分配内存。而malloc是在堆上分配内存；
- new/delete会调用构造/析构函数，但是malloc/free不会
- new在使用时不用声明申请内存的大小，但是malloc必须指定申请的内存大小
- 内存分配失败时，new抛出异常，但是malloc返回NULL；

> **delete和delete[]的区别：**
>
> - delete只会调用一次析构函数，但是delete[]会调用每个成员的析构函数
> - 用new分配的内存用delete释放，用new[]分配的内存用delete[]释放

> **为什么要求new和delete**
>
> 因为在C++中是存在对象的，当对非基本数据类型“对象”使用的时候，对象创建和销毁需要使用构造函数和析构函数，而malloc/free是库函数，是已经编译的代码，所以不能把构造函数和析构函数的功能强加给malloc/free。

## 4. 深拷贝与浅拷贝

- 浅拷贝只是对指针的拷贝，拷贝后两个指针指向同一个内存空间，
- 深拷贝不但对指针进行拷贝，而且对指针指向的内容进行拷贝，经深拷贝后的指针是指向两个不同地址的指针

## 5. 栈和堆的区别

**堆栈空间分配** 

栈（操作系统）：由操作系统自动分配释放 ，存放函数的[参数值](http://baike.baidu.com/view/1703315.htm)，[局部变量](http://baike.baidu.com/view/552847.htm)的值等。其操作方式类似于数据结构中的栈。

堆（操作系统）：一般由程序员分配释放， 若程序员不释放，程序结束时可能由OS回收。

**堆栈缓存方式** 

栈使用的是[一级缓存](http://baike.baidu.com/view/16882.htm)， 他们通常都是被调用时处于存储空间中，调用完毕立即释放。

堆则是存放在[二级缓存](http://baike.baidu.com/view/27650.htm)中，生命周期由虚拟机的垃圾回收算法来决定（并不是一旦成为孤儿对象就能被回收）。所以调用这些对象的速度要相对来得低一些。

**堆栈数据结构区别** 

栈（数据结构）：一种先进后出的数据结构。

堆（数据结构）：堆可以被看成是一棵树，如：堆排序。

## 6. struct和class的区别

在C++中，可以用struct和class定义类，都可以继承。

**区别在于：**

- struct的默认继承权限和默认访问权限是public，
- class的默认继承权限和默认访问权限是private。另外，class还可以定义模板类形参，比如template <class T, int i>。

## 7. define 和const的区别

**1.编译器处理方式**

define – 在预处理阶段进行替换 ； 
const – 在编译时确定其值；

**2.类型检查**

define – 无类型，不进行类型安全检查，可能会产生意想不到的错误 
const – 有数据类型，编译时会进行类型检查

**3.内存空间**

define – 不分配内存，给出的是立即数，有多少次使用就进行多少次替换，在内存中会有多个拷贝，消耗内存大。 const – 在静态存储区中分配空间，在程序运行过程中内存中只有一个拷贝

**4.其他**

const可以定义函数，但是define不可以。



> define和typedef的区别
>
> - define是预处理命令，在预处理是执行简单的替换，不做正确性的检查
> - typedef是在编译时处理的，它是在自己的作用域内给已经存在的类型一个别名

## 8. C++内存管理

- **栈区**：主要存储函数的参数和局部变量。栈区由系统进行内存管理，在函数完成执行时，系统会自行释放栈区的内存，而不需要用户参与管理。
- **堆区：**由用户手动申请，手动释放。如：malloc/free开辟内存的空间，从低地址向高地址增长。   
- **自由存储区：**就是由new/delete开辟内存空间。   

> - ​       通常认为C++中有两个动态内存区域。通过new/delete方式进行内存资源的分配和释放的称为自由存储区（free store），而通过malloc/free方式进行内存资源的分配和释放的称为堆区（heap）。      
> - ​       本质上来说很多编译器中的new操作符是通过malloc进行内存申请的**，因此**可以将自由存储区理解为堆区的一个具体实现，虽然二者不完全相同，但很多时候可以混为一谈。

- ​    **全局/静态存储区**：全局变量和静态变量被分配到同一块内存中，在以前的C语言中，全局变量又分为初始化的和未初始化的，在C++里面没有这个区分了，他们共同占用同一块内存区。   

  ​    注意：   

  > ​     在C语言中，初始化的全局变量和静态变量放在一块内存区域中，而未初始化的全局变量和静态变量放在与之相邻的另一块内存区域中。而在C++中则没有在静态区中将初始化的和未初始化的变量进行分开存储，因为C++会对未初始化的全局变量和静态变量进行默认初始化（一般默认初始化为0）。该区域存储的数据会在程序结束后由系统来释放。    

- ​    **常量存储区：**这是一块比较特殊的存储区，他们里面存放的是常量，不允许修改。

## 9. 重载和重写、隐藏(重定义)的区别

**基本概念**

- 重载(函数名相同，但是参数列表不同)：是指同一可访问区内被声明的几个具有不同参数列（参数的类型，个数，顺序不同）的同名函数，根据参数列表确定调用哪个函数，重载不关心函数返回类型。
- 隐藏(重定义)：是指派生类的函数屏蔽了与其同名的基类函数，注意只要同名函数，不管参数列表是否相同，基类函数都会被隐藏。
- 重写(覆盖，函数相同，参数列表也相同，方法体不相同)：是指派生类中存在重新定义的函数。其函数名，参数列表，返回值类型，所有都必须同基类中被重写的函数一致。只有函数体不同（花括号内），派生类调用时会调用派生类的重写函数，不会调用被重写函数。重写的基类中被重写的函数必须有virtual修饰。

**重载和重写的区别：**

（1）范围区别：重写和被重写的函数在不同的类中，重载和被重载的函数在同一类中。
（2）参数区别：重写的函数参数列表是相同的，重载和被重载的函数参数列表一定不同。
（3）virtual的区别：重写的基类必须要有virtual修饰，重载函数和被重载函数可以被virtual修饰，也可以没有。

**隐藏和重写，重载的区别：**

（1）与重载范围不同：隐藏函数和被隐藏函数在不同类中。

（2）参数的区别：隐藏函数和被隐藏函数参数列表可以相同，也可以不同，但函数名一定同；当参数不同时，无论基类中的函数是否被virtual修饰，基类函数都是被隐藏，而不是被重写。 

## 10. 封装、继承、多态

面向对象的三个基本特征是：封装、继承、多态。封装可以隐藏实现细节，使得代码模块化；继承可以扩展已存在的代码模块（类）；它们的目的都是为了——代码重用。而多态则是为了实现另一个目的——接口重用。

**什么是封装？**

封装是把过程和数据包围起来，对数据的访问只能通过已定义的接口。面向对象计算始于这个基本概念，即现实世界可以被描绘成一系列完全自治、封装的对象，这些对象通过一个受保护的接口访问其他对象。在面向对象编程上可理解为：把客观事物封装成抽象的类，并且类可以把自己的数据和方法只让可信的类或者对象操作，对不可信的进行信息隐藏。

**什么是继承？**

- 继承是指这样一种能力：它可以使用现有类的所有功能，并在无需重新编写原来的类的情况下对这些功能进行扩展。其继承的过程，就是从一般到特殊的过程。
- 通过继承创建的新类称为“子类”或“派生类”。被继承的类称为“基类”、“父类”或“超类”。要实现继承，可以通过“继承”（Inheritance）和“组合”（Composition）来实现。

**继承类型**

当一个类派生自基类，该基类可以被继承为 **public、protected** 或 **private** 几种类型

- **公有继承（public）：**当一个类派生自**公有**基类时，基类的**公有**成员也是派生类的**公有**成员，基类的**保护**成员也是派生类的**保护**成员，基类的**私有**成员不能直接被派生类访问，但是可以通过调用基类的**公有**和**保护**成员来访问。
- **保护继承（protected）：** 当一个类派生自**保护**基类时，基类的**公有**和**保护**成员将成为派生类的**保护**成员。
- **私有继承（private）：**当一个类派生自**私有**基类时，基类的**公有**和**保护**成员将成为派生类的**私有**成员。

**继承的实现方式？**

继承概念的实现方式有三类：实现继承、接口继承和可视继承。

- 实现继承是指使用基类的属性和方法而无需额外编码的能力；
- 接口继承是指仅使用属性和方法的名称、但是子类必须提供实现的能力；
- 可视继承是指子窗体（类）使用基窗体（类）的外观和实现代码的能力。

## 11. 多态

**什么是多态？**

同一操作作用于不同的对象，可以有不同的解释，产生不同的执行结果。多态一般跟随继承的概念，利用基类初始化一个指针指向子类，当调用不同子类的相同函数时可以得到不同的结果。

多态又分为**静态多态和动态多态**，静态多态是利用重载实现，动态多态是利用虚函数机制（**虚函数机制是利用虚函数表来实现**）实现。



> C++ 多态包括编译时多态和运行时多态，
>
> - 编译时多态体现在函数重载和模板上；
> - 运行时多态体现在虚函数上。



## 12. 虚函数相关

**什么是虚函数**

基于基类的指针操作他的多态类对象时，会根据不同的对象调用相应对象的函数，这个函数就是虚函数。

**虚函数实现机制（虚函数表和虚指针）**

- 虚函数的实现是利用**虚函数表和虚函数指针**来实现

- 虚函数都会有一个对应的虚函数表，该虚函数表存放的是每一个对象的虚函数入口地址。对于一个派生类来说，他会继承基类的虚函数表同时增加自己的虚函数入口地址，如果派生类重写了基类的虚函数，那么被继承的虚函数入口地址将被派生类的虚函数入口地址替代。

**什么是虚函数表**

- 虚函数表是每个类中存放虚函数地址的指针数组，类的实例在调用函数时会在虚函数表中寻找函数地址进行调用，如果子类覆盖了父类的函数，则子类的虚指针会指向子类实现的函数地址，否则指向父类的函数地址。
- 一个类的所有实例对象都**共享同一张虚函数表**。**但是每一个对象都有一个自己的虚指针**  

**纯虚函数**

- 形如：
  virtual 返回类型 函数名 (形参表) = 0;

```
class Animal {
public:
	virtual void eat (void) = 0;
	virtual void run (void) = 0;
	virtual void cry (void) = 0;
};
```

的虚函数，称为纯虚函数或抽象方法，表达一种抽象化的行为概念

- 如果一类含有至少一个纯虚函数，那么该类就是一个抽象类，他不能被实例化，只有实现了这个纯虚函数的子类才能生成对象
- 除了构造函数和析构函数以外全部成员函数都是纯虚函数的抽象类叫做纯抽象类，亦称接口类 

## 13. C++所有的构造函数

**默认构造函数、一般构造函数和拷贝构造函数**

- 默认构造函数（无参数）：如果创建一个类你没有写任何构造函数,则系统会自动生成默认的构造函数，或者写了一个不带任何形参的构造函数
- 一般构造函数：一般构造函数可以有各种参数形式,一个类可以有多个一般构造函数，前提是参数的个数或者类型不同（基于c++的重载函数原理）
- 拷贝构造函数参数为类对象本身的引用，用于根据一个已存在的对象复制出一个新的该类的对象，一般在函数中会将已存在对象的数据成员的值**复制**一份到新创建的对象中。参数（对象的引用）是不可变的（const类型）。**此函数经常用在函数调用时用户定义类型的值传递及返回**。

> **什么情况下会调用拷贝构造函数**
>
> - 对象以值传递的方式传入函数参数。如 `void func(Dog dog){};`
> - 对象以值传递的方式从函数返回。如 `Dog func(){ Dog d; return d;}`
> - 对象需要通过另一个对象进行初始化



## 14. 析构函数一般写成虚函数的原因

> 只有一个类是基类要构成多态时才令其析构函数为虚函数，这样可以节省内存空间。否则就是浪费。

如果一个基类的析构函数不是虚构函数，在继承类对象经由一个基类指针被删除是可能无法释放其占用的空间，进而可能造成内存泄漏，破坏数据结构。



## 15. 构造函数为什么一般不定义为虚函数

- 因为创建一个对象时需要确定对象的类型，而虚函数是在运行时确定其类型的。而在构造一个对象时，由于对象还未创建成功，编译器无法知道对象的实际类型，是类本身还是类的派生类等等
- 虚函数的调用需要虚函数表指针，而该指针存放在对象的内存空间中；若构造函数声明为虚函数，那么由于对象还未创建，还没有内存空间，更没有虚函数表地址用来调用虚函数即构造函数了



## 16. [静态绑定和动态绑定](https://www.cnblogs.com/conanpeng/p/12799419.html)

- 静态绑定在编译期完成，指针指的是静态对象。
- 动态绑定在运行期完成，虚函数中的指针指向对象。（基类指针指向派生类对象）

在C++中动态绑定是通过虚函数实现的。基类指针调用虚函数时发生动态绑定。基类指针既可以指向基类对象，又可以指向派生类对象，这是动态绑定的关键。指针调用的虚函数在运行时确定，被调用的虚函数是由指针所指对象的实际类型（基类或派生类）定义的。

## 17. 引用是否能实现动态绑定，为什么引用可以实现 

 **可以**。因为引用（或指针）既可以指向基类对象也可以指向派生类对象，这一事实是动态绑定的关键。用引用（或指针）调用的虚函数在运行时确定，被调用的函数是引用（或指针）所指的对象的实际类型所定义的。 

## 18. 什么情况下会调用拷贝函数

- 用类的一个对象去初始化另一个对象时
- 当函数的形参是类的对象时（也就是值传递时），如果是引用传递则不会调用
- 当函数的返回值是类的对象（返回值为引用不会调用拷贝构造函数）

## 19. 内存泄漏，如何检测和避免

**1. 什么是内存泄漏？**

内存泄漏(memory leak)是指由于疏忽或错误造成了**程序未能释放掉不再使用的内存的情况**。内存泄漏并非指内存在物理上的消失，而是[应用程序](http://baike.baidu.com/view/330120.htm)分配某段内存后，由于设计错误，失去了对该段内存的控制，因而造成了内存的浪费。

**2. 内存泄漏的后果？** 

最难捉摸也最难检测到的错误之一是内存泄漏，即未能正确释放以前分配的内存的 bug。 只发生一次的小的内存泄漏可能不会被注意，但泄漏大量内存的程序或泄漏日益增多的程序可能会表现出各种征兆：从性能不良（并且逐渐降低）到内存完全用尽。 更糟的是，泄漏的程序可能会用掉太多内存，以致另一个程序失败，而使用户无从查找问题的真正根源。 此外，即使无害的内存泄漏也可能是其他问题的征兆。

**3. 内存泄漏的分类：**

1. 堆内存泄漏 （Heap leak）。对内存指的是程序运行中根据需要分配通过malloc,realloc new等从堆中分配的一块内存，再是完成后必须通过调用对应的 free或者delete 删掉。如果程序的设计的错误导致这部分内存没有被释放，那么此后这块内存将不会被使用，就会产生Heap Leak.
2. 系统资源泄露（Resource Leak）。主要指程序使用系统分配的资源比如 Bitmap,handle ,SOCKET等没有使用相应的函数释放掉，导致系统资源的浪费，严重可导致系统效能降低，系统运行不稳定。
3. 没有将基类的析构函数定义为虚函数。当基类指针指向子类对象时，如果基类的析构函数不是virtual，那么子类的析构函数将不会被调用，子类的资源没有正确是释放，因此造成内存泄露。

**4. 解决内存泄漏最有效的办法就是使用智能指针（Smart Pointer）。**

**5. 如何检测内存泄漏**

- 在Linux系统下可以采用检测工具valgrind。
- 可以在写代码的时候采用内存申请和释放的统计功能，统计当前申请和释放的内存是否一致，以此来判断内存是否泄露。

**6. 什么时候发生段错误**（**段错误通常发生在访问非法内存地址的时候**）

- 使用野指针
- 非法修改const修饰的常量的时候

## 20. 模板的用法与适用场景 

 代码可重用，泛型编程，在不知道参数类型下，函数模板和类模板 

## 21. 成员初始化列表的概念，为什么快

> **初始化列表为什么快？**
>
> 因为<font color=blue>使用成员初始化列表进行初始化的话，**会直接使用传入参数的拷贝构造函数进行初始化，省去了一次调用默认构造函数的过程。所以使用成员初始化列表效率会高一些**。</font>

**何谓初始化列表**

与其他函数不同，构造函数除了有名字，参数列表和函数体之外，还可以有初始化列表，初始化列表以冒号开头，后跟一系列以逗号分隔的初始化字段。在C++中，struct和class的唯一区别是默认的访问性不同，而这里我们不考虑访问性的问题，所以下面的代码都以struct来演示。

```
struct foo{
    string name ;
    int id ;
    foo(string s, int i):name(s), id(i){} ; // 初始化列表
};
```

**构造函数的两个执行阶段**

构造函数的执行可以分成两个阶段，初始化阶段和计算阶段，初始化阶段先于计算阶段。

**初始化阶段**

所有类类型（class type）的成员都会在初始化阶段初始化，即使该成员没有出现在构造函数的初始化列表中。

**计算阶段**

一般用于执行构造函数体内的赋值操作，下面的代码定义两个结构体，其中Test1有构造函数，拷贝构造函数及赋值运算符，为的是方便查看结果。Test2是个测试类，它以Test1的对象为成员，我们看一下Test2的构造函数是怎么样执行的。

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

```c++
struct Test1
{
    Test1() // 无参构造函数
    { 
        cout << "Construct Test1" << endl ;
    }

    Test1(const Test1& t1) // 拷贝构造函数
    {
        cout << "Copy constructor for Test1" << endl ;
        this->a = t1.a ;
    }

    Test1& operator = (const Test1& t1) // 赋值运算符
    {
        cout << "assignment for Test1" << endl ;
        this->a = t1.a ;
        return *this;
    }

    int a ;
};

struct Test2
{
    Test1 test1 ;
    Test2(Test1 &t1)
    {
        test1 = t1 ;
    }
};
```

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

调用代码

```c++
Test1 t1 ;
Test2 t2(t1) ;
```

输出

![img](https://pic002.cnblogs.com/images/2012/64257/2012091523283349.png)

解释一下，第一行输出对应调用代码中第一行，构造一个Test1对象。第二行输出对应Test2构造函数中的代码，用默认的构造函数初始化对象test1，这就是所谓的初始化阶段。第三行输出对应Test1的赋值运算符，对test1执行赋值操作，这就是所谓的计算阶段。

**为什么使用初始化列表**

初始化类的成员有两种方式，一是使用初始化列表，二是在构造函数体内进行赋值操作。使用初始化列表主要是基于性能问题，对于内置类型，如int, float等，使用初始化类表和在构造函数体内初始化差别不是很大，但是对于类类型来说，最好使用初始化列表，为什么呢？<font color=blue>**由上面的测试可知，使用初始化列表少了一次调用默认构造函数的过程，这对于数据密集型的类来说，是非常高效的**</font>。同样看上面的例子，我们使用初始化列表来实现Test2的构造函数

```c++
struct Test2{
    Test1 test1 ;
    Test2(Test1 &t1):test1(t1){}
}
```

使用同样的调用代码，输出结果如下。

![img](https://pic002.cnblogs.com/images/2012/64257/2012091523291178.png)

第一行输出对应 调用代码的第一行。第二行输出对应Test2的初始化列表，直接调用拷贝构造函数初始化test1，省去了调用默认构造函数的过程。所以一个好的原则是，能使用初始化列表的时候尽量使用初始化列表。

<font color=red>**哪些东西必须放在初始化列表中**</font>

除了性能问题之外，有些时场合初始化列表是不可或缺的，以下几种情况时必须使用初始化列表

- **常量成员**，因为常量只能初始化不能赋值，所以必须放在初始化列表里面
- **引用类型**，引用必须在定义的时候初始化，并且不能重新赋值，所以也要写在初始化列表里面
- **没有默认构造函数的类类型**，因为使用初始化列表可以不必调用默认构造函数来初始化，而是直接调用拷贝构造函数初始化。

对于没有默认构造函数的类，我们看一个例子。

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

```c++
struct Test1
{
    Test1(int a):i(a){}
    int i ;
};

struct Test2
{
    Test1 test1 ;
    Test2(Test1 &t1)
    {
        test1 = t1 ;
    }
};
```

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

以上代码无法通过编译，因为Test2类中Test1 test1;需要调用默认的构造函数，但是Test1类没有无参的构造函数，但是由于Test1没有默认的构造函数，故而编译错误。正确的代码如下，使用初始化列表代替赋值操作。

```c++
struct Test2
{
    Test1 test1 ;
    Test2(Test1 &t1):test1(t1){}
}
```

**成员变量的初始化顺序**

成员是按照他们在类中出现的顺序进行初始化的，而不是按照他们在初始化列表出现的顺序初始化的，看代码。

```c++
struct foo
{
    int i ;
    int j ;
    foo(int x):i(x), j(i){}; // ok, 先初始化i，后初始化j
};
```

再看下面的代码

```c++
struct foo
{
    int i ;
    int j ;
    foo(int x):j(x), i(j){} // i值未定义
};

```

这里i的值是未定义的，虽然j在初始化列表里面出现在i前面，但是i先于j定义，所以先初始化i，但i由j初始化，此时j尚未初始化，所以导致i的值未定义。所以，一个好的习惯是，按照成员定义的顺序进行初始化。

## 22. vector和list的区别

- 底层结构

  **vector**的底层结构是动态顺序表，在内存中是一段连续的空间。
  **list**的底层结构是带头节点的双向循环[链表](https://blog.csdn.net/Shuffle_Ts/article/details/95055467)，在内存中不是一段连续的空间。

- 随机访问

  **vector**支持随机访问，可以利用下标精准定位到一个元素上，访问某个元素的时间复杂度是O(1)。
  **list**不支持随机访问，要想访问list中的某个元素只能是从前向后或从后向前依次遍历，时间复杂度是O(N)。

- 插入和删除

  **vector**任意位置插入和删除的效率低，因为它每插入一个元素（尾插除外），都需要搬移数据，时间复杂度是O(N)，而且插入还有可能要增容，这样一来还要开辟新空间，拷贝元素，是旧空间，效率会更低。
  **list**任意位置插入和删除的效率高，他不需要搬移元素，只需要改变插入或删除位置的前后两个节点的指向即可，时间复杂度为O(1)。

- 空间利用率

  **vector**底层为连续空间，不容易造成内存碎片，空间利用率高，缓存利用率高。
  **list**的底层节点动态开辟空间，小节点容易造成内存碎片，空间利用率低，缓存利用率低。

- 迭代器

  **vector**的迭代器是原生态指针。
  **list**对原生态指针（节点的指针）进行了封装。

- 迭代器失效

  **vector**在插入元素时的时候，要重新给所有的迭代器赋值，因为插入元素有可能导致扩容，只是原来的迭代器失效，删除元素时当前迭代器同样需要重新赋值，否则会失效。
  **list**在插入元素的时候不会导致迭代器实现，删除元素的时候指挥导致当前迭代器失效，其他的迭代器不会受到影响。

- 使用场景

  **vector**适合需要高效率存储，需要随机访问，并且不管行插入和删除效率的场景。
  **list**适合有大量的插入和删除操作，并且不关心随机访问的场景

## 23. C++的STL介绍

- STL中map和unordered_map的应用场景区别

  -  unordered_map是使用哈希实现的，占用内存比较多，查询速度比较快，是常数时间复杂度。它内部是无序的，需要实现==操作符。

  - map底层是采用红黑树实现的，插入删除查询时间复杂度都是O(log(n))，它的内部是有序的，因此需要实现比较操作符(<)。

- STL包括容器、迭代器、算法（查找、排序）、函数对象、适配器、空间配置器

- 各种容器：

  - vector：可变大小数组，支持快速随机访问，在尾部之外的位置插入或者删除元素可能很慢

    > 对vector的任何操作一旦引起了空间的重新配置，指向原vector的所有迭代器就会都失效。

    size() : 当前有多少元素; 

    capacity() : 可容纳多少元素；

    vector元素不能是引用，因为vector元素需要有实际地址

  - deque：双端队列，支持快速随机访问，在头尾插入删除速度很快

    底层是双向开口的连续线性空间

  - list：双向链表，只支持双向顺序访问，在任何位置插入删除速度很快

    底层是双向链表，push_back(), pop_back(), push_front(), pop_front()

  - array：固定大小数组，不能添加删除元素

  - string：专门存储字符，与vector类似

  - priority_queue：优先队列，*底层用堆实现的*

    ```c++
    priority_queue<int, vector<int>, greater<int>> pq; //最小堆
    priority_queue<int, vector<int>, less<int>> pq; //最大堆
    pq.top();//优先级最高（堆顶）
    pq.pop();//删除最高
    ```
  
- map，set，multiset，multimap
  
  底层都是红黑树
  
  - map中mp.count(key) > 0和mp.find(key) != mp.end()都可以表示key存在
    - set,multiset会自动排序，set不允许元素重复，multiset可以重复
    - map, multimap将key, value组成的pair作为元素，根据key排序
  
- unordered_map, unordered_set
  
  - 底层是防冗余的哈希表（除留余数法）
    - 常数级别查找，但是耗内存

## 24. STL源码中的hash表的实现

- [参考链接1](https://light-city.club/sc/src_analysis/stl/hashtable/)
- [参考链接2](https://blog.csdn.net/ddkxddkx/article/details/6555754)

## 25. STL中unordered_map和map的区别

**内部实现机理不同**

- **map：** 内部实现了一个**红黑树**（红黑树是非严格平衡二叉搜索树，而AVL是严格平衡二叉搜索树），红黑树具有自动排序的功能，因此map内部的所有元素都是有序的，红黑树的每一个节点都代表着map的一个元素。因此，对于map进行的查找，删除，添加等一系列的操作都相当于是对红黑树进行的操作。map中的元素是按照二叉搜索树（又名二叉查找树、二叉排序树，特点就是左子树上所有节点的键值都小于根节点的键值，右子树所有节点的键值都大于根节点的键值）存储的，使用中序遍历可将键值按照从小到大遍历出来。
- **unordered_map**: 内部实现了一个**哈希表**（也叫散列表，通过把关键码值映射到Hash表中一个位置来访问记录，查找的时间复杂度可达到O(1)，其在海量数据处理中有着广泛应用），unordered_map占用内存比较多，查询速度比较快，是常数时间复杂度 。另外，其元素的排列顺序是无序的。

**优缺点以及适用条件**

**map：**

```
优点：
    有序性，这是map结构最大的优点，其元素的有序性在很多应用中都会简化很多的操作
    红黑树，内部实现一个红黑书使得map的很多操作在log(n)的时间复杂度下就可以实现，因此效率非常的高

缺点： 空间占用率高，因为map内部实现了红黑树，虽然提高了运行效率，但是因为每一个节点都需要额外保存父节点、孩子节点和红/黑性质，使得每一个节点都占用大量的空间

适用处：对于那些有顺序要求的问题，用map会更高效一些
```

**unordered_map：**

```
优点： 因为内部实现了哈希表，因此其查找速度非常的快
缺点： 哈希表的建立比较耗费时间
适用处：对于查找问题，unordered_map会更加高效一些，因此遇到查找问题，常会考虑一下用unordered_map
```

**总结：**

```
内存占有率的问题就转化成红黑树 VS hash表 , 还是unorder_map占用的内存要高。
但是unordered_map执行效率要比map高很多
对于unordered_map或unordered_set容器，其遍历顺序与创建该容器时输入的顺序不一定相同，因为遍历是按照哈希表从前往后依次遍历的
```

## 26. STL中vector的实现

STL中的vector是封装了动态数组的顺序容器。不过与动态数组不同的是，vector可以根据需要自动扩大容器的大小。具体策略是每次容量不够用时重新申请一块大小为原来容量两倍的内存，将原容器的元素拷贝至新容器，并释放原空间，返回新空间的指针。  

在原来空间不够存储新值时，**每次调用push_back方法都会重新分配新的空间以满足新数据的添加操作。如果在程序中频繁进行这种操作，还是比较消耗性能的。**

## 27. vector使用的注意点及其原因

如果需要频繁插入，最好先指定vector的大小，因为vector在容器大小不够用的时候会重新申请一块大小为原容器两倍的空间，并将原容器的元素拷贝到新容器中，并释放原空间，这个过程是十分耗时和耗内存的。**频繁调用push_back()会使得程序花费很多时间在vector扩容上，会变得很慢。这种情况可以考虑使用list。**  

## **28. 什么是Reactor模式**

> 1.[Reactor模式简介](https://lotabout.me/2018/reactor-pattern/)

reactor模型要求主线程只负责监听文件描述上是否有事件发生，有的话就立即将该事件通知工作线程，除此之外，主线程不做任何其他实质性的工作，读写数据、接受新的连接以及处理客户请求均在工作线程中完成

## 29. 右值引用

> 1.[从4行代码看右值引用](https://www.cnblogs.com/qicosmos/p/4283455.html)

**1. 什么是右值引用**

C++中所有的值都必然属于左值或者右值。**左值**是指表达式结束后依旧存在的持久化对象，**右值**是指表达式结束时就不再存在的临时对象。所有具名变量或者对象都是左值，而右值不具名。有一个可以**区分左值和右值**的便捷方法：看能不能对表达式取地址，如果能，则为左值，否则为右值。 

```C++
A && a = getTemp(); //getTemp()的返回值是右值（临时变量）
```

常见右值：**字面常量，匿名对象，以及函数的返回值**。 另外，也可以通过 std::move 显式地将一个左值转换为右值。

> ```c++
> int a; //变量
> const int b = 10; //b为常量，10为字面量
> string str = “hello world！”; // str 为变量，hello world！为字面量
> int a=123 // 这里的a为左值，123为右值 123在使用之后就不再存在了，但是a是一直存在的
> ```



getTemp() 返回的右值本来在表达式语句结束后，其生命也就该终结了（因为是临时变量），而通过右值引用，该右值又重获新生，其生命期将与右值引用类型变量 a 的生命期一样，只要 a 还活着，该右值临时变量将会一直存活下去。实际上就是给那个临时变量取了个名字。

注意：这里 a 的类型是右值引用类型( int && )，但是如果从左值和右值的角度区分它，它实际上是个左值。因为可以对它取地址，而且它还有名字，是一个已经命名的右值。 



**2. 右值引用的作用**

右值引用是C++11中新增加的一个很重要的特性，<font color=blue>他主是要用来解决C++98/03中遇到的两个问题</font>：

- **第一个问题就是临时对象非必要的昂贵的拷贝操作；**
- **第二个问题是在模板函数中如何按照参数的实际类型进行转发。**

C++11中，右值引用就是对一个右值进行引用的类型。由于右值通常不具有名字，所以我们一般只能通过右值表达式获得其引用，比如：

```C++
T && a=ReturnRvale(); // ReturnRvale()函数返回的是一个右值（也就是一个临时变量）
```

ReturnRvalue()函数返回一个右值，那么上述语句声明了一个名为a的右值引用，其值等于ReturnRvalue函数返回的临时变量的值。



**3. 右值引用的特点**

- 右值引用的第一个特点：通过右值引用的声明，右值又“重获新生",其生命周期与右值引用类型变量的生
  命周期一样长，只要该变量还活着，该右值临时量将会一直存活下去。
- 右值引用的第二个特点：右值引用独立于左值和右值。也就是说右值引用类型的变量可能是左值也可能
  是右值。 
- 右值引用的第三个特点： T&& t在发生自动类型推断的时候，它是未定的引用类型（universal references），如果被一个左值初始化，它就是一个左值；如果它被一个右值初始化，它就是一个右值，它是左值还是右值取决于它的初始化。 [只有发生自动类型推断的时候才是，函数模板的类型自动推导，或auto关键字。

## 30. 堆和自由存储区的区别

堆是C的概念，自由存储区是C++的概念，两者在概念上有根本的不同，但C++沿袭了C，实际使用的是一块空间

## 31 传指针和传引用的适用场景
- 需要返回函数内局部变量的内存的时候用指针。
- 对栈空间大小比较敏感（比如递归）的时候使用引用。使用引用传递不需要创建临时变量，开销要更小 
- 类对象作为参数传递的时候使用引用，这是C++类对象传递的标准方式

## 32. 堆和栈的区别

1）申请方式：

栈由系统自动分配和管理，堆由程序员手动分配和管理。

2）效率：

栈由系统分配，速度快，不会有内存碎片。

堆由程序员分配，速度较慢，可能由于操作不当产生内存碎片。

3）扩展方向

栈从高地址向低地址进行扩展，堆由低地址向高地址进行扩展。

4）程序局部变量是使用的栈空间，new/malloc动态申请的内存是堆空间，函数调用时会进行形参和返回值的压栈出栈，也是用的栈空间。

## 33. 堆快还是栈快

**栈快一点**。因为操作系统会在底层对栈提供支持，会分配专门的寄存器存放栈的地址，栈的入栈出栈操作也十分简单，并且有专门的指令执行，所以栈的效率比较高也比较快。

而堆的操作是由C/C++函数库提供的，在分配堆内存的时候需要一定的算法寻找合适大小的内存。并且获取堆的内容需要两次访问，第一次访问指针，第二次根据指针保存的地址访问内存，因此堆比较慢。

## 34. sizeof的使用

- 一个类中定义一个虚函数`virtual fun()`，那么这个类的大小是4(因为虚函数的实现是利用虚函数表和虚指针，类的大小就是指针的大小)
- 空类的大小为1
- static定义的变量不占用类的大小，普通函数也不占用类的大小

## 35. 红黑树如何保持平衡

> 1. [红黑树（2）保持平衡的根本套路](https://blog.csdn.net/mottohlm/article/details/81604069)

左旋、右旋和变颜色。

## 36. 结构体内存对齐的方式和为什么要进行内存对齐

**为什么要进行内存对齐**
因为结构体的成员可以有不同的数据类型，所占的大小也不一样。同时，由于CPU读取数据是按块读取的，内存对齐可以使得CPU一次就可以将所需的数据读进来。

**对齐的方式**

- 第一个成员在与结构体变量偏移量为0的地址

- 其他成员变量要对齐到某个数字（对齐数）的整数倍的地址处。 

- 对齐数=编译器默认的一个对齐数 与 该成员大小的较小值。 

- linux 中默认为4 

- vs 中的默认值为8
  结构体总大小为最大对齐数的整数倍（每个成员变量除了第一个成员都有一个对齐数）

## 37. inline关键字以及他和宏的区别

inline是内联的意思，可以定义比较小的函数。因为函数频繁调用会占用很多的栈空间，进行入栈出栈操作也耗费计算资源，所以可以用inline关键字修饰频繁调用的小函数。编译器会在编译阶段将代码体嵌入内联函数的调用语句块中 。

## 38. 成员初始化列表以及优势

成员初始化列表就是在类或者结构体的构造函数中，在参数列表后以冒号开头，逗号进行分隔的一系列初始化字段。

```C++
class A{
int id;
string name;
FaceImage face;
A(int& inputID,string& inputName,FaceImage& inputFace):id(inputID),name(inputName),face(inputFace){} // 成员初始化列表
};
```

因为<font color=blue>使用成员初始化列表进行初始化的话，**会直接使用传入参数的拷贝构造函数进行初始化，省去了一次调用默认构造函数的过程。所以使用成员初始化列表效率会高一些**。</font>

另外，有三种情况是必须使用成员初始化列表进行初始化的：

- 常量成员 (const) 的初始化，因为常量成员只能初始化不能赋值
- 引用类型
- 没有默认构造函数的对象必须使用成员初始化列表的方式进行初始化

## 39. C++的4种强制类型转换

四种强制类型转换操作符分别为：static_cast、dynamic_cast、const_cast、reinterpret_cast

## 40. 一个函数或者可执行文件的生成过程或者编译过程是怎样的

预处理，编译，汇编，链接

- 预处理： 对预处理命令进行替换等预处理操作
- 编译：代码优化和生成汇编代码
- 汇编：将汇编代码转化为机器语言
- 链接：将目标文件彼此链接起来

## 41. 声明和定义的区别

- 声明是告诉编译器变量的类型和名字，不会为变量分配空间

  int a; 声明一个变量a

- 定义就是对这个变量和函数进行内存分配和初始化。需要分配空间，同一个变量可以被声明多次，但是只能被定义一次

  int a=3; // 定义一个变量a

## 42. typde和define的区别

-  #define是预处理命令，在预处理是执行简单的替换，不做正确性的检查

- typedef是在编译时处理的，它是在自己的作用域内给已经存在的类型一个别名

## 43. 被free回收的内存是立即返还给操作系统吗？为什么
不是的，被free回收的内存会首先被 ptmalloc 使用双链表保存起来，当用户下一次申请内存的时候，会尝试从这些内存中寻找合适的返回。这样就避免了频繁的系统调用，占用过多的系统资源。同时ptmalloc也会尝试对小块内存进行合并，避免过多的内存碎片。

## 44. 引用作为函数参数以及返回值的好处

1）在函数内部可以对此参数进行修改
2）提高函数调用和运行的效率（因为没有了传值和拷贝的时间、空间消耗）

<font color=blue>**用引用作为返回值最大的好处就是在内存中不产生被返回值的拷贝**。</font>
但是有以下的限制：
1）不能返回局部变量的引用。因为函数返回以后局部变量就会被销毁；
2）不能返回函数内部new分配的内存的引用。虽然不存在局部变量的被动销毁问题，可对于这种情况（返回函数内部new分配内存的引用），又面临其它尴尬局面。例如，被函数返回的引用只是作为一 个临时变量出现，而没有被赋予一个实际的变量，那么这个引用所指向的空间（由new分配）就无法释放，造成内存泄漏；
3）可以返回类成员的引用，但是最好是const。因为如果其他对象可以获得该属性的非常量的引用，那么对该属性的单纯赋值就会破坏业务规则的完整性。



## 45. 友元函数和友元类

类的友元函数是定义在类外部，但有权访问类的所有私有（private）成员和保护（protected）成员。尽管友元函数的原型有在类的定义中出现过，但是友元函数并不是成员函数。友元可以是一个函数，该函数被称为友元函数；友元也可以是一个类，该类被称为友元类，在这种情况下，整个类及其所有成员都是友元。

```C++
#include <iostream>
using namespace std;
 
class Box{
   double width;
public:
   friend void printWidth( Box box );
   void setWidth( double wid );
};

// 成员函数定义
void Box::setWidth( double wid ){
    width = wid;
}
 
// 请注意：printWidth() 不是任何类的成员函数
void printWidth( Box box ){
   /* 因为 printWidth() 是 Box 的友元，它可以直接访问该类的任何成员 */
   cout << "Width of box : " << box.width <<endl;
}
 
// 程序的主函数
int main( ){
   Box box;
   box.setWidth(10.0); // 使用成员函数设置宽度
   printWidth( box ); // 使用友元函数输出宽度
   return 0;
}
```



## 46.  STL中的sort()算法是用什么实现的，stable_sort()呢

- sort算法是用快排和插入排序结合的方法实现的

- stable_sort()是归并排序。

## 47. vector的迭代器会失效吗

**会失效**

- 当vector在插入的时候，如果原来的空间不够，会将申请新的内存并将原来的元素移动到新的内存，此时指向原内存地址的迭代器就失效了，begin和end迭代器都失效。
- 当vector在插入的时候，end迭代器肯定会失效 
- 当vector在删除的时候，被删除元素以及它后面的所有元素迭代器都失效。

## 48. 如何判断大端小端

字节序是对象在内存中存储的方式，大端即为最高有效位在前面，小端即为最低有效位在前面。

判断大小端的方法：使用一个union数据结构

```C++
union{
  short s;
  char c[2]; // sizeof(short)=2;
}un;
un.s=0x0102;
if(un.c[0]==1 and un.c[1]==2) cout<<"大端";
if(un.c[0]==2 and un.c[1]==1) cout<<"小端";
```

## 49. 如何使得类只在堆上或者栈上开辟空间

> 1. [只在堆上或者栈上开辟空间](https://blog.csdn.net/u011857683/article/details/81837879)

**1. 只在堆上**

**将析构函数设为私有，类对象就无法建立在栈上了**，只能在堆上开辟空间。

```C++
class A  {  
public:  
    A(){}  
    void destory(){delete this;}  
private:  
    ~A(){}  
};  
```

**2. 只在栈上**

只有使用new运算符，对象才会建立在堆上，因此，只要禁用new运算符就可以实现类对象只能建立在栈上。虽然你不能影响new operator的能力（因为那是C++语言内建的），但是你可以利用一个事实：new operator 总是先调用 operator new，而后者我们是可以自行声明重写的。因此，**将operator new()设为私有即可，禁止对象被new在堆上**。

```C++
class A  
{  
private:  
    void* operator new(size_t t){}    // 注意函数的第一个参数和返回值都是固定的  
    void operator delete(void* ptr){} // 重载了new就需要重载delete  
public:  
    A(){}  
    ~A(){}  
}; 
```



## 50. C++11新特性

- **空指针常量 nullptr**

  一个函数重载了空指针和整型的情形下，NULL并不能表示空指针，就有可能会出现错误，但是nullptr可以保证在任何情况下都是空指针。

- **自动类型推断 auto**

- **匿名函数**lambda

- **后置返回类型（tailng-return-type）**

- **long long int类型**

- **新增基于范围的for循环**

- 右值引用



## 51. 哪些数据会影响类的大小（sizeof）

```C++
class classSize{ // 空类的大小是1
    static int a; // 静态变量占用0空间
    const static int b=1; // 静态常量占用0空间
    const int c=0; // 常量占用4空间
    int * ptr=nullptr; // 指针占用4空间
    virtual int getRes(){ return 0;} // 虚函数占用4空间
    int getRes1(){int c=0; return 0;} // 一般函数占用0空间
    int d=3; // 变量占用4空间
};
```

常量、成员变量、虚函数、定义空类时类本身占用一个空间大小

## 52. vector中的clear和resize会回收内存吗？

只能清空数据，不会回收内存。

> 如何回收vector所占用的内存空间？
>
> 先使用vecInt.clear()清空, 再使用swap,释放空间回收内存. (先vec.clear()再vec->swap( (std::vector <temp>)(vec) )，就能实现清空vector和释放原来vector的内存)

## 53. 定义一个空类会自动生成哪些成员函数

- 缺省的(无参数的)构造函数
- 拷贝构造函数
- 析构函数
- 赋值运算符
- 取址运算符
- const版本的取址运算符

## 54. 拷贝构造函数和赋值运算符

```C++
class Person{
public:
	Person(){}
	Person(const Person& p){
		cout << "Copy Constructor" << endl;
	}

	Person& operator=(const Person& p){
		cout << "Assign" << endl;
		return *this;
	}

private:
	int age;
	string name;
};

void f(Person p){
	return;
}

Person f1(){
	Person p;
	return p;
}

int main(){
	Person p;
	Person p1 = p;    // 1
	Person p2;
	p2 = p;           // 2
	f(p2);            // 3

	p2 = f1();        // 4

	Person p3 = f1(); // 5

	getchar();
	return 0;
}
```



## 55. 传参、传指针、传引用的区别

**传值：**传值就是实参的拷贝传递给形参，但是两者相互独立，对形参的修改就不会影响到实参。

**传地址：**传地址就是把实参的地址复制给形参。对形参地址的修改不会影响到实参, 但是对形参地址所指向对象的修改却直接反应在实参中。

**传引用：**传引用本质没有任何实参的拷贝，一句话，就是让另外一个变量也执行该实参。就是两个变量指向同一个对象。这是对形参的修改，必然反映到实参上。

```C++
#include<bits/stdc++.h>
using namespace std
 
void adjustNum(int a){
    a++;
    return;
}

void adjustNum_ptr(int *a){
    (*a)++;
    return;
}

void adjustNum_addr(int &a){
    a++;
    return;
}

int main(){
    int b = 1;
    adjustNum(b); // 输出1
    adjustNum_ptr(&b) // 输出2；
    adjustNum_addr(b) // 输出2；
    cout << b << endl;
    return 0；
}
```





## 56. 智能指针

> 1. [C++11中智能指针的原理、使用、实现](https://www.cnblogs.com/wxquare/p/4759020.html)

智能指针和普通指针类似，只是不需要手动释放指针，而是通过智能指针自己管理内存的释放，**智能指针可以很好的避免内存泄漏的问题**。 智能指针包括：**auto_ptr、共享指针(shared_ptr)、弱指针（weak_ptr）和独占指针（unique_ptr）**

- **unique_ptr(独占指针)**

  ![转移 unique_ptr 的所有权](https://i-msdn.sec.s-msft.com/dynimg/IC786112.jpeg)

  - Unique_ptr是一个独占的智能指针，他不允许其他的智能指针共享其内部的指针，不允许通过赋值将一个unique_ptr赋值给另外一个 unique_ptr。
  - unique_ptr不允许复制，但可以通过函数返回给其他的unique_ptr，还可以通过move来转移到其他的unique_ptr，这样它本身就不再拥有原来指针的所有权了。
  - 如果希望只有一个智能指针管理资源或管理数组就用unique_ptr，如果希望多个智能指针管理同一个资源就用shared_ptr。

  ```C++
  #include<bits/stdc++.h>
  using namespace std;
  
  // 使用举例
  void useExample(){
      //创建一个指向int的空指针
      std::unique_ptr<int> fPtr1;
      std::unique_ptr<int> fPtr2(new int(4));
      auto fPtr3 = std::make_unique<int>();
      
      //fPtr2释放指向对象的所有权，并且被置为nullptr
      std::cout << "fPtr2 release before:" << fPtr2.get() << std::endl;
      int *pF = fPtr2.release();
      std::cout << "fPtr2 release after:" << fPtr2.get() << " and pF value:" << *pF << std::endl;
      
      //所有权转移，转移后fPtr3变为空指针
      std::cout << "move before fPtr1 address:" << fPtr1.get() << " fPtr3 address:" << fPtr3.get() << std::endl;
      fPtr1 = std::move(fPtr3);
      std::cout << "move after  fPtr1 address:" << fPtr1.get() << " fPtr3 address:" << fPtr3.get() << std::endl;
  
      std::cout << "move before fPtr1 address:" << fPtr1.get() << std::endl;
      fPtr1.reset();
      std::cout << "move after  fPtr1 address:" << fPtr1.get() << std::endl;
      
  }
  
  unique_ptr<int> clone(int p)
  {
      unique_ptr<int> pInt(new int(p));
      return pInt;    // 返回unique_ptr
  }
  
  int main()
  {
      // 1. 创建一个unique_ptr实例
      unique_ptr<int> pInt(new int(5));
      cout << "pInt1: " << *pInt << endl;
  
      // 2. unique_ptr不可以复制和拷贝
      // unique_ptr<int> pInt2(pInt);    // 报错
      // unique_ptr<int> pInt3 = pInt;   // 报错
  
      // 3. unique_ptr可以进行移动
      unique_ptr<int> pInt2 = move(pInt);    // 转移所有权
      // cout << *pInt << endl; // 出错，pInt为空
      cout << "pInt2: " << *pInt2 << endl;
      unique_ptr<int> pInt3(move(pInt2));
      cout << "pInt3: " << *pInt3 << endl;
  
      // 4. 可以作为返回对象返回
      unique_ptr<int> res = clone(6);
      cout << "result of function: " << *res << endl;
  
      useExample();
      return 0;
  }
  ```

  > 注意：
  >
  > - release和reset的区别：前者会释放控制权，返回裸指针，你还可以继续使用。而后者直接释放了指向对象。

- **shared_ptr(共享指针)**

  > 1. [shared_ptr的用法](https://www.cnblogs.com/jiayayao/p/6128877.html)

  shared_ptr多个指针指向相同的对象。shared_ptr使用引用计数，每一个shared_ptr的拷贝都指向相同的内存。每使用他一次，内部的引用计数加1，每析构一次，内部的引用计数减1，减为0时，自动删除所指向的堆内存。shared_ptr内部的引用计数是线程安全的，但是对象的读取需要加锁。
  
  > 注意事项：
  >
  > 1. 不要用一个原始指针初始化多个shared_ptr。 
  > 2. 不要在函数实参中创建shared_ptr，在调用函数之前先定义以及初始化它。 
  > 3. 不要将this指针作为shared_ptr返回出来。 
  > 4. 要避免循环引用。
  
  ```C++
  # include<bits/stdc++.h>
  using namespace std;
  
  class Person{
  public:
      Person(int v) { // 构造函数
          value = v;
          cout << "Cons" <<value<< endl;
      }
      ~Person() { // 析构函数
          cout << "Des" <<value<< endl;
      }
      int value;
  };
  
  
  int main(){
      shared_ptr<Person> p1(new Person(1));// Person(1)的引用计数为1
      shared_ptr<Person> p2 = make_shared<Person>(2);
      // std::shared_ptr<int> p4 = new int(1);// error
  
      p1.reset(new Person(3));// 先生成新对象，然后引用计数减1，引用计数为0，故析构Person(1)
                              // 最后将新对象的指针交给智能指针
      shared_ptr<Person> p3 = p1;//现在p1和p3同时指向Person(3)，Person(3)的引用计数为2
      p1.reset();//Person(3)的引用计数为1
      p3.reset();//Person(3)的引用计数为0，析构Person(3)
      return 0;
  }
  ```
  
  
  
- **weak_ptr（弱指针**）

  weak_ptr是弱智能指针对象，它不控制所指向对象生存期的智能指针，它指向由一个shared_ptr管理的智能指针。将一个weak_ptr绑定到一个shared_ptr对象，不会改变shared_ptr的引用计数。一旦最后一个所指向对象的shared_ptr被销毁，所指向的对象就会被释放，即使此时有weak_ptr指向该对象，所指向的对象依然被释放。
  
  weak_ptr是用来监视shared_ptr的，不会使引用计数加一，它不管理shared_ptr内部的指针，主要是为了监视shared_ptr的生命周期。 weak_ptr没有重载运算符*和->，因为它不共享指针，不能操作资源，主要是为了通过shared_ptr获得资源的监测权，它的构造不会增加引用计数，它的析构不会减少引用计数，纯粹只是作为一个旁观者来监视shared_ptr中关联的资源是否存在。 weak_ptr还可以用来返回this指针和解决循环引用的问题。

> 什么是循环引用
>
> 内存的正常回收：
>
> ![img](https://upload-images.jianshu.io/upload_images/2118879-1f06c66f210fb3e3.png?imageMogr2/auto-orient/strip|imageView2/2/w/472/format/webp)

>  循环引用导致的内存泄漏：
>
> ![img](https://upload-images.jianshu.io/upload_images/2118879-09fed596c7d95b42.png?imageMogr2/auto-orient/strip|imageView2/2/w/443/format/webp)
>
> 



## 57. 库函数和系统调用的区别

- 库函数是语言或应用程序的一部分，而系统调用是操作系统的一部分；
- 库函数在用户态，系统调用在内核态；
- 库函数属于过程调用，开销比较小，但是系统调用需要在用户空间和内核上下文环境间切换，开销较大；

## 58. 构造函数调用虚函数调用谁的

调用自己的

## 59. 析构函数调用虚函数调用谁的



## 60. 类是先开辟空间还是先调用构造函数

先开辟空间，构造函数只是初始化这片空间

## 61. 何时调用析构函数

- 对象生命周期结束，被销毁时。也就是超出变量作用域；
- 主动调用delete ；
- 对象A是对象B的成员，B的析构函数被调用时，对象A的析构函数也被调用。

## 62. 源码到可执行文件的过程

<font color=blue>1）预编译</font>

主要处理源代码文件中的以“#”开头的预编译指令。处理规则见下

1、删除所有的#define，展开所有的宏定义。

2、处理所有的条件预编译指令，如“#if”、“#endif”、“#ifdef”、“#elif”和“#else”。

3、处理“#include”预编译指令，将文件内容替换到它的位置，这个过程是递归进行的，文件中包含其他文件。

4、删除所有的注释，“//”和“/**/”。

5、保留所有的#pragma 编译器指令，编译器需要用到他们，如：#pragma once 是为了防止有文件被重复引用。

6、添加行号和文件标识，便于编译时编译器产生调试用的行号信息，和编译时产生编译错误或警告是能够显示行号。

<font color=blue>2）编译</font>

把预编译之后生成的xxx.i或xxx.ii文件，进行一系列词法分析、语法分析、语义分析及优化后，生成相应的汇编代码文件。

1、词法分析：利用类似于“有限状态机”的算法，将源代码程序输入到扫描机中，将其中的字符序列分割成一系列的记号。

2、语法分析：语法分析器对由扫描器产生的记号，进行语法分析，产生语法树。由语法分析器输出的语法树是一种以表达式为节点的树。

3、语义分析：语法分析器只是完成了对表达式语法层面的分析，语义分析器则对表达式是否有意义进行判断，其分析的语义是静态语义——在编译期能分期的语义，相对应的动态语义是在运行期才能确定的语义。

4、优化：源代码级别的一个优化过程。

5、目标代码生成：由代码生成器将中间代码转换成目标机器代码，生成一系列的代码序列——汇编语言表示。

6、目标代码优化：目标代码优化器对上述的目标机器代码进行优化：寻找合适的寻址方式、使用位移来替代乘法运算、删除多余的指令等。

<font color=blue>3）汇编</font>

将汇编代码转变成机器可以执行的指令(机器码文件)。 汇编器的汇编过程相对于编译器来说更简单，没有复杂的语法，也没有语义，更不需要做指令优化，只是根据汇编指令和机器指令的对照表一一翻译过来，汇编过程有汇编器as完成。经汇编之后，产生目标文件(与可执行文件格式几乎一样)xxx.o(Windows下)、xxx.obj(Linux下)。

<font color=blue>4）链接</font>

将不同的源文件产生的目标文件进行链接，从而形成一个可以执行的程序。链接分为静态链接和动态链接：

1、静态链接：

函数和数据被编译进一个二进制文件。在使用静态库的情况下，在编译链接可执行文件时，链接器从库中复制这些函数和数据并把它们和应用程序的其它模块组合起来创建最终的可执行文件。

空间浪费：因为每个可执行程序中对所有需要的目标文件都要有一份副本，所以如果多个程序对同一个目标文件都有依赖，会出现同一个目标文件都在内存存在多个副本；

更新困难：每当库函数的代码修改了，这个时候就需要重新进行编译链接形成可执行程序。

运行速度快：但是静态链接的优点就是，在可执行程序中已经具备了所有执行程序所需要的任何东西，在执行的时候运行速度快。

2、动态链接：

动态链接的基本思想是把程序按照模块拆分成各个相对独立部分，在程序运行时才将它们链接在一起形成一个完整的程序，而不是像静态链接一样把所有程序模块都链接成一个单独的可执行文件。

共享库：就是即使需要每个程序都依赖同一个库，但是该库不会像静态链接那样在内存中存在多分，副本，而是这多个程序在执行时共享同一份副本；

更新方便：更新时只需要替换原来的目标文件，而无需将所有的程序再重新链接一遍。当程序下一次运行时，新版本的目标文件会被自动加载到内存并且链接起来，程序就完成了升级的目标。

性能损耗：因为把链接推迟到了程序运行时，所以每次执行程序都需要进行链接，所以性能会有一定损失。



## 63. STL的基本组成

- STL主要由：以下几部分组成：容器、迭代器、仿函数、算法、分配器、配接器
- 他们之间的关系：分配器给容器分配存储空间，算法通过迭代器获取容器中的内容，仿函数可以协助算法完成各种操作，配接器用来套接适配仿函数

## 64. 静态函数和虚函数的区别

静态函数是在编译时确定运行的时机，但是虚函数是在运行时动态绑定。并且虚函数是使用了虚函数表机制。调用的时候会增加一次内存的开销。

## 65. C++是如何定义常量的，常量存储在什么位置

添加一个const限定就可以定义一个常量

局部对象存储于栈区，全局对象存储在全局/静态变量区，对于字面值常量，常量存放在常量存储区



## 66. 静态变量什么时候初始化

静态变量的初始化是在编译期确定的。

> 静态变量存储在虚拟地址空间的数据段和bss段，C语言中其在代码执行之前初始化，属于编译期初始化。而C++中由于引入对象，对象生成必须调用构造函数，因此C++规定全局或局部静态对象当且仅当对象首次用到时进行构造。



## 67. 什么时候会发生段错误

- 使用野指针
- 尝试对常量进行修改

## 68. 如何判断内存泄漏

- Linux下可以使用专门的工具Valgrind进行检测
- 可以添加内存申请和释放的统计功能，统计当前申请和释放的内存是否一致，以此来判断内存是否泄露。

## 69. map和set的区别

map和set都是C++的关联容器，其底层实现都是红黑树（RB-Tree）。由于 map 和set所开放的各种操作接口，RB-tree 也都提供了，所以几乎所有的 map 和set的操作行为，都只是转调 RB-tree 的操作行为。

**map和set区别在于：**

- map中的元素是key-value（关键字—值）对：关键字起到索引的作用，值则表示与索引相关联的数据；Set与之相对就是关键字的简单集合，set中每个元素只包含一个关键字。

- set的迭代器是const的，不允许修改元素的值；map允许修改value，但不允许修改key

  >  其原因是因为map和set是根据关键字排序来保证其有序性的，如果允许修改key的话，那么首先需要删除该键，然后调节平衡，再插入修改后的键值，调节平衡，如此一来，严重破坏了map和set的结构，导致iterator失效，不知道应该指向改变前的位置，还是指向改变后的位置。所以STL中将set的迭代器设置成const，不允许修改迭代器的值；而map的迭代器则不允许修改key值，允许修改value值。

- map支持下标操作，set不支持下标操作。

  > map可以用key做下标

## 70. 智能指针有没有内存泄漏的情况

有，循环引用会导致内存泄漏。当两个对象，对象1中使用指针指向对象2，对象2使用指针指向1就导致了循环引用。解决循环引用可以使用weak_ptr.



## 71. strlen 和sizeof的区别

- strlen 是计算字符串的长度的，以‘\0’为结尾；sizeof是分配的数组实际所占的内存空间大小，不受里面存储内容的影响。
- strlen是一个函数，sizeof是运算符

> sizeof()是运算符，由于在编译时计算，因此sizeof不能用来返回动态分配的内存空间的大小。实际上，
> 用sizeof来返回类型以及静态分配的对象、结构或数组的空间，返回值跟这些里面所存储的内容没有关
> 系。
> 具体而言，当参数分别如下时，sizeof返回的值含义如下：
> 数组-编译时分配的数组空间大小
> 指针-存储该指针所用的空间大小
> 类型-该类型所占的空间的大小
> 对象-对象的实际占用空间大小
> 函数-函数返回类型所占空间的大小 



## 72. STL各种容器的底层实现

- vector： 数组  [在插入位置和删除位置之后的所有的迭代器和指针引用都会失效，扩容之后也是]

- map、multimap： 红黑树实现。红黑树中的元素为 pair<K, V> 实现以key为序排列。map 和
  multimap是有序

- unordered_map 和 unordered_multimap 是无序的，底层用hash table

- set 、multiset：和map的区别在于map中存储的是<key, value>,而set可以理解为关键字即值，也
  就是只保存关键字的容器。理解了这个，set multiset的实现与map 的底层实现一样，都是采用红
  黑树有序存储元素。
- unordered_set、unordered_multiset 底层实现为hash table。

- priority_queue（优先级队列） 相当于一个有权值得单向队列，在这个队列中，所有元素都是按照优先级排列得。 根据堆得处理规则来调整元素之间的位置，取出最大最小元素的时间复杂度为O(1)，插入和删除最坏的情况为O(logn)。

- list的底层数据结构为双向链表，特点是支持快速的增删。

- queue为单向队列，为先入先出原则。

- deque 为双向队列，其对比queue可以在头尾两端高效的插入和删除操作。 

## 73. 类的空指针可以调用成员函数吗

**可以**，正常情况下调用时编译器会默认将this指针作为参数传递过去，这种情况下，传递的this指针为空，参数为空不影响函数的调用。但是如果在执行的时候使用了成员变量，也就是会出现null->data，程序就会崩溃。 

```C++
class  CNullPointCall
{
public :
     static   void  Test1();
     void  Test2();
     void  Test3( int  iTest);
     void  Test4();

private :
     static   int  m_iStatic;
     int  m_iTest;
};

int  CNullPointCall::m_iStatic  =   0 ;

void  CNullPointCall::Test1()
{
    cout  <<  m_iStatic  <<  endl;
}

void  CNullPointCall::Test2()
{
    cout  <<   " Very Cool! "   <<  endl; 
}

void  CNullPointCall::Test3( int  iTest)
{
    cout  <<  iTest  <<  endl; 
}

void  CNullPointCall::Test4()
{
    cout  <<  m_iTest  <<  endl; 
}

int main(){
    CNullPointCall  * pNull  =  NULL;  //  定义一个类的空指针
    pNull -> Test1(); //  call 1
    pNull -> Test2();  //  call 2
    pNull -> Test3( 13 );  //  call 3
    pNull -> Test4(); / /  call 4
}
```



## 74. 数组和指针的区别

- 赋值：
  同类型指针变量可以相互赋值，数组不行，只能一个一个元素的赋值或拷贝。
- 存储方式
  - 数组在内存中是连续存放的，开辟一块连续的内存空间。数组是根据数组的下标进行访问的；
    多维数组在内存中是按照一维数组存储的，只是在逻辑上是多维的；
    数组的存储空间，不是在静态区就是在栈上；
  - 指针：指针很灵活，它可以指向任意类型的数据。指针的类型说明了它所指向地址空间的内存。
    指针：由于指针本身就是一个变量，再加上它所存放的也是变量，所以指针的存储空间不能确
    定。
- 求sizeof
  数组
  数组所占存储空间的内存：sizeof（数组名字）
  数字的大小 sizeof(数组名) / sizeof(数据类型)
  指针：
  在32位平台下，无论指针的类型是什么，sizeof（指针名）都是4，在64位平台下，无论指
  针的类型是什么，sizeof（指针名）都是8。
- 传参
  数组传参：将整个数组拷贝一份传入函数时，将数组名看做常量指针，传数组元素的地址。 

## 75. C++哪类函数不可以设计为虚函数

> <font color=blue>不能是虚函数的函数：静态成员函数、内联函数、构造函数</font>

设置虚函数须注意：
1：只有类的成员函数才能说明为虚函数；
**2：静态成员函数不能是虚函数；**
**3：内联函数不能为虚函数；**
**4：构造函数不能是虚函数；**
5：析构函数可以是虚函数，而且通常声明为虚函数。

虚函数可以实现多态，那么那些函数不能申明为虚函数呢？

1.普通的函数

因为普通函数只能被overload，不能被override，也不能被继承，所以在编译的时候就绑定函数，所以不能申明为virtual，没有意义！

2.构造函数

这个也很简单。主要因为构造函数是用来确定初始化对象的，而virtual主要是为了在不了解具体的情况下实现动态绑定，调用不同类型中合适的成员函数而存在的，现在对象都没产生，怎么能实现多态呢。一个是为了具体化，一个是为了在不同对象类型中确定合适的函数，这是不可能的！

此外，构造函数不能被继承，所以不能virtual；构造函数是系统默认提供或者自己写的，并且和类名相同，就算继承了也不是自己的了，所以不能被继承；

构造函数是在为了创建初始化对象存在的，对象不存在实现多态是不可能的；

3.内联函数

inline函数在编译时被展开，在调用处将整个函数替换为代码块，省去了函数跳转的时间，提高了SD，减少函数调用的开销，虚函数是为了继承后对象能够准确的调用自己的函数，执行相应的动作。

主要的原因是：inline函数在编译时被展开，用函数体去替换函数，而virtual是在运行期间才能动态绑定的，这也决定了inline函数不可能为虚函数。（inline函数体现的是一种编译机制，而virtual体现的是一种动态运行机制）

4.静态成员函数

静态成员函数是类的组成部分，但是不是任何对象的组成部分，所有对象共享一份，没有必要动态绑定，也不能被继承【效果能，但机理不能。静态成员函数就一份实体，在父类里；子类继承父类时也无需拷贝父类的静态函数，但子类可以使用父类的静态成员函数】，并且静态成员函数只能访问静态变量。所以不能为virtual。

5.友员函数

友员函数不是类的成员函数，C++不支持友员被继承，所以不能为virtual。

# 二、计算计网络高频

> 1. [计算机网络太难？了解这一篇就够了](https://zhuanlan.zhihu.com/p/84316213)
> 2. [【面试题总结】计算机网络面试总结](http://yyanghhu.tech/2020/05/12/network-001/)
> 3. https://blog.csdn.net/chenchaofuck1/article/details/51980794

## 1. 五层协议

**应用层，运输层，网络层，数据链路层，物理层**

- 第五层——应用层(application layer) 

  - **应用层(application layer)：**是体系结构中的最高。<font color=blue>直接为用户的应用进程（例如电子邮件、文件传输和终端仿真）提供服务</font>。
  - 在因特网中的应用层协议很多，如支持万维网应用的HTTP协议，支持电子邮件的SMTP协议，支持文件传送的FTP协议，DNS，POP3，SNMP，Telnet等等。

- 第四层——运输层(transport layer)

  - **运输层(transport layer)：**<font color=blue>负责向两个主机中进程之间的通信提供服务</font>。由于一个主机可同时运行多个进程，因此运输层有复用和分用的功能
  - 复用，就是多个应用层进程可同时使用下面运输层的服务。
  - 分用，就是把收到的信息分别交付给上面应用层中相应的进程。
  - **运输层主要使用以下两种协议：** 
    **(1) 传输控制协议TCP(Transmission Control Protocol)：**面向连接的，数据传输的单位是报文段，能够提供可靠的交付。 
    **(2) 用户数据包协议UDP(User Datagram Protocol)：**无连接的，数据传输的单位是用户数据报，不保证提供可靠的交付，只能提供“尽最大努力交付”。

- 第三层——网络层(network layer)

  - 网络层(network layer)主要包括以下两个任务：

    ​	**(1) <font color=blue>负责为分组交换网上的不同主机提供通信服务</font>。在发送数据时，网络层把运输层产生的报文段或用户数据报封装成分组或包进行传送。在TCP/IP体系中，由于网络层使用IP协议，因此分组也叫做IP数据报，或简称为数据报。**

    ​	**(2) <font color=blue>选中合适的路由，使源主机运输层所传下来的分组，能够通过网络中的路由器找到目的主机</font>。**

  - **协议：IP,ICMP,IGMP,ARP（根据IP地址通过广播寻求MAC地址）,RARP**

- 第二层——数据链路层(data link layer)

  > <font color=blue>数据链路层的作用就是把IP数据报封装成帧，并实现相邻结点之间数据传输</font>

  - **数据链路层(data link layer)：**常简称为链路层，我们知道，两个主机之间的数据传输，总是在一段一段的链路上传送的，也就是说，<font color=blue>在两个相邻结点之间传送数据</font>是直接传送的(点对点)，这时就需要使用专门的链路层的协议。

  - 在两个相邻结点之间传送数据时，数据链路层将网络层交下来的IP数据报组装成帧(framing)，在两个相邻结点之间的链路上“透明”地传送帧中的数据。

  - 每一帧包括数据和必要的控制信息(如同步信息、地址信息、差错控制等)。典型的帧长是几百字节到一千多字节。

    > 注：”透明”是一个很重要的术语。它表示，某一个实际存在的事物看起来却好像不存在一样。”在数据链路层透明传送数据”表示无力什么样的比特组合的数据都能够通过这个数据链路层。因此，对所传送的数据来说，这些数据就“看不见”数据链路层。或者说，数据链路层对这些数据来说是透明的。 
    > (1)在接收数据时，控制信息使接收端能知道一个帧从哪个比特开始和到哪个比特结束。这样，数据链路层在收到一个帧后，就可从中提取出数据部分，上交给网络层。 

  > (2)控制信息还使接收端能检测到所收到的帧中有无差错。如发现有差错，数据链路层就简单地丢弃这个出了差错的帧，以免继续传送下去白白浪费网络资源。如需改正错误，就由运输层的TCP协议来完成。

- 第一层——物理层(physical layer)

  - **物理层(physical layer)：**在物理层上所传数据的单位是比特。物理层的任务就是透明地<font color=blue>传送比特流</font>。

**各个层的作用是什么**

- 应用层：直接为用户的应用进程提供服务
- 传输层：为不同主机上的两个进程提供通信服务
- 网络层：1) 为分组交换网中的不同主机提供通信服务；2)选中合适的路由，使得源主机上通过运输成传下来的数据可以经过网路中的路由到达正确的目的主机
- 数据链路层：把IP数据包封装成帧并实现相邻结点之间的传输
- 物理层：传输比特流



## 2. 为什么有TCP的存在

因为IP通信时不可靠的，IP只为上层提供无状态、无连接、不可靠的服务。只保证尽力的交付，并且交付的数据是无序的并且还可能是重复的，也可能丢失。对于接受端的IP模块只要收到了完整的IP数据报就会将其数据部分交付给上层协议，所以如果不经过TCP的处理，应用层直接获取这样的数据是有问题的。所以TCP的存在时有必要的。TCP可以通过序列号确认、超时重传、流量控制、拥塞避免等保证数据的可靠交付。



## 3. TCP和UDP的区别

**1) 区别：**

-  连接
  TCP是面向连接的传输层协议，即传输数据之前必须先建立好连接。
  UDP无连接。

-  服务对象
  TCP是点对点的两点间服务，即一条TCP连接只能有两个端点；
  UDP支持一对一，一对多，多对一，多对多的交互通信。

- 可靠性
  TCP是可靠交付：无差错，不丢失，不重复，按序到达。
  UDP是尽最大努力交付，不保证可靠交付。

- 拥塞控制，流量控制
  TCP有拥塞控制和流量控制保证数据传输的安全性。
  UDP没有拥塞控制，网络拥塞不会影响源主机的发送效率。
- 开销
  TCP的开销比价大，UDP的开销比较小



**2) TCP对应的协议和UDP对应的协议**
**TCP对应的协议：**

- FTP：定义了文件传输协议，使用21端口。
- Telnet：一种用于远程登陆的端口，使用23端口，用户可以以自己的身份远程连接到计算机上，可提供基于DOS模式下的通信服务。
- SMTP：邮件传送协议，用于发送邮件。服务器开放的是25号端口。
- POP3：它是和SMTP对应，POP3用于接收邮件。POP3协议所用的是110端口。
- HTTP：是从Web服务器传输超文本到本地浏览器的传送协议。

**3) UDP对应的协议：**

- DNS：用于域名解析服务，将域名地址转换为IP地址。DNS用的是53号端口。
- SNMP：简单网络管理协议，使用161号端口，是用来管理网络设备的。由于网络设备很多，无连接的服务就体现出其优势。
- TFTP(Trivial File Transfer Protocal)，简单文件传输协议，该协议在熟知端口69上使用UDP服务。

## 4. TCP三次握手/四次握手

**三次握手**：

- 第一次握手：客户端发送syn包(syn=x)到服务器，并进入SYN_SEND状态，等待服务器确认；

- 第二次握手：服务器收到syn包，必须确认客户的SYN（ack=x+1），同时自己也发送一个SYN包（syn=y），即SYN+ACK包，此时服务器进入SYN_RECV状态；

- 第三次握手：客户端收到服务器的SYN＋ACK包，向服务器发送确认包ACK(ack=y+1)，此包发送完毕，客户端和服务器进入ESTABLISHED状态，完成三次握手。

  > 握手过程中传送的包里不包含数据，三次握手完毕后，客户端与服务器才正式开始传送数据。理想状态下，TCP连接一旦建立，在通信双方中的任何一方主动关闭连接之前，TCP 连接都将被一直保持下去。
  
  ![img](https://pic2.zhimg.com/80/v2-1c5da3391ad30aa7aa30f9362407a77f_1440w.jpg)



**四次握手**

与建立连接的“三次握手”类似，断开一个TCP连接则需要“四次握手”。

- 第一次挥手：主动关闭方发送一个FIN，用来关闭主动方到被动关闭方的数据传送，也就是主动关闭方告诉被动关闭方：我已经不会再给你发数据了(当然，在fin包之前发送出去的数据，如果没有收到对应的ack确认报文，主动关闭方依然会重发这些数据)，但是，此时主动关闭方还可 以接受数据。
- 第二次挥手：被动关闭方收到FIN包后，发送一个ACK给对方，确认序号为收到序号+1（与SYN相同，一个FIN占用一个序号）。
- 第三次挥手：被动关闭方发送一个FIN，用来关闭被动关闭方到主动关闭方的数据传送，也就是告诉主动关闭方，我的数据也发送完了，不会再给你发数据了。
- 第四次挥手：主动关闭方收到FIN后，发送一个ACK给被动关闭方，确认序号为收到序号+1，至此，完成四次挥手。

![img](https://pic3.zhimg.com/80/v2-dc0bdc69237df055ff8c2aa477887237_1440w.jpg)

**TIME-WAIT存在的含义：**

C向S发送的最后一个ACK有可能会丢失，这个时候S会再次向C发送一个FIN，如果C已经关闭，S会重复向C发送FIN，这就导致了资源的浪费，但是如果这个TIME-WAIT存在的话，即使最后一个C向S发送的ACK丢失，导致S再次发送FIN， 也会使得C和S之间的链接能够正常断开

### 1. TCP是如何保证可靠传输的

- 校验和

  发送的数据包的二进制相加然后取反，目的是检测数据在传输过程中的任何变化。如果收到段的检验和有差错，TCP将丢弃这个报文段和不确认收到此报文段。

- 确认应答+序列号

  TCP给发送的每一个包进行编号，接收方对数据包进行排序，把有序数据传送给应用层。

- 超时重传

  当TCP发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段。

- 连接管理

- 流量控制

  TCP连接的每一方都有固定大小的缓冲空间，TCP的接收端只允许发送端发送接收端缓冲区能接纳的数据。当接收方来不及处理发送方的数据，能提示发送方降低发送的速率，防止包丢失。TCP使用的流量控制协议是可变大小的滑动窗口协议。接收方有即时窗口（滑动窗口），随ACK报文发送 。

- 拥塞控制

  当网络拥塞时，减少数据的发送。

  > **慢启动、拥塞避免、快速重传、快速恢复**

### 2.  建立TCP 服务器的系统调用

> 1. [建立TCP 服务器的系统调用](https://blog.csdn.net/qq_37964547/article/details/81429627)

![这里写图片描述](https://img-blog.csdn.net/20180804211807158?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3OTY0NTQ3/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)



- accept只是从监听队列中取出链接，而不论链接处于何种状态，更不关心网络的变化

- ```C++
  recv(int socketfd, void* buf, size_t len, int flags)// 读取socketfd上的数据
  send(int socketfd, const void *buf, size_t len, int flags); // 往socketfd上写入数据
  ```

### 3. 超时重传

<font color=blue>当发生数据包丢失或者确认应答丢失时会触发超时重传机制</font>

![img](https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZeuicRMlA8rKvl5AVLibhibDhgObdlvOJianvD0oj586rMc8wVs4hlzUtgRibWfD0WBpAJhRtHxOPd9ibibQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

超时时间一般设置为2个RTT时间，当超时时间设置的标准不同时会发生的情况

- 当超时时间 **RTO 较大**时，重发就慢，丢了老半天才重发，没有效率，性能差；
- 当超时时间 **RTO 较小**时，会导致可能并没有丢就重发，于是重发的就快，会增加网络拥塞，导致更多的超时，更多的超时导致更多的重发。

根据上述的两种情况，**超时重传时间 RTO 的值应该略大于报文往返  RTT 的值**。



### 4. 快速重传

![img](https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZeuicRMlA8rKvl5AVLibhibDhggRhxrfiaRIsia0z3T4l7TxVM7J9vjFktFRKHkdva953UY6vFIpsYsOicQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

在上图，发送方发出了 1，2，3，4，5 份数据：

- 第一份 Seq1 先送到了，于是就 Ack 回 2；
- 结果 Seq2 因为某些原因没收到，Seq3 到达了，于是还是 Ack 回 2；
- 后面的 Seq4 和 Seq5 都到了，但还是 Ack 回 2，因为 Seq2 还是没有收到；
- **发送端收到了三个 Ack = 2 的确认，知道了 Seq2 还没有收到，就会在定时器过期之前，重传丢失的 Seq2。**
- 最后，接收到收到了 Seq2，此时因为 Seq3，Seq4，Seq5 都收到了，于是 Ack 回 6 。

所以，快速重传的工作方式是当收到三个相同的 ACK 报文时，会在定时器过期之前，重传丢失的报文段。

快速重传机制只解决了一个问题，就是超时时间的问题，但是它依然面临着另外一个问题。就是<font color=blue>**重传的时候，是重传之前的一个，还是重传所有的问题。**</font>比如对于上面的例子，是重传 Seq2 呢？还是重传 Seq2、Seq3、Seq4、Seq5 呢？因为发送端并不清楚这连续的三个 Ack 2 是谁传回来的。



**4.1 SACK方法解决上述问题**

这种方式需要在 TCP 头部「选项」字段里加一个 `SACK` 的东西，它**可以将缓存的地图发送给发送方**，这样发送方就可以知道哪些数据收到了，哪些数据没收到，知道了这些信息，就可以**只重传丢失的数据**。

如下图，发送方收到了三次同样的 ACK 确认报文，于是就会触发快速重发机制，通过 `SACK` 信息发现只有 `200~299` 这段数据丢失，则重发时，就只选择了这个 TCP 段进行重复。

![img](https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZeuicRMlA8rKvl5AVLibhibDhg3RbEZItSOQY1TadJpUTuibIDziaibALaEmk7JO0Ill7iaeiaGI94Wyia0NXA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

**4.2 D-SACK**

Duplicate SACK 又称 `D-SACK`，其主要**使用了 SACK 来告诉「发送方」有哪些数据被重复接收了。**



### 5. 流量控制

> 流量控制是针对端到端的，也就是针对客户端发送和服务端接收的速度控制的机制，以避免客户端发送的太快，而服务端接受的太慢，导致问题的出现

TCP 利用滑动窗口实现流量控制。**流量控制是为了控制发送方发送速率，保证接收方来得及接收。接收方发送的确认报文中的窗口字段可以用来控制发送方窗口大小，从而影响发送方的发送速率**。将窗口字段设置为 0，则发送方不能发送数据。

**滑动窗口**：

TCP 利用滑动窗口实现流量控制的机制。**滑动窗口（Sliding window）是一种流量控制技术**。早期的网络通信中，通信双方不会考虑网络的拥挤情况直接发送数据。由于大家不知道网络拥塞状况，同时发送数据，导致中间节点阻塞掉包，谁也发不了数据，所以就有了滑动窗口机制来解决此问题。

TCP 中采用滑动窗口来进行传输控制，滑动窗口的大小意味着接收方还有多大的缓冲区可以用于接收数据。发送方可以通过滑动窗口的大小来确定应该发送多少字节的数据。当滑动窗口为 0 时，发送方一般不能再发送数据报，但有两种情况除外，一种情况是可以发送紧急数据，例如，允许用户终止在远端机上的运行进程。另一种情况是发送方可以发送一个 1 字节的数据报来通知接收方重新声明它希望接收的下一字节及发送方的滑动窗口大小。

### 6. 拥塞控制

> <font color=blue>说一下什么是拥塞控制</font>
>
> <font color=blue>拥塞控制主要是作用于网络，防止过多地数据被注入到网络，避免出现网络负载过大的情况。在C/S模型中，发送方维持一个叫做拥塞窗口cwnd（congestion window）。拥塞窗口的大小取决于网络的拥塞程度，并且动态地在变化。发送方可以让自己的发送窗口等于拥塞窗口，但是考虑到接受方的接收能力，发送窗口可能小于拥塞窗口。常用的方法包括慢开始、拥塞避免、快重传、快恢复。</font>

![图片说明](https://uploadfiles.nowcoder.com/images/20200826/498663897_1598422806100_85D3125CBCFE4357921CDD910EA780D5)



> 拥塞控制是针对网络的，当计算过多时，网络可能会出现拥堵，这个时候发送方应该如何让发送数据。这就利用到了拥塞控制。

拥塞控制和流量控制不同，前者是一个全局性的过程，而后者指点对点通信量的控制。在某段时间，若对网络中某一资源的需求超过了该资源所能提供的可用部分，网络的性能就要变坏。这种情况就叫拥塞。

**拥塞控制就是为了防止过多的数据注入到网络中，这样就可以使网络中的路由器或链路不致于过载**。拥塞控制所要做的都有一个前提，就是网络能够承受现有的网络负荷。拥塞控制是一个全局性的过程，涉及到所有的主机，所有的路由器，以及与降低网络传输性能有关的所有因素。相反，**流量控制往往是点对点通信量的控制，是个端到端的问题。流量控制所要做到的就是抑制发送端发送数据的速率，以便使接收端来得及接收**。

为了进行拥塞控制，TCP 发送方要维持一个拥塞窗口(cwnd) 的状态变量。拥塞控制窗口的大小取决于网络的拥塞程度，并且动态变化。**发送方让自己的发送窗口取为拥塞窗口和接收方的接受窗口中较小的一个**。

TCP 的拥塞控制采用了四种算法，即：**慢开始、拥塞避免、快重传和快恢复**。在网络层也可以使路由器采用适当的分组丢弃策略，以减少网络拥塞的发生。

- **慢开始**

  最开始发送方的拥塞窗口为1，由小到大逐渐增大发送窗口和拥塞窗口。每经过一个传输轮次，拥塞窗口cwnd加倍。当cwnd超过慢开始门限，则使用拥塞避免算法，避免cwnd增长过大。

- **拥塞避免**

  每经过一个往返时间RTT，cwnd就增长1。在慢开始和拥塞避免的过程中，一旦发现网络拥塞，就把慢开始门限设为当前值的一半，并且重新设置cwnd为1，重新慢启动。（乘法减小，加法增大）

- **快重传**

  接收方每次收到一个失序的报文段后就立即发出重复确认，发送方只要连续收到三个重复确认就立即重传（尽早重传未被确认的报文段）。

- **快恢复**

  当发送方连续收到了三个重复确认，就乘法减半（慢开始门限减半），将当前的cwnd设置为慢开始门限，并且采用拥塞避免算法（连续收到了三个重复请求，说明当前网络可能没有拥塞）。



<font color=blue>**6.1 发送端如何判断拥塞发生**</font>

- 发生超时重传
- 接收到重复确认的报文段

### 7. TCP为什么采用三次握手，而非两次

考虑这样一种特殊情况，主机A第一次发送的连接请求并没有丢失，而是因为网络节点导致延迟达到主机B，主机B以为是主机A又发起的新连接，于是主机B同意连接，并向主机A发回确认，但是此时主机A根本不会理会，主机B就一直在等待主机A发送数据，导致主机B的资源浪费。

### 8. UDP要想实现可靠传输如何实现

因为UDP是无连接的协议，所以在传输层上无法保证可靠传输，要想实现可靠传输，只能从应用层实现。需要实现seq/ack机制，重传机制和窗口确认机制就要接收方收到UDP之后回复个确认包，发送方有个机制，收不到确认包就要重新发送，每个包有递增的序号，接收方发现中间丢了包就要发重传请求，当网络太差时候频繁丢包，防止越丢包越重传的恶性循环，要有个发送窗口的限制，发送窗口的大小根据网络传输情况调整，调整算法要有一定自适应性。

### 9. TCP相关开放性问题

#### 9.1 TCP性能瓶颈

当连续接受三个重复的ACK时，发生超时重传，这时候发送端的发送窗口就会阻塞，不能向右继续滑动，也就限制了后面的数据的发送。这就是TCP的性能瓶颈。

> 如何解决？
>
> 使用QUIC技术解决TCP性能瓶颈问题

#### 9.2 TCP连接文件描述符耗尽怎么办

- 客户端最大tcp连接数位65536 - 1 = 65535 port 0 特殊含义
- 服务器的最大tcp连接数， {local ip, local port,remote ip,remote port}
- server最大tcp连接数：server通常固定在某个本地端口上监听，等待client的连接请求。不考虑地址重
  用（unix的SO_REUSEADDR选项）的情况下，即使server端有多个ip，本地监听端口也是独占的，因此
  server端tcp连接4元组中只有remote ip（也就是client ip）和remote port（客户端port）是可变的，
  因此最大tcp连接为客户端ip数×客户端port数，对IPV4，不考虑ip地址分类等因素，最大tcp连接数约为
  2的32次方（ip数）×2的16次方（port数），也就是server端单机最大tcp连接数约为2的48次方。
  当系统的文件描述符耗尽的时候，我们要做一些处理：
  - **方式一：**在拿到大于或者等于0的connfd(连接文件描述符)之后，非阻塞的epoll/select一下，看看这个fd是否可写。正常情况下epoll/select会返回writable，表明connfd可用。如果epoll/select返回错误，表示这个fd有问题，应该立刻关闭连接
  - **方式二：**设置一个最大连接数，当连接超过设定值时，直接关闭当前这个fd 

#### 9.3 TCP的7种定时器

> 1. 建立连接定时器(connection-establishment timer)
> 2. 重传定时器(retransmission timer)
> 3. 延迟应答定时器(delayed ACK timer)
> 4. 坚持定时器(persist timer)
> 5. 保活定时器(keepalive timer)
> 6. FIN_WAIT_2定时器(FIN_WAIT_2 timer)
> 7. TIME_WAIT定时器 (TIME_WAIT timer, 也叫2MSL timer) 

**1. 建立连接定时器**

TCP三次握手的时候，客户端先发送一个SYN请求建立连接，但是这个SYN可能会丢失。如果SYN包丢失了， 那么3秒以后会重新发送SYN包的(当然还会启动一个新的定时器， 设置成6秒超时) 

**2. 重传定时器**

重传定时器在TCP发送数据时设定，在计时器超时后没有收到返回的确认ACK，发送端就会重新发送队列中需要重传的报文段 。

**3. 延迟应答计时器**

延迟应答也被成为捎带ACK， 这个定时器是在延迟应答的时候使用的。 为什么要延迟应答呢？ 延迟应答是为了提高网络传输的效率。
举例说明，比如服务端收到客户端的数据后， 不是立刻回ACK给客户端， 而是等一段时间(一般最大200ms)，这样如果服务端要是有数据需要发给客户端，那么这个ACK就和服务端的数据一起发给客户端了， 这样比立即回给客户端一个ACK节省了一个数据包。 

**4. 坚持定时器**

我们已经知道TCP通过让接收方指明希望从发送方接收的数据字节数（即窗口大小）来进行流量控制。如果窗口大小为 0会发生什么情况呢？这将有效地阻止发送方传送数据，直到窗口变为非0为止。接收端窗口变为非0后，就会发送一个确认ACK指明需要的报文段序号以及窗口大小。
如果这个确认ACK丢失了，则双方就有可能因为等待对方而使连接终止：接收方等待接收数据（因为它已经向发送方通告了一个非0的窗口），而发送方在等待允许它继续发送数据的窗口更新。为防止这种死锁情况的发生，发送方使用一个坚持定时器 (persist timer)来周期性地向接收方查询，以便发现窗口是否已增大。这些从发送方发出的报文段称为窗口探查 (window probe)。 

**5. 保活定时器**

如果长时间客户端和服务端没有数据交换，那么就需要验证这个TCP链接是否还需要继续保持，那么就设定一个定时器，超时就认为TCP链接可以断开了。真正的实现还是需要自己实现心跳包

**6. FIN_WAIT_2**

**7. TIME_WAIT**

主要是为了保证TCP可以正常完成挥手的过程。在最后客户端向服务端发送ACK的时候，有可能会因为网络延迟或者丢失导致服务端重发FIN来断开TCP连接，这个时候如果客户端已经关闭，那么就会造成服务端不断的发送FIN，这就造成了服务器的资源浪费。



#### 9.4 TCP通信中可能出现的异常问题

##### 01 试图与一个不存在的端口建立连接
服务器端口还没有监听，我们的客户端就调用connect，试图与其建立连接。这是会发生什么呢？没
错，这符合触发发送**RST**分节的条件，目的为某端口的SYN分节到达，而端口没有监听，那么内核会立
即响应一个RST，表示出错。客户端TCP收到这个RST之后则放弃这次连接的建立，并且返回给应用程序
一个错误。正如上面所说的，建立连接的过程对应用程序来说是不可见的，这是操作系统帮我们来完成
的，所以即使进程没有启动，也可以响应客户端。

##### 02 试图与一个不存在的主机上面的某端口建立连接

这也是一种比较常见的情况，当某台服务器主机宕机了，而客户端并不知道，仍然尝试去与其建立连
接。根据上面的经验，这次主机已经处于未启动状态，操作系统也帮不上忙了，那么也就是连RST也不
能响应给客户端，此时服务器端是一种完全没有响应的状态。那么此时客户端的TCP会怎么办呢？据书
上介绍，如果客户端TCP没有得到任何响应，那么等待6s之后再发一个SYN，若无响应则等待24s再发一
个，若总共等待了75s后仍未收到响应就会返回ETIMEDOUT错误。这是TCP建立连接自己的一个保护机
制，但是我们要等待75s才能知道这个连接无法建立，对于我们所有服务来说都太长了。更好的做法是
在代码中给connect设置一个超时时间，使它变成我们可控的，让等待时间在毫秒级还是可以接收的。

##### 03 Server进程被阻塞

由于某些情况，服务器端进程无法响应任何请求，比如所在主机的硬盘满了，导致进程处于完全阻塞，
通常我们测试时会用gdb模拟这种情况。上面提到过，建立连接的过程对应用程序是不可见的，那么，
这时连接可以正常建立。当然，客户端进程也可以通过这个连接给服务器端发送请求，服务器端TCP会
应答ACK表示已经收到这个分节（这里的收到指的是数据已经在内核的缓冲区里准备好，由于进程被阻
塞，无法将数据从内核的缓冲区复制到应用程序的缓冲区），但永远不会返回结果。

##### 04 我们杀死server

这是线上最常见的操作，当一个模块上线时，OP同学总是会先把旧的进程杀死，然后再启动新的进程。那么在这个过程中TCP连接发生了什么呢。在进程正常退出时会自动调用close函数来关闭它所打开的文件描述符，这相当于服务器端来主动关闭连接——会发送一个FIN分节给客户端TCP；客户端要做的就是配合对端关闭连接，TCP会自动响应一个ACK，然后再由客户端应用程序调用close函数，也就是我们上面所描述的关闭连接的4次挥手过程。接下来，客户端还需要定时去重连，以便当服务器端进程重新启动好时客户端能够继续与之通信。

当然，我们要保证客户端随时都可以响应服务器端的断开连接请求，就必须不能让客户端进程再任何时刻阻塞在任何其他的输入上面。比如，书上给的例子是客户端进程会阻塞在标准输入上面，这时如果服务器端主动断开连接，显然客户端不能立刻响应，因为它还在识图从标准输入读一段文本……当然这在实际中很少遇到，如果有多输入源这种情况的话开通通常会用类似select功能的函数来处理，可以同时监控多个输入源是否准备就绪，可以避免上述所说的不能立即响应对端关闭连接的情况。

##### 05 Server进程所在的主机关机

实际上这种情况不会带来什么更坏的后果。在系统关闭时，init进程会给所有进程发送SIGTERM信号，等待一段时间（5~20秒），然后再给所有仍在运行的进程发送SIGKILL信号。当服务器进程死掉时，会关闭所有文件描述符。带来的影响和上面杀死server相同。

##### 06 Server进程所在的主机宕机

这是我们线上另一种比较常见的状况。即使宕机是一个小概率事件，线上几千台服务器动不动一两台挂
掉也是常有的事。主机崩溃不会像关机那样会预先杀死上面的进程，而是突然性的。那么此时我们的客
户端准备给服务器端发送一个请求，它由write写入内核，由TCP作为一个分节发出，随后客户阻塞于
read的调用（等待接收结果）。对端TCP显然不会响应这个分节，因为主机已经挂掉，于是客户端TCP
持续重传分节，试图从服务器上接收一个ACK，然而服务器始终不能应答，重传数次之后，大约4~10分
钟才停止，之后返回一个ETIMEDOUT错误。
这样尽管最后还是知道对方不可达，但是很多时候我们希望比等待4~10分钟更快的知道这个结果。可以
为read设置一个超时时间，就得到了一个较好的解决方法。但是这样还是需要等待一个超时时间，事实
上TCP为我们提供了更好的方法，用SO_KEEPALIVE的套接字选项——相当于心跳包，每隔一段时间给
对方发送一个心跳包，当对方没有响应时会一更短的时间间隔发送，一段时间后仍然无响应的话就断开
这个连接。

##### 07 服务器进程所在的主机宕机后重启

在客户端发出请求前，服务器端主机经历了宕机——重启的过程。当客户端TCP把分节发送到服务器端
所在的主机，服务器端所在主机的TCP丢失了崩溃前所有连接信息，即TCP收到了一个根本不存在连接
上的分节，所以会响应一个RST分节。如果开发的代码足够健壮的话会试图重新建立连接，或者把这个
请求转发给其他服务器。

#### 9.5 close和shutdown的区别

- shutdown()函数可以选择关闭全双工连接的读通道或者写通道；close()是关闭全双工连接的读写通道，也就是关闭连接；

- close()函数会释放套接字占用的文件描述符，而shutdown()不会释放占用的文件描述符。

  > 所以即使调用shutdown()关闭连接，也仍然要调用close()来释放连接占用的文件描述符。调用close()后将该socket的文件描述符减一，如果为0，就释放文件占用的内存。 

## 5. 各种协议介绍

- ICMP协议： 因特网控制报文协议。它是TCP/IP协议族的一个子协议，用于在IP主机、路由器之间传递控制消息。
- TFTP协议： 是TCP/IP协议族中的一个用来在客户机与服务器之间进行简单文件传输的协议，提供不复杂、开销不大的文件传输服务。
- HTTP协议： 超文本传输协议，是一个属于应用层的面向对象的协议，由于其简捷、快速的方式，适用于分布式超媒体信息系统。
- NAT协议：网络地址转换属接入广域网(WAN)技术，是一种将私有（保留）地址转化为合法IP地址的转换技术，
- DHCP协议：动态主机配置协议，是一种让系统得以连接到网络上，并获取所需要的配置参数手段，使用UDP协议工作。具体用途：给内部网络或网络服务供应商自动分配IP地址，给用户或者内部网络管理员作为对所有计算机作中央管理的手段。






## 6. 路由器、网关、交换机的用途

1）交换机
在计算机网络系统中，交换机是针对共享工作模式的弱点而推出的。交换机拥有一条高带宽的背部总线和内部交换矩阵。交换机的所有的端口都挂接在这条背部总线上，当控制电路收到数据包以后，处理端口会查找内存中的地址对照表以确定目的MAC（网卡的硬件地址）的NIC（网卡）挂接在哪个端口上，通过内部 交换矩阵迅速将数据包传送到目的端口。目的MAC若不存在，交换机才广播到所有的端口，接收端口回应后交换机会“学习”新的地址，并把它添加入内部地址表 中。
交换机工作于OSI参考模型的第二层，即数据链路层。交换机内部的CPU会在每个端口成功连接时，通过ARP协议学习它的MAC地址，保存成一张 ARP表。在今后的通讯中，发往该MAC地址的数据包将仅送往其对应的端口，而不是所有的端口。因此，交换机可用于划分数据链路层广播，即冲突域；但它不 能划分网络层广播，即广播域。
交换机被广泛应用于二层网络交换，俗称“二层交换机”。
交换机的种类有：二层交换机、三层交换机、四层交换机、七层交换机分别工作在OSI七层模型中的第二层、第三层、第四层盒第七层，并因此而得名。

2）路由器
路由器（Router）是一种计算机网络设备，提供了路由与转送两种重要机制，可以决定数据包从来源端到目的端所经过 的路由路径（host到host之间的传输路径），这个过程称为路由；将路由器输入端的数据包移送至适当的路由器输出端(在路由器内部进行)，这称为转 送。路由工作在OSI模型的第三层——即网络层，例如网际协议。
路由器的一个作用是连通不同的网络，另一个作用是选择信息传送的线路。 路由器与交换器的差别，路由器是属于OSI第三层的产品，交换器是OSI第二层的产品(这里特指二层交换机)。

3）网关
网关（Gateway），网关顾名思义就是连接两个网络的设备，区别于路由器（由于历史的原因，许多有关TCP/IP 的文献曾经把网络层使用的路由器（Router）称为网关，在今天很多局域网采用都是路由来接入网络，因此现在通常指的网关就是路由器的IP），经常在家 庭中或者小型企业网络中使用，用于连接局域网和Internet。 网关也经常指把一种协议转成另一种协议的设备，比如语音网关。
在传统TCP/IP术语中，网络设备只分成两种，一种为网关（gateway），另一种为主机（host）。网关能在网络间转递数据包，但主机不能 转送数据包。在主机（又称终端系统，end system）中，数据包需经过TCP/IP四层协议处理，但是在网关（又称中介系 统，intermediate system）只需要到达网际层（Internet layer），决定路径之后就可以转送。在当时，网关 （gateway）与路由器（router）还没有区别。
在现代网络术语中，网关（gateway）与路由器（router）的定义不同。网关（gateway）能在不同协议间移动数据，而路由器（router）是在不同网络间移动数据，相当于传统所说的IP网关（IP gateway）。
网关是连接两个网络的设备，对于语音网关来说，他可以连接PSTN网络和以太网，这就相当于VOIP，把不同电话中的模拟信号通过网关而转换成数字信号，而且加入协议再去传输。在到了接收端的时候再通过网关还原成模拟的电话信号，最后才能在电话机上听到。
对于以太网中的网关只能转发三层以上数据包，这一点和路由是一样的。而不同的是网关中并没有路由表，他只能按照预先设定的不同网段来进行转发。网关最重要的一点就是端口映射，子网内用户在外网看来只是外网的IP地址对应着不同的端口，这样看来就会保护子网内的用户。

**总结**
**1. 交换机的作用：**交换机只有转发的功能，他的每个端口并不具有MAC地址，但是他的内部保存了一张MAC缓存表，每一个接口对应的MAC地址会保存在表里，当有数据来了以后，先查找MAC缓存表是否有对应的接口，如果有直接向这个端口转发，如果没有就通过广播的方式来查找哪个端口对应着目标MAC地址，查到后转发数据并把MAC地址对应的端口放到MAC缓存表里面。<font color=blue>**MAC 头部的作用就是将包送达路由器**</font>

**2. 路由器的作用：**
在网络包传输的过程中，**源 IP 和目标 IP 始终是不会变的，一直变化的是 MAC 地址**，因为需要 MAC 地址在以太网内进行**两个设备**之间的包传输。

## 7. 什么是粘包

可能会发现：如果客户端连续不断的向服务端发送数据包时，服务端接收的数据会出现两个数据包粘在一起的情况。

1. TCP 是基于字节流的，虽然应用层和 TCP 传输层之间的数据交互是大小不等的数据块，但是 TCP 把这些数据块仅仅看成一连串无结构的字节流，没有边界；
2. 从 TCP 的帧结构也可以看出，在 TCP 的首部没有表示数据长度的字段。

基于上面两点，在使用 TCP 传输数据时，才有粘包或者拆包现象发生的可能。一个数据包中包含了发送端发送的两个数据包的信息，这种现象即为粘包。

接收端收到了两个数据包，但是这两个数据包要么是不完整的，要么就是多出来一块，这种情况即发生了拆包和粘包。拆包和粘包的问题导致接收端在处理的时候会非常困难，因为无法区分一个完整的数据包。

## 8. TCP 黏包是怎么产生的？

- **发送方产生粘包**

采用 TCP 协议传输数据的客户端与服务器经常是保持一个长连接的状态（一次连接发一次数据不存在粘包），双方在连接不断开的情况下，可以一直传输数据。但当发送的数据包过于的小时，那么 TCP 协议默认的会启用 Nagle 算法，将这些较小的数据包进行合并发送（缓冲区数据发送是一个堆压的过程）；这个合并过程就是在发送缓冲区中进行的，也就是说数据发送出来它已经是粘包的状态了。

- **接收方产生粘包**

接收方采用 TCP 协议接收数据时的过程是这样的：数据到接收方，从网络模型的下方传递至传输层，传输层的 TCP 协议处理是将其放置接收缓冲区，然后由应用层来主动获取（C 语言用 recv、read 等函数）；这时会出现一个问题，就是我们在程序中调用的读取数据函数不能及时的把缓冲区中的数据拿出来，而下一个数据又到来并有一部分放入的缓冲区末尾，等我们读取数据时就是一个粘包。（放数据的速度 > 应用层拿数据速度）

## 9.  怎么解决拆包和粘包？

分包机制一般有两个通用的解决方法：

1. 特殊字符控制；
2. 在包头首都添加数据包的长度。

如果使用 netty 的话，就有专门的编码器和解码器解决拆包和粘包问题了。

tips：UDP 没有粘包问题，但是有丢包和乱序。不完整的包是不会有的，收到的都是完全正确的包。传送的数据单位协议是 UDP 报文或用户数据报，发送的时候既不合并，也不拆分。

## 10. 什么是数字签名？

为了避免数据在传输过程中被替换，比如黑客修改了你的报文内容，但是你并不知道，所以我们让发送端做一个数字签名，把数据的摘要消息进行一个加密，比如 MD5，得到一个签名，和数据一起发送。然后接收端把数据摘要进行 MD5 加密，如果和签名一样，则说明数据确实是真的。

## 11. 什么是数字证书？

对称加密中，双方使用公钥进行解密。虽然数字签名可以保证数据不被替换，但是数据是由公钥加密的，如果公钥也被替换，则仍然可以伪造数据，因为用户不知道对方提供的公钥其实是假的。所以为了保证发送方的公钥是真的，CA 证书机构会负责颁发一个证书，里面的公钥保证是真的，用户请求服务器时，服务器将证书发给用户，这个证书是经由系统内置证书的备案的。

## 12. 什么是对称加密和非对称加密？

对称密钥加密是指加密和解密使用同一个密钥的方式，这种方式存在的最大问题就是密钥发送问题，即如何安全地将密钥发给对方。

非对称加密指使用一对非对称密钥，即：公钥和私钥，公钥可以随意发布，但私钥只有自己知道。发送密文的一方使用对方的公钥进行加密处理，对方接收到加密信息后，使用自己的私钥进行解密。

由于非对称加密的方式不需要发送用来解密的私钥，所以可以保证安全性。但是和对称加密比起来，它非常的慢，所以我们还是要用对称加密来传送消息，但对称加密所使用的密钥我们可以通过非对称加密的方式发送出去。

## 13. 服务器出现大量close_wait的连接的原因以及解决方法

close_wait状态是在TCP四次挥手的时候收到FIN但是没有发送自己的FIN时出现的，服务器出现大量close_wait状态的原因有两种：

- 服务器内部业务处理占用了过多时间，都没能处理完业务；或者还有数据需要发送；或者服务器的业务逻辑有问题，没有执行close()方法 
- 服务器的父进程派生出子进程，子进程继承了socket，收到FIN的时候子进程处理但父进程没有处理该信号，导致socket的引用不为0无法回收

处理方法：

- 停止应用程序
- 修改程序里的bug

## 14. TIME_WAIT出现在哪个阶段，并发量大的情况下TIME_WAIT同时大量存在有什么措施

- 降低TIME_WAIT的等待时间；
- 设置处于TIME_WAIT的端口可重用



## <font color=red> 15. IP协议</font>

### 1. IP地址的分类

A类地址：以0开头，   第一个字节范围：1~126（1.0.0.0 - 126.255.255.255）；

B类地址：以10开头，  第一个字节范围：128~191（128.0.0.0 - 191.255.255.255）；

C类地址：以110开头， 第一个字节范围：192~223（192.0.0.0 - 223.255.255.255）；

D类地址：以1110开头，第一个字节范围：224~239（224.0.0.0 - 239.255.255.255）；（作为多播使用）

E类地址：保留

其中A、B、C是基本类，D、E类作为多播和保留使用。

以下是留用的内部私有地址：

A类 10.0.0.0--10.255.255.255

B类 172.16.0.0--172.31.255.255

C类 192.168.0.0--192.168.255.255

IP地址与子网掩码相与得到网络号：

ip       : 192.168.2.110

&

Submask : 255.255.255.0

\----------------------------

网络号   ：192.168.2  .0

注:主机号，全为0的是网络号（例如：192.168.2.0），主机号全为1的为广播地址（192.168.2.255）

### 2. 为什么有了MAC地址还需要IP地址

mac地址就好像个人的身份证号，人的身份证号和人户口所在的城市，出生的日期有关，但是和人所在的位置没有关系，人是会移动的，知道一个人的身份证号，并不能找到它这个人，mac地址类似，它是和设备的生产者，批次，日期之类的关联起来，知道一个设备的mac，并不能在网络中将数据发送给它，除非它和发送方的在同一个网络内。

所以要实现机器之间的通信，我们还需要有ip地址的概念，ip地址表达的是当前机器在网络中的位置，类似于城市名+道路号+门牌号的概念。通过ip层的寻址，我们能知道按何种路径在全世界任意两台Internet上的的机器间传输数据。

mac地址通常是不变的，ip地址是可变的，尤其是移动设备，ip地址会经常变更。

mac地址的设计不携带设备在网络中的位置信息，想要通过mac地址通信，我们得在所有的设备上维护一张很大的表，记录所有mac地址路由在当前位置的的下一跳，这显然是不合理的。



## <font color=red>16. HTTP协议</font>

### 1. HTTP的概念

**HTTP 是一个在计算机世界里专门在「两点」之间「传输」文字、图片、音频、视频等「超文本」数据的「约定和规范」。**

### 2. HTTP长连接和短链接

- 短链接：客户端和服务器每进行一次 HTTP 操作，就建立一次连接，任务结束就中断连接。
- 长连接： 在使用长连接的情况下，当一个网页打开完成后，客户端和服务器之间用于传输 HTTP 数据的 TCP 连接不会关闭，客户端再次访问这个服务器时，会继续使用这一条已经建立的连接。

> 应用场景
>
> - 长连接：常用于p2p通信。
> - 短链接：常用于一点对多通信，c/s通信 

### 3.  HTTP常见状态码

常见的包括：

- 2XX：类状态码表示服务器**成功**处理了客户端的请求

  200 - 请求成功

  **204 No Content**请求成功，但是没有body数据。

  **206 Partial Content**请求成功，但是body数据只是包含部分资源。

- 3xx：类状态码表示客户端请求的资源发送了变动，需要客户端用新的 URL 重新发送请求获取资源，也就是**重定向**。

  301 - 资源（网页等）被永久转移到其它URL

  **302 Moved Permanently**表示临时重定向，说明请求的资源还在，但暂时需要用另一个 URL 来访问。

  **304 Not Modified**不具有跳转的含义，表示资源未修改，重定向已存在的缓冲文件，也称缓存重定向，用于缓存控制。

- 4xx：类状态码表示客户端发送的**报文有误**，服务器无法处理，也就是错误码的含义。

  400 - 请求无效

  403 - 禁止访问

  404 - 请求的资源（网页等）不存在

- 5xx：类状态码表示客户端请求报文正确，但是**服务器处理时内部发生了错误**，属于服务器端的错误码。

  500 - 内部服务器错误

  **500 Internal Server Error**与 400 类型，是个笼统通用的错误码，服务器发生了什么错误，我们并不知道。

  **501 Not Implemented**表示客户端请求的功能还不支持，类似“即将开业，敬请期待”的意思。

  **502 Bad Gateway**通常是服务器作为网关或代理时返回的错误码，表示服务器自身工作正常，访问后端服务器发生了错误。

  **503 Service Unavailable**表示服务器当前很忙，暂时无法响应服务器，类似“网络服务正忙，请稍后重试”的意思。

### 4. HTTP常见字段

- *Host*：客户端发送请求时，用来指定服务器的域名。
- *Content-Length 字段*：服务器在返回数据时，会有 `Content-Length` 字段，表明本次回应的数据长度。
- *Connection 字段*：`Connection` 字段最常用于客户端要求服务器使用 TCP 持久连接，以便其他请求复用。
- *Content-Type 字段*：`Content-Type` 字段用于服务器回应时，告诉客户端，本次数据是什么格式。
- *Content-Encoding 字段*：`Content-Encoding` 字段说明数据的压缩方法。表示服务器返回的数据使用了什么压缩格式

### 5. GET和POST的区别

1. GET方法不会修改服务器上的资源，它的查询是没有副作用的，而POST有可能会修改服务器上的资源 

   > 举个例子：我们平时访问网站，制定一个URL就会收到服务器响应的数据，但是这个请求本身没有对服务器造成更改，这就是GET方法。如果我们在一个朋友圈下面提交自己的评论，别人再去看这个朋友圈就会看到你的评论，也就相当于对服务器端的内容做出了改变，这就是POST方法。

4. GET把请求附在url上，而POST把参数附在http包的包体中 

3. 一般对get方法所提交的url长度有限制，而对post方法没有限度

4. get产生一个tcp包，post产生两个tcp数据包。post先发header，服务器响应100 continue， 浏览器再发data，服务器响应200（返回数据）。 

6. POST 比GET 更安全，因为参数不会被保存在浏览器历史或web服务器日志中。

### 6. Cookie技术

>  Cookie主要是为了解决HTTP无状态问题而产生的，并且cookie存储在客户端

- 客户端首次向服务器发出请求时，服务器会针对客户端生成一个cookie并添加到响应中，客户端在接收到响应数据后会把cookie保存到本地
- 客户端再次向服务端发出请求的时候，就会再请求报文中添加cookie，这样服务器根据请求中的cookie就可以知道我们的客户端的一个状态，也就弥补了HTTP 无状态的问题。

> cookie和session的区别
>
> - cookie是保存在客户端；session是保存在服务器端

### 7. HTTP和HTTPS的区别

- HTTP 是超文本传输协议，信息是明文传输，存在安全风险的问题。HTTPS 则解决 HTTP 不安全的缺陷，在 TCP 和 HTTP 网络层之间加入了 SSL/TLS 安全协议，使得报文能够加密传输。

- HTTP 连接建立相对简单， TCP 三次握手之后便可进行 HTTP 的报文传输。而 HTTPS 在 TCP 三次握手之后，还需进行 SSL/TLS 的握手过程，才可进入加密报文传输。

- HTTP 的端口号是 80，HTTPS 的端口号是 443。

- HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。

  
  
  ![img](https://mmbiz.qpic.cn/mmbiz_jpg/J0g14CUwaZfXG1113Sjm0iaOXfoOv0tlUzdWm2toFZmoutgdMlZichgjsFggJOHXg6Z09ckSyeTPpkdywfljh3uw/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



### 8. TLS的握手过程

### 9. HTTP各个版本的区别

- HTTP 0.9
  - 只支持`GET`请求方式：由于不支持其他请求方式，因此客户端是没办法向服务端传输太多的信息
  - 没有请求头概念：所以不能在请求中指定版本号，服务端也只具有返回 HTML字符串的能力
  - 不支持长连接，服务端相响应之后，立即关闭TCP连接

- HTTP 1.0

  - 请求方式新增了POST，DELETE，PUT，HEADER等方式

  - 增添了请求头和响应头的概念，在通信中指定了 HTTP 协议版本号，以及其他的一些元信息 (比如: 状态码、权限、缓存、内容编码)

  - 扩充了传输内容格式，图片、音视频资源、二进制等都可以进行传输

    >  在这个版本主要的就是对请求和响应的元信息进行了扩展，客户端和服务端有更多的获取当前请求的所有信息，进而更好更快的处理请求相关内容。

- HTTP 1.1

  - 新增connection字段，支持长连接
  - 管道化
  - 支持缓存处理
  - 支持断点传输

- HTTP2.0

  - 二进制分帧：HTTP 1.x 的解析是基于文本，HTTP 2之后将所有传输的信息分割为更小的消息和帧，并对它们采用二进制格式的编码，提高传输效率
  - 多路复用：在共享TCP连接的基础上同事发送请求和响应
  - 头部压缩
  - 服务器推送：服务器可以额外的向客户端推送资源，而无需客户端明确请求

### 10. HTTP与HTTPS交互的过程




## <font color=red>17. ARP地址解析协议(IP->MAC)</font>

- 1：首先，每个主机都会在自己的ARP缓冲区中建立一个ARP列表，以表示IP地址和MAC地址之间的对应关系。
- 2：当源主机要发送数据时，首先检查ARP列表中是否有对应IP地址的目的主机的MAC地址，如果有，则直接发送数据，如果没有，就向本网段的所有主机发送ARP数据包，该数据包包括的内容有：源主机 IP地址，源主机MAC地址，目的主机的IP 地址。
- 3：当本网络的所有主机收到该ARP数据包时，首先检查数据包中的IP地址是否是自己的IP地址，如果不是，则忽略该数据包，如果是，则首先从数据包中取出源主机的IP和MAC地址写入到ARP列表中，如果已经存在，则覆盖，然后将自己的MAC地址写入ARP响应包中，告诉源主机自己是它想要找的MAC地址。
- 4：源主机收到ARP响应包后。将目的主机的IP和MAC地址写入ARP列表，并利用此信息发送数据。如果源主机一直没有收到ARP响应数据包，表示ARP查询失败。

## <font color=red>18. DNS域名解析工作原理(URL->IP)</font>

DNS 中的域名都是用**句点**来分隔的，比如 `www.server.com`，这里的句点代表了不同层次之间的**界限**。在域名中，**越靠右**的位置表示其层级**越高**。根域是在最顶层，它的下一层就是 com 顶级域，再下面是 server.com。
所以域名的层级关系类似一个树状结构：

- 根 DNS 服务器
- 顶级域 DNS 服务器（com）
- 权威 DNS 服务器（server.com）

![img](https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZdCwxNydn5YuT0s7aLuqWCvN6F6eZ2vAU04o8gh1mJ6l7ovc7wsCvTVMvCFHyHqfsRUKtWYnblsCA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



**域名解析的过程**
(1) 在输入域名后, 先查找自己主机对应的域名服务器，域名服务器先查找自己的数据库中的数据。如果存在对应的IP地址就直接返回。
(2) 如果没有， 就向根域名服务器进行查找，如果没有就继续向下面顶级域和权威DNS服务器迭代查询，直到找到这个域名的IP地址并返回。
(3) 在找到URL对应的IP地址以后就可以开始通信了。



![img](https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZdCwxNydn5YuT0s7aLuqWCv5bBPibRf9nk4wIb6J3jP62L6NEmPk3HicMUgf8VatcBicynP6BKLeT6GQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



> **DNS缓存的了解**
>
> 目的是为了提高查询效率，减轻服务器的负荷和减少因特网上的 DNS 查询报文数量。
>
> 由于名字到地址的绑定并不经常改变，为保持高速缓存中的内容正确，域名服务器应为每项内容设置计时器并处理超过合理时间的项（例如：每个项目两天）。当域名服务器已从缓存中删去某项信息后又被请求查询该项信息，就必须重新到授权管理该项的域名服务器绑定信息。当权限服务器回答一个查询请求时，在响应中都指明绑定有效存在的时间值。增加此时间值可减少网络开销，而减少此时间值可提高域名解析的正确性。



## 19. 在浏览器中输入一个url后执行的全部过程

- 客户端浏览器通过DNS解析到url的的IP地址，通过这个IP地址找到客户端到服务器的路径。客户端浏览器发起一个HTTP会话到这个IP地址，然后通过TCP进行封装数据包，输入到网络层。
- 在客户端的传输层，把HTTP会话请求分成报文段，添加源和目的端口，与服务器进行交换，服务器把相应的请求返回给客户端。然后使用IP层的IP地址查找目的端。
- 客户端的网络层，主要做的是通过查找路由表确定如何到达服务器，期间可能经过多个路由器，这些都是由路由器来完成的工作。
- 客户端的链路层，包通过链路层发送到路由器，通过ARP协议查找给定IP地址的MAC地址，然后发送ARP请求查找目的地址，如果得到回应后就可以使用ARP的请求应答交换的IP数据包现在就可以传输了，然后发送IP数据包到达服务器的地址。

> **在浏览器输入URL地址到显示的过程**
>
> 1. **DNS 解析：浏览器查询 DNS，获取域名对应的 IP 地址**（具体过程包括浏览器搜索自身的 DNS 缓存、搜索操作系统的 DNS 缓存、读取本地的 Host 文件和向本地 DNS 服务器进行查询等。对于向本地 DNS 服务器进行查询，如果要查询的域名包含在本地配置区域资源中，则返回解析结果给客户机，完成域名解析(此解析具有权威性)；如果要查询的域名不由本地 DNS 服务器区域解析，但该服务器已缓存了此网址映射关系，则调用这个 IP 地址映射，完成域名解析（此解析不具有权威性）。如果本地域名服务器并未缓存该网址映射关系，那么将根据其设置发起递归查询或者迭代查询）
> 2. TCP 连接：浏览器获得域名对应的 IP 地址以后，浏览器向服务器请求建立链接，发起三次握手；
> 3. 发送 HTTP 请求：TCP 连接建立起来后，浏览器向服务器发送 HTTP 请求；
> 4. 服务器处理请求并返回 HTTP 报文：服务器接收到这个请求，并根据路径参数映射到特定的请求处理器进行处理，并将处理结果及相应的视图返回给浏览器；
> 5. 浏览器解析渲染页面：浏览器解析并渲染视图，若遇到对 js 文件、css 文件及图片等静态资源的引用，则重复上述步骤并向服务器请求这些资源；浏览器根据其请求到的资源、数据渲染页面，最终向用户呈现一个完整的页面。
> 6. 连接结束。

## 20. 网络中两台主机通信的过程

> 1. [主机通信过程](https://blog.csdn.net/qq_28657577/article/details/82258141)

**1. 在同一个局域网中**

直接走二层交换机进行通信

**2. 不在同一个局域网中**

需要经过路由器进行通信



## 21. TCP相关开放性问题

### 1. TCP性能瓶颈

当连续接受三个重复的ACK时，发生超时重传，这时候发送端的发送窗口就会阻塞，不能向右继续滑动，也就限制了后面的数据的发送。这就是TCP的性能瓶颈。

> 如何解决？
>
> 使用QUIC技术解决TCP性能瓶颈问题

### 2. TCP连接文件描述符耗尽怎么办

- 客户端最大tcp连接数位65536 - 1 = 65535 port 0 特殊含义
- 服务器的最大tcp连接数， {local ip, local port,remote ip,remote port}
- server最大tcp连接数：server通常固定在某个本地端口上监听，等待client的连接请求。不考虑地址重
  用（unix的SO_REUSEADDR选项）的情况下，即使server端有多个ip，本地监听端口也是独占的，因此
  server端tcp连接4元组中只有remote ip（也就是client ip）和remote port（客户端port）是可变的，
  因此最大tcp连接为客户端ip数×客户端port数，对IPV4，不考虑ip地址分类等因素，最大tcp连接数约为
  2的32次方（ip数）×2的16次方（port数），也就是server端单机最大tcp连接数约为2的48次方。
  当系统的文件描述符耗尽的时候，我们要做一些处理：
  - **方式一：**在拿到大于或者等于0的connfd(连接文件描述符)之后，非阻塞的epoll/select一下，看看这个fd是否可写。正常情况下epoll/select会返回writable，表明connfd可用。如果epoll/select返回错误，表示这个fd有问题，应该立刻关闭连接
  - **方式二：**设置一个最大连接数，当连接超过设定值时，直接关闭当前这个fd 

### 3. TCP的7种定时器

> 1. 建立连接定时器(connection-establishment timer)
> 2. 重传定时器(retransmission timer)
> 3. 延迟应答定时器(delayed ACK timer)
> 4. 坚持定时器(persist timer)
> 5. 保活定时器(keepalive timer)
> 6. FIN_WAIT_2定时器(FIN_WAIT_2 timer)
> 7. TIME_WAIT定时器 (TIME_WAIT timer, 也叫2MSL timer) 

# 三、OS高频

> 1. [操作系统常见面试题](https://www.cnblogs.com/inception6-lxc/p/9073983.html)
> 2. [常见操作系统面试题]([https://blog.csdn.net/qq_39207948/article/details/80677811?ops_request_misc=%7B%22request_id%22:%22158338765919726867828830%22,%22scm%22:%2220140713.130056874..%22%7D&request_id=158338765919726867828830&biz_id=0&utm_source=distribute.pc_search_result.none-task](https://blog.csdn.net/qq_39207948/article/details/80677811?ops_request_misc={"request_id":"158338765919726867828830","scm":"20140713.130056874.."}&request_id=158338765919726867828830&biz_id=0&utm_source=distribute.pc_search_result.none-task))

## 1. 线程、进程、协程

> 1.同步和互斥的概念：
>
> **同步就是两个线程是有先后关系的，例如B必须在A之后执行，A未完成的情况下，B就不可以执行。**
> **互斥就是A和B无论先后，但是需要满足一点就是A执行的时候B不可以执行，B执行的时候A不可以执行**



### **1.1 概念**：

> **进程**是**具有独立功能程序在某个数据集合上的一次执行过程**。**线程**是**进程内的一个执行实体或执行单元**。

- **进程**是具有独立功能程序在某个数据集合上的一次执行过程。
  - 各个进程之间相互独立，实现了操作系统的并发。
- **线程**是进程内的一个执行实体或执行单元。
  - 线程是操作系统可识别的最小执行和调度单位。每个线程都独自占用一个虚拟处理器：独自的寄存器组，指令计数器和处理器状态。每个线程完成不同的任务，但是共享同一地址空间（也就是同样的动态内存，映射文件，目标代码等等），打开的文件队列和其他内核资源。
  - 线程之间是相互影响的，一个线程的崩溃可能导致其所在进程的崩溃，进而导致该进程下所有线程的崩溃。

### **1.2 线程和进程区别**

- 一个线程只能属于一个进程，而一个进程可以有多个线程，但至少有一个线程。线程依赖于进程而存在。
- 进程在执行过程中拥有独立的内存单元，而多个线程共享进程的内存。（资源分配给进程，同一进程的所有线程共享该进程的所有资源。同一进程中的多个线程共享代码段（代码和常量），数据段（全局变量和静态变量），扩展段（堆存储）。但是每个线程拥有自己的栈段，栈段又叫运行时段，用来存放所有局部变量和临时变量。）
- 进程是资源分配的最小单位，线程是CPU调度的最小单位；
- **系统开销：** 
  - 由于在**创建或撤消进程时**，系统都要为之分配或回收资源。因此，操作系统所付出的开销将显著地大于在创建或撤消线程时的开销。
  - 类似地，在**进行进程切换时**，涉及到整个当前进程CPU环境的保存以及新被调度运行的进程的CPU环境的设置。
  - 而线程切换只须保存和设置少量寄存器的内容，并不涉及存储器管理方面的操作。
  - 因此进程切换的开销也远大于线程切换的开销。
- **通信**：由于同一进程中的多个线程具有相同的地址空间，致使它们之间的同步和通信的实现，也变得比较容易。进程间通信IPC，线程间可以直接读写进程数据段（如全局变量）来进行通信——需要进程同步和互斥手段的辅助，以保证数据的一致性。在有的系统中，线程的切换、同步和通信都无须操作系统内核的干预
- 进程编程调试简单可靠性高，但是创建销毁开销大；线程正相反，开销小，切换速度快，但是编程调试相对复杂。
- 进程间不会相互影响 ；一个线程挂掉可能将导致整个进程挂掉
- 进程适应于多核、多机分布；线程适用于多核

### **1.3 进程间通信的方式**

**<font color=blue>进程间通信主要包括管道、系统IPC（包括消息队列、信号量、信号、共享内存等）、以及套接字socket</font>**。

#### 1.3.1 <font color=blue>管道</font>

管道是一种半双工的通信方式，数据只能单向流动。

- **匿名管道**：只能父子进程之间通信
- **有名管道** (namedpipe) ： 有名管道也是半双工的通信方式，但是它允许无亲缘关系进程间的通信。
- **缺点**：效率比较低，不适合进程间频繁地交换数据。

#### 1.3.2 <font color=blue>信号量</font>

信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。<font color=red>信号量既可以实现进程间的互斥，也可以实现进程间的同步</font>.

信号量表示资源的数量，控制信号量的方式有两种原子操作：

- 一个是 **P 操作**，这个操作会把信号量减去 -1，相减后如果信号量 < 0，则表明资源已被占用，进程需阻塞等待；相减后如果信号量 >= 0，则表明还有资源可使用，进程可正常继续执行。
- 另一个是 **V 操作**，这个操作会把信号量加上 1，相加后如果信号量 <= 0，则表明当前有阻塞中的进程，于是会将该进程唤醒运行；相加后如果信号量 > 0，则表明当前没有阻塞中的进程；

P 操作是用在进入共享资源之前，V 操作是用在离开共享资源之后，这两个操作是必须成对出现的。

![img](https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZckxn1SzJ697nE1m1wJzmPQ5UocfiaqAGx3FLcc1c0u29F6vL79KiaERHUibna0Fw6OvoI7sO72IKF8Q/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

具体的过程如下：

- 进程 A 在访问共享内存前，先执行了 P 操作，由于信号量的初始值为 1，故在进程 A 执行 P 操作后信号量变为 0，表示共享资源可用，于是进程 A 就可以访问共享内存。
- 若此时，进程 B 也想访问共享内存，执行了 P 操作，结果信号量变为了 -1，这就意味着临界资源已被占用，因此进程 B 被阻塞。
- 直到进程 A 访问完共享内存，才会执行 V 操作，使得信号量恢复为 0，接着就会唤醒阻塞中的线程 B，使得进程 B 可以访问共享内存，最后完成共享内存的访问后，执行 V 操作，使信号量恢复到初始值 1。

可以发现，信号初始化为 `1`，就代表着是**互斥信号量**，它可以保证共享内存在任何时刻只有一个进程在访问，这就很好的保护了共享内存。

另外，在多进程里，每个进程并不一定是顺序执行的，它们基本是以各自独立的、不可预知的速度向前推进，但有时候我们又希望多个进程能密切合作，以实现一个共同的任务。

例如，进程 A 是负责生产数据，而进程 B 是负责读取数据，这两个进程是相互合作、相互依赖的，进程 A 必须先生产了数据，进程 B 才能读取到数据，所以执行是有前后顺序的。

那么这时候，就可以用信号量来实现多进程同步的方式，我们可以初始化信号量为 `0`。

![img](https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZckxn1SzJ697nE1m1wJzmPQlO6zu8K0xlLpDBbew0jVibibhVm59TQy4ibJSZKxqKsWOrcLIibZE6RAVg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

具体过程：

- 如果进程 B 比进程 A 先执行了，那么执行到 P 操作时，由于信号量初始值为 0，故信号量会变为 -1，表示进程 A 还没生产数据，于是进程 B 就阻塞等待；
- 接着，当进程 A 生产完数据后，执行了 V 操作，就会使得信号量变为 0，于是就会唤醒阻塞在 P 操作的进程 B；
- 最后，进程 B 被唤醒后，意味着进程 A 已经生产了数据，于是进程 B 就可以正常读取数据了。

可以发现，信号初始化为 `0`，就代表着是**同步信号量**，它可以保证进程 A 应在进程 B 之前执行。

#### 1.3.3 <font color=blue>消息队列</font> 

消息队列是由消息的链表，存放在内核中并由消息队列标识符标识。

- 优点：消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。
- 缺点：一是通信不及时，二是附件也有大小限制。因此消息队列不适合大数据的传输，并且消息队列也存在用户态和内核态拷贝的开销。

#### 1.3.4 信号 

信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。**Linux下的kill命令的实现机制就是信号。**

#### 1.3.5 <font color=blue>共享内存</font>

共享内存的机制，就是拿出一块虚拟地址空间来，映射到相同的物理内存中。这样这个进程写入的东西，另外一个进程马上就能看到了，都不需要拷贝来拷贝去，传来传去，大大提高了进程间通信的速度。

![img](https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZckxn1SzJ697nE1m1wJzmPQicu3anA4icCr5sY8I4CWsXBUSsGQQGlWuWgNSNJThhyNrpaourrwITQQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

- 缺点：如果多个进程同时修改同一个共享内存，很有可能就冲突了



#### 1.3.6 套接字(socket ) 

套解口也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同及其间的进程通信。

![img](https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZckxn1SzJ697nE1m1wJzmPQOIIKS58Z9r7rE99UGdDF2fHVwxY76wNCVCGVgm4Z395UibkacZTUJPw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

### **1.4 线程间通信的方式:**

- <font color=blue>临界区</font>：通过多线程的串行化来访问公共资源或一段代码，速度快，适合控制数据访问；
- <font color=blue>互斥量Synchronized/Lock(**也称为互斥锁**)</font>：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问
- <font color=blue>信号量 Semphare</font>：为控制具有有限数量的用户资源而设计的，它允许多个线程在同一时刻去访问同一个资源，但一般需要限制同一时刻访问此资源的最大线程数目。
- <font color=blue>事件(信号)，Wait/Notify</font>：通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操作

#### 1.4.1 多线程间锁机制和种类

同步的时候用一个互斥量，在访问共享资源前对互斥量进行加锁，在访问完成后释放互斥量上的锁。对
互斥量进行加锁以后，任何其他试图再次对互斥量加锁的线程将会被阻塞直到当前线程释放该互斥锁。
如果释放互斥锁时有多个线程阻塞，所有在该互斥锁上的阻塞线程都会变成可运行状态，第一个变为运
行状态的线程可以对互斥量加锁，其他线程将会看到互斥锁依然被锁住，只能回去再次等待它重新变为
可用。在这种方式下，每次只有一个线程可以向前执行。 

**Linux的4种锁机制：**

- 互斥锁：mutex，用于保证在任何时刻，都只能有一个线程访问该对象。当获取锁操作失败时，线程会
  进入睡眠，等待锁释放时被唤醒
- 读写锁：rwlock，分为读锁和写锁。处于读操作时，可以允许多个线程同时获得读操作。但是同一时刻
  只能有一个线程可以获得写锁。其它获取写锁失败的线程都会进入睡眠状态，直到写锁释放时被唤醒。
  注意：写锁会阻塞其它读写锁。当有一个线程获得写锁在写时，读锁也不能被其它线程获取；写者优先
  于读者（一旦有写者，则后续读者必须等待，唤醒时优先考虑写者）。适用于读取数据的频率远远大于
  写数据的频率的场合。
- 自旋锁：spinlock，在任何时刻同样只能有一个线程访问对象。但是当获取锁操作失败时，不会进入睡
  眠，而是会在原地自旋，直到锁被释放。这样节省了线程从睡眠状态到被唤醒期间的消耗，在加锁时间
  短暂的环境下会极大的提高效率。但如果加锁时间过长，则会非常浪费CPU资源。
- RCU：即read-copy-update，在修改数据时，首先需要读取数据，然后生成一个副本，对副本进行修
  改。修改完成后，再将老数据update成新的数据。使用RCU时，读者几乎不需要同步开销，既不需要获
  得锁，也不使用原子指令，不会导致锁竞争，因此就不用考虑死锁问题了。而对于写者的同步开销较
  大，它需要复制被修改的数据，还必须使用锁机制同步并行其它写者的修改操作。在有大量读操作，少
  量写操作的情况下效率非常高。 

#### 1.4.2 互斥机制以及互斥锁和读写锁的区别

- 互斥锁：mutex，用于保证在任何时刻，都只能有一个线程访问该对象。当获取锁操作失败时，线程会
  进入睡眠，等待锁释放时被唤醒 。

- 读写锁：rwlock， 分为读锁和写锁。处于读操作时，可以允许多个线程同时获得读操作。但是同一时刻
  只能有一个线程可以获得写锁。其它获取写锁失败的线程都会进入睡眠状态，直到写锁释放时被唤醒。
  注意：写锁会阻塞其它读写锁。当有一个线程获得写锁在写时，读锁也不能被其它线程获取；写者优先
  于读者（一旦有写者，则后续读者必须等待，唤醒时优先考虑写者）。适用于读取数据的频率远远大于
  写数据的频率的场合。

- 互斥锁和读写锁的**区别：**
  1）读写锁区分读者和写者，而互斥锁不区分
  2）互斥锁同一时间只允许一个线程访问该对象，无论读写；读写锁同一时间内只允许一个写者，但是
  允许多个读者同时读对象。 

  

### **1.5 有了进程为什么还要有线程**

**线程产生的原因：**

- 进程可以使多个程序能并发执行，以提高资源的利用率和系统的吞吐量；但是其具有一些缺点：
  1）进程在同一时间只能干一件事
  2）进程在执行的过程中如果阻塞，整个进程就会挂起，即使进程中有些工作不依赖于等待的资源，仍然不会执行。
  因此，操作系统引入了比进程粒度更小的线程，作为并发执行的基本单位，从而减少程序在并发执行时所付出的时空开销，提高并发性。

**和进程相比，线程的优势如下：**

- 从资源上来讲，线程是一种非常"节俭"的多任务操作方式。在linux系统下，启动一个新的进程必须分配给它独立的地址空间，建立众多的数据表来维护它的代码段、堆栈段和数据段，这是一种"昂贵"的多任务工作方式。
- 从切换效率上来讲，运行于一个进程中的多个线程，它们之间使用相同的地址空间，而且线程间彼此切换所需时间也远远小于进程间切换所需要的时间。
- 从通信机制上来讲，线程间方便的通信机制。对不同进程来说，它们具有独立的数据空间，要进行数据的传递只能通过进程间通信的方式进行，这种方式不仅费时，而且很不方便。线程则不然，由于同一进城下的线程之间贡献数据空间，所以一个线程的数据可以直接为其他线程所用，这不仅快捷，而且方便。
- 除以上优点外，多线程程序作为一种多任务、并发的工作方式，还有如下优点：
  1）使多CPU系统更加有效。操作系统会保证当线程数不大于CPU数目时，不同的线程运行于不同的CPU上
  2）改善程序结构。一个既长又复杂的进程可以考虑分为多个线程，成为几个独立或半独立的运行部分，这样的程序才会利于理解和修改。

> 引入进程和线程的目的是什么?
>
> 进程引入的目的：进程引入的目的是为了提高系统的资源利用率和增加系统的吞吐量。
>
> 线程引入的目的：线程引入是为了在进程的基础上节省系统的时空开销，进一步提高操作系统的并发性。
>
> 进程与线程的比较：
>
> 1. 进程是操作系统进行资源调度和独立运行的基本单位，引入线程之后，进程只是操作系统资源调度的基本单位，线程成为独立运行的基本单位。
> 2. 多个线程共享同一进程的所有资源，表现在同一进程的所有线程都具有相同的地址空间。
> 3. 创建或撤销进程时所付出的开销明显大于线程创建或撤销时所付出的时空开销。
> 4. 对于多处理机系统，对于进程而言，不管有多少处理机，该进程只能运行在一个处理机上，而对于多线程进程，可以将一个进程中的多个线程非配多个处理机上，是它们并行的执行。

### **1.6 多线程一定比多进程高效吗？**

- 不一定，因为线程间的切换也是有开销的

### **1.7 多线程和多进程各自的优点**

**多进程：**

- 由于不同的进程地址空间相互独立，所以有比较高的安全性。也具有更高的容错性
- 具有更好的多核可伸缩性，因为进程将地址空间，页表等进行了隔离，在多核的系统上可伸缩性更强

**多线程：**

- 更加高效的内存共享。多进程下内存共享不便
- 较轻的上下文切换。因为不用切换地址空间，CR3寄存器和清空TLB

### **1.8 如何让提升多线程的效率**

- 尽量使用池化技术，也就是线程池，从而不用频繁的创建，销毁线程
- 减少线程之间的同步和通信
- 通过Huge Page的方式避免产生大量的缺页异常
- 避免需要频繁共享写的数据

### 1.9 上下文切换

**什么是上下文切换呢,上下文切换时需要履行的步骤：**

1. 将前一个 CPU 的上下文（也就是 CPU 寄存器和程序计数器里边的内容）保存起来；
2. 然后加载新任务的上下文到寄存器和程序计数器；
3. 最后跳转到程序计数器所指的新位置，运行新任务。

被保存起来的上下文会存储到**系统内核**中，等待任务重新调度执行时再次加载进来。CPU 的上下文切换分三种：**进程上下文切换、线程上下文切换、中断上下文切换**。

#### 1.9.1 **进程的上下文切换**

> <font color=blue>进程切换需要分两步：</font>
>
> 1. 切换页目录、刷新TLB以使用新的地址空间；
> 2. 切换内核栈和硬件上下文（寄存器）

1. **进程上下文切换只发生在内核态中**

2. **进程的上下文切换不仅包含了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的资源。**

3. **进程上下文切换发生的场景**

   CPU时间片耗尽、资源不足、通过sleep主动挂起、优先级更高的进程进来要优先运行此进程、发生硬件中断

#### **1.9.2 线程的上下文切换**

> <font color=blue>线程在切换的过程中需要保存当前线程Id、线程状态、堆栈、寄存器状态等信息</font>

- 当属于不同的进程发生上下文切换的时候和进程之间的上下文切换相同
- 当相同进程的中的线程进行切换时，共享的资源保持不变，但是私有的数据和寄存器等不共享的数据要进行切换

### 1.10 协程

#### 1.10.1 协程的概念

协程看上去也是子程序，但执行过程中，在子程序内部可中断，然后转而执行别的子程序，在适当的时候再返回来接着执行。

#### 1.10.2 协程的优点

- 协程执行效率极高。因为子程序切换不是线程切换，而是由程序自身控制，因此，没有线程切换的开销，和多线程比，线程数量越多，协程的性能优势就越明显。

- 第二大优势就是不需要多线程的锁机制，因为只有一个线程，也不存在同时写变量冲突，在协程中控制共享资源不加锁，只需要判断状态就好了，所以执行效率比多线程高很多。

#### 1.10.3 如何使用多核CPU

在协程上利用多核CPU呢——多进程+协程，既充分利用多核，又充分发挥协程的高效率，可获得极高的性能。

## 2. 进程调度算法

> <font color=red> 先来先服务、最短作业优先、时间片轮转调度、优先级调度、多级队列</font>

**1、先来先服务**
先来先服务(FCFS)调度算法是一种最简单的调度算法，该算法既可用于作业调度，也可用于进程调度。当在作业调度中采用该算法时，每次调度都是从后备作业队列中选择一个或多个最先进入该队列的作业，将它们调入内存，为它们分配资源、创建进程，然后放入就绪队列。在进程调度中采用FCFS算法时，则每次调度是从就绪队列中选择一个最先进入该队列的进程，为之分配处理机，使之投入运行。该进程一直运行到完成或发生某事件而阻塞后才放弃处理机。

 

**2、最短作业(进程)优先**
短作业(进程)优先调度算法，是指对短作业或短进程优先调度的算法。它们可以分别用于作业调度和进程调度。短作业优先(SJF)的调度算法是从后备队列中选择一个或若干个估计运行时间最短的作业，将它们调入内存运行。而短进程优先(SPF)调度算法则是从就绪队列中选出一个估计运行时间最短的进程，将处理机分配给它，使它立即执行并一直执行到完成，或发生某事件而被阻塞放弃处理机时再重新调度。

 

**3、时间片轮转调度**
在早期的时间片轮转法中，系统将所有的就绪进程按先来先服务的原则排成一个队列，每次调度时，把CPU分配给队首进程，并令其执行一个时间片。时间片的大小从几ms到几百ms。当执行的时间片用完时，由一个计时器发出时钟中断请求，调度程序便据此信号来停止该进程的执行，并将它送往就绪队列的末尾；然后，再把处理机分配给就绪队列中新的队首进程，同时也让它执行一个时间片。这样就可以保证就绪队列中的所有进程在一给定的时间内均能获得一时间片的处理机执行时间。换言之，系统能在给定的时间内响应所有用户的请求。

**4、优先级调度**

**5、多级队列**
前面介绍的各种用作进程调度的算法都有一定的局限性。如短进程优先的调度算法，仅照顾了短进程而忽略了长进程，而且如果并未指明进程的长度，则短进程优先和基于进程长度的抢占式调度算法都将无法使用。而多级反馈队列调度算法则不必事先知道各种进程所需的执行时间，而且还可以满足各种类型进程的需要，因而它是目前被公认的一种较好的进程调度算法。在采用多级反馈队列调度算法的系统中，调度算法的实施过程如下所述：

1）应设置多个就绪队列，并为各个队列赋予不同的优先级。第一个队列的优先级最高，第二个队列次之，其余各队列的优先权逐个降低。该算法赋予各个队列中进程执行时间片的大小也各不相同，在优先权愈高的队列中，为每个进程所规定的执行时间片就愈小。例如，第二个队列的时间片要比第一个队列的时间片长一倍，第i+1个队列的时间片要比第i个队列的时间片长一倍。

2）当一个新进程进入内存后，首先将它放入第一队列的末尾，按FCFS原则排队等待调度。当轮到该进程执行时，如它能在该时间片内完成，便可准备撤离系统；如果它在一个时间片结束时尚未完成，调度程序便将该进程转入第二队列的末尾，再同样地按FCFS原则等待调度执行；如果它在第二队列中运行一个时间片后仍未完成，再依次将它放入第三队列，……，如此下去，当一个长作业(进程)从第一队列依次降到第n队列后，在第n队列便采取按时间片轮转的方式运行。

3）仅当第一队列空闲时，调度程序才调度第二队列中的进程运行；仅当第1～(i-1)队列均空时，才会调度第i队列中的进程运行。如果处理机正在第i队列中为某进程服务时，又有新进程进入优先权较高的队列(第1～(i-1)中的任何一个队列)，则此时新进程将抢占正在运行进程的处理机，即第i队列中某个正在运行的进程的时间片用完后，由调度程序选择优先权较高的队列中的那一个进程，把处理机分配给它。

 

**6、优先权调度算法**
为了照顾紧迫型作业，使之在进入系统后便获得优先处理，引入了最高优先权优先(FPF)调度算法。此算法常被用于批处理系统中，作为作业调度算法，也作为多种操作系统中的进程调度算法，还可用于实时系统中。当把该算法用于作业调度时，系统将从后备队列中选择若干个优先权最高的作业装入内存。当用于进程调度时，该算法是把处理机分配给就绪队列中优先权最高的进程，这时，又可进一步把该算法分成如下两种。

1) 非抢占式优先权算法

在这种方式下，系统一旦把处理机分配给就绪队列中优先权最高的进程后，该进程便一直执行下去，直至完成；或因发生某事件使该进程放弃处理机时，系统方可再将处理机重新分配给另一优先权最高的进程。这种调度算法主要用于批处理系统中；也可用于某些对实时性要求不严的实时系统中。

2) 抢占式优先权调度算法

在这种方式下，系统同样是把处理机分配给优先权最高的进程，使之执行。但在其执行期间，只要又出现了另一个其优先权更高的进程，进程调度程序就立即停止当前进程(原优先权最高的进程)的执行，重新将处理机分配给新到的优先权最高的进程。因此，在采用这种调度算法时，是每当系统中出现一个新的就绪进程i时，就将其优先权Pi与正在执行的进程j的优先权Pj进行比较。如果Pi≤Pj，原进程Pj便继续执行；但如果是Pi>Pj，则立即停止Pj的执行，做进程切换，使i进程投入执行。显然，这种抢占式的优先权调度算法能更好地满足紧迫作业的要求，故而常用于要求比较严格的实时系统中，以及对性能要求较高的批处理和分时系统中。

## 3. 并发和并行

**并发（concurrency）**：指宏观上看起来两个程序在同时运行，比如说在单核cpu上的多任务。但是从微观上看两个程序的指令是交织着运行的，你的指令之间穿插着我的指令，我的指令之间穿插着你的，在单个周期内只运行了一个指令。这种并发并不能提高计算机的性能，只能提高效率。

**并行（parallelism）**：指严格物理意义上的同时运行，比如多核cpu，两个程序分别运行在两个核上，两者之间互不影响，单个周期内每个程序都运行了自己的指令，也就是运行了两条指令。这样说来并行的确提高了计算机的效率。所以现在的cpu都是往多核方面发展。

## 4. 缺页中断

malloc()和mmap()等内存分配函数，在分配时只是建立了进程虚拟地址空间，并没有分配虚拟内存对应的物理内存。当进程访问这些没有建立映射关系的虚拟内存时，处理器自动触发一个缺页异常。

缺页中断：**在请求分页系统中，可以通过查询页表中的状态位来确定所要访问的页面是否存在于内存中。每当所要访问的页面不在内存时，会产生一次缺页中断，此时操作系统会根据页表中的外存地址在外存中找到所缺的一页，将其调入内存。**

缺页本身是一种中断，与一般的中断一样，需要经过4个处理步骤：

1、保护CPU现场

2、分析中断原因

3、转入缺页中断处理程序进行处理

4、恢复CPU现场，继续执行

但是缺页中断是由于所要访问的页面不存在于内存时，由硬件所产生的一种特殊的中断，因此，与一般的中断存在区别：

1、在指令执行期间产生和处理缺页中断信号

2、一条指令在执行期间，可能产生多次缺页中断

3、缺页中断返回是，执行产生中断的一条指令，而一般的中断返回是，执行下一条指令。



## 5. 缺页置换算法

当访问一个内存中不存在的页，并且内存已满，则需要从内存中调出一个页或将数据送至磁盘对换区，替换一个页，这种现象叫做缺页置换。当前操作系统最常采用的缺页置换算法如下：

**最佳置换算法：**只具有理论意义的算法，用来评价其他页面置换算法。置换策略是将当前页面中在未来最长时间内不会被访问的页置换出去。

**先进先出置换算法：**简单粗暴的一种置换算法，没有考虑页面访问频率信息。每次淘汰最早调入的页面。

**最近最久未使用算法LRU：**算法赋予每个页面一个访问字段，用来记录上次页面被访问到现在所经历的时间t，每次置换的时候把t值最大的页面置换出去(实现方面可以采用寄存器或者栈的方式实现)。

**时钟算法clock(也被称为是最近未使用算法NRU)：**页面设置一个访问位，并将页面链接为一个环形队列，页面被访问的时候访问位设置为1。页面置换的时候，如果当前指针所指页面访问为为0，那么置换，否则将其置为0，循环直到遇到一个访问为位0的页面。

**改进型Clock算法：**在Clock算法的基础上添加一个修改位，替换时根究访问位和修改位综合判断。优先替换访问位和修改位都是0的页面，其次是访问位为0修改位为1的页面。

**最少使用算法LFU：**设置寄存器记录页面被访问次数，每次置换的时候置换当前访问次数最少的。

## 6. fork()和vfork()的区别

1. fork( )的子进程拷贝父进程的数据段和代码段；vfork( )的子进程与父进程共享数据段
2. fork( )的父子进程的执行次序不确定；vfork( )保证子进程先运行，在调用exec或exit之前与父进程数据是共享的，在它调用exec或exit之后父进程才可能被调度运行。如果在调用这两个函数之前子进程依赖于父进程的进一步动作，则会导致死锁。
4. 当需要改变共享数据段中变量的值，则拷贝父进程。



## 7. 生产者-消费者问题

**1. 利用信号量解决生产者和消费者问题**

```C++
// 单生产者-单消费者问题
#define N 100;
int count = 0;

void producer(void){
    int item;
    while(true){
        item = produce_item();
        if(count==N) sleep();
        insert(item);
        count++;
        if(count==1) wakeup(consumer);
    }
}

void consumer(void){
    int item;
    while(true){
        if(count==0) sleep();
        item = remove_item();
        count--;
        if(count==N-1) wakeup(producer);
        consume_item(item);
    }
}
```

**2. 利用信号量解决生产者-消费者问题**

> 信号量的pv操作

## 8. 一个总结

> https://juejin.im/entry/6844903478859431943

### 1. 操作系统的四个特性

并发、共享、虚拟、异步

### 2. OS的主要功能

- 处理机管理：
- 存储器管理
- 设备管理
- 文件管理
- 提供用户接口

### 3. 进程的状态和转换

**就绪态、运行态、阻塞态**

- 就绪态到运行态(进程调度)
- 阻塞态到就绪态（某个事件已经发生）
- 运行态到就绪态（时间片用完）
- 运行态到阻塞态（等待某个事件发生）

### 4. 进程与线程的区别

**进程**：进程是进程实体的运行过程，是系统进行资源分配和调度的基本单位；引入进程为了使得多个程序可以并发的执行，以提高系统的资源利用率和吞吐量。

**线程**：是比进程更小的可独立运行的基本单位，是CPU调度的基本单位；引入的目的是为了减少程序在并发执行过程中的开销，使得OS并发效率更高。

**两者对比**

- 进程是资源分配和调度的基本单位，线程是CPU调度的基本单位
- 一个线程只能属于一个进程，但是一个进程可以有多个进程。各个进程之间是独立的，但是一个进程中的线程之间可能是相互影响的。
- 进程是基本的资源拥有单位，线程只拥有很少的基本的资源，但是线程可以访问所隶属的进程的资源（进程的代码段，数据段和所拥有的系统资源）
- 系统开销：创建或撤销进程的时候，系统要为之创建或者回收PCB，系统资源等，切换时也需要保存和回复CPU环境。而线程的切换只需要保存和恢复少量的寄存器，不涉及存储器管理方面的工作，所以开销比较小。
- 通信的方式：由于同一个进程中的线程共享地址空间，所以通信同步等变得比较简单。

### 5. 进程间通信的方式

> 同步和通信是一会事吗?

socket、管道、信号量、信号、消息队列、共享内存

信号量机制和信号机制傻傻分不清：

**5.1 Linux信号（signal) 机制** 

signal，又简称为信号（软中断信号）用来通知进程发生了异步事件。

**原理：**

​     一个进程收到一个信号与处理器收到一个中断请求可以说是一样的。信号是进程间通信机制中唯一的异步通信机制，一个进程不必通过任何操作来等待信号的到达，事实上，进程也不知道信号到底什么时候到达。进程之间可以互相通过系统调用kill发送软中断信号。内核也可以因为内部事件而给进程发送信号，通知进程发生了某个事件。信号机制除了基本通知功能外，还可以传递附加信息。

**分类：**

从两个不同的分类角度对信号进行：

可靠性方面：可靠信号与不可靠信号；

与时间的关系上：实时信号与非实时信号。

**5.2 Linux信号量（semaphore）机制**

**Linux内核的信号量用来操作系统进程间同步访问共享资源。**

 **原理：**信号量在创建时需要设置一个初始值，表示同时可以有几个任务可以访问该信号量保护的共享资源，初始值为1就变成互斥锁（Mutex），即同时只能有一个任务可以访问信号量保护的共享资源。

一个任务要想访问共享资源，首先必须得到信号量，获取信号量的操作将把信号量的值减1，若当前信号量的值为负数，表明无法获得信号量，该任务必须挂起在该信号量的等待队列等待该信号量可用；若当前信号量的值为非负数，表示可以获得信号量，因而可以立刻访问被该信号量保护的共享资源。

当任务访问完被信号量保护的共享资源后，必须释放信号量，释放信号量通过把信号量的值加1实现，如果信号量的值为非正数，表明有任务等待当前信号量，因此它也唤醒所有等待该信号量的任务。

### 6. 线程间通信的方式

- 信号量
- 互斥量
- 临界区
- 事件

### 7. 用户态和内核态

**内核态：**cpu可以访问内存的所有数据，包括外围设备，例如硬盘，网卡，cpu也可以将自己从一个程序切换到另一个程序。

**用户态：**只能受限的访问内存，且不允许访问外围设备，占用cpu的能力被剥夺，cpu资源可以被其他程序获取。

> 为什么要有用户态和内核态？
>
> 解释一：
>
> 由于需要限制不同的程序之间的访问能力, 防止他们获取别的程序的内存数据, 或者获取外围设备的数据, 并发送到网络, CPU划分出两个权限等级 -- 用户态和内核态。
>
> 解释二：
>
> 由于用户可能会对操作系统内核进行错误的修改导致系统的崩溃，因此限定了用户的访问权限，因此也就把操作系统分为了用户态和内核态。用户态的访问权限是受限的，但是内核态的访问权限是不受限的。



**用户态切换到内核态的方式如下：**

- **系统调用**：程序的执行一般是在用户态下执行的，但当程序需要使用操作系统提供的服务时，比如说打开某一设备、创建文件、读写文件（这些均属于系统调用）等，就需要向操作系统发出调用服务的请求，这就是系统调用。
- **异常**：当CPU在执行运行在用户态下的程序时，发生了某些事先不可知的异常，这时会触发由当前运行进程切换到处理此异常的内核相关程序中，也就转到了内核态，比如缺页异常。
- **外围设备的中断：**当外围设备完成用户请求的操作后，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条即将要执行的指令转而去执行与中断信号对应的处理程序，如果先前执行的指令是用户态下的程序，那么这个转换的过程自然也就发生了由用户态到内核态的切换。比如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后续操作等。

### 8.死锁

死锁是指多个进程在运行过程中，因为争夺资源而造成的一种僵局，如果没有外力推动，处于僵局中的进程就无法继续执行。

![img](https://mmbiz.qpic.cn/mmbiz_png/NdsdouZwicaeY0fdOUxrwTABu5sAN6O6uBAoxiaZ9EWWlpXLWKoMX2kiaODoEu4uJwJBMg4fy7YVzYfYeYzzVVcug/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

> 线程 1 已经成功拿到了**互斥量 1** ，正在申请**互斥量 2** ，而同时在另一个  CPU   上，线程 2 已经拿到了互**斥量 2** ，正在申请**互斥量 1** 。彼此占有对方正在申请的互斥量，结局就是谁也没办法拿到想要的互斥量，于是死锁就发生了。



**死锁的原因：**

- 资源竞争
- 进程推进的顺序非法

**死锁产生的必要条件**：

- 不可剥条件:进程对于已经申请到的资源在使用完成之前不可以被剥夺
- 互斥条件:进程对所分配的资源进行排他性的使用
- 请求和保持条件:进程被阻塞的时候并不释放锁申请到的资源
- 环路等待条件:发生死锁的时候存在的一个 进程-资源 环形等待链



**死锁处理：**

1. 预防死锁：破坏产生死锁的4个必要条件中的一个或者多个；实现起来比较简单，但是如果限制过于严格会降低系统资源利用率以及吞吐量

   - **破坏互斥**

   > 通过与锁完全不同的同步方式CAS，CAS提供原子性支持，实现各种无锁的数据结构，不仅可以避免互斥锁带来的开销也可避免死锁问题。

   - **破坏不可剥夺**

   > 如果一个线程已经获取到了一些锁，那么在这个线程释放锁之前这些锁是不会被强制剥夺的。但是为了防止死锁的发生，我们可以选择让线程在获取后续的锁失败时主动放弃自己已经持有的锁并在之后重试整个任务，这样其他等待这些锁的线程就可以继续执行了。

   - **破坏环路等待**

   > 在实践的过程中，采用破坏环路等待的方式非常常见，这种技术叫做"锁排序"。很好理解，我们假设现在有个数组A，采用单向访问的方式(从前往后)，依次访问并加锁，这样一来，线程只会向前单向等待锁释放，自然也就无法形成一个环路了。

2. 避免死锁：在资源的动态分配中，防止系统进入不安全状态(可能产生死锁的状态)-如银行家算法

   - **银行家算法**

     当进程首次申请资源时，要测试该进程对资源的**最大需求量**，如果系统现存的资源可以满足它的最大需求量则按当前的申请量分配资源，否则就推迟分配。

     当进程在执行中继续申请资源时，先测试该进程已占用的资源数与本次申请资源数之和是否超过了该进程对资源的最大需求量。若超过则拒绝分配资源。若没超过则再测试系统现存的资源能否满足该进程尚需的最大资源量，若满足则按当前的申请量分配资源，否则也要推迟分配。

   - **安全序列**

     是指系统能按某种进程推进顺序（P1, P2, P3, …, Pn），为每个进程 Pi 分配其所需要的资源，直至满足每个进程对资源的最大需求，使每个进程都可以顺序地完成。这种推进顺序就叫安全序列【银行家算法的核心就是找到一个安全序列】。

   - **系统安全状态**

     如果系统能找到一个安全序列，就称系统处于安全状态，否则，就称系统处于不安全状态。

3. 检测死锁：允许系统运行过程中产生死锁，在死锁发生之后，采用一定的算法进行检测，并确定与死锁相关的资源和进程，采取相关方法清除检测到的死锁。实现难度大

4. 解除死锁：与死锁检测配合，将系统从死锁中解脱出来（撤销进程或者剥夺资源）。对检测到的和死锁相关的进程以及资源，通过撤销或者挂起的方式，释放一些资源并将其分配给处于阻塞状态的进程，使其转变为就绪态。

   - 资源剥夺：挂起某些死锁进程，并抢占它的资源，将这些资源分配给其他死锁进程（但应该防止被挂起的进程长时间得不到资源）；
   - 撤销进程：强制撤销部分、甚至全部死锁进程并剥夺这些进程的资源（撤销的原则可以按进程优先级和撤销进程代价的高低进行）；
   - 进程回退：让一个或多个进程回退到足以避免死锁的地步。进程回退时自愿释放资源而不是被剥夺。要求系统保持进程的历史信息，设置还原点。

### 9. 进程调度算法

- 先来先服务
- 短作业优先
- 时间片轮转
- 优先级调度
- 多级队列

### 10. 内存连续分配

主要是指几种动态分区分配时所采用的几种算法。

动态分区分配又称为可变分区分配，是一种动态划分内存的分区方法。这种分区方法不预先将内存划分，而是在进程装入内存时，根据进程的大小动态地建立分区，并使分区的大小正好适合进程的需要。因此系统中分区的大小和数目是可变的

- 首次适应
- 最佳适应算法
- 最坏适应算法

### 11. 分页存储管理方式

把主存空间划分为大小相等且固定的块，块相对较小，作为主存的基本单位。每个进程也以块为单位进行划分，进程在执行时，以块为单位逐个申请主存中的块空间。

因为程序数据存储在不同的页面中，而页面又离散的分布在内存中，**因此需要一个页表来记录逻辑地址和实际存储地址之间的映射关系，以实现从页号到物理块号的映射。**

由于页表也是存储在内存中的，因此和不适用分页管理的存储方式相比，访问分页系统中内存数据需要**两次的内存访问**(一次是从内存中访问页表，从中找到指定的物理块号，加上页内偏移得到实际物理地址；第二次就是根据第一次得到的物理地址访问内存取出数据)。

![img](https://user-gold-cdn.xitu.io/2017/5/22/c453381c57fa4d0804b2c7dd35c55099?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)



为了减少两次访问内存导致的效率影响，分页管理中引入了**快表机制**，包含快表机制的内存管理中，当要访问内存数据的时候，首先将页号在快表中查询，如果查找到说明要访问的页表项在快表中，那么直接从快表中读取相应的物理块号；如果没有找到，那么访问内存中的页表，从页表中得到物理地址，同时将页表中的该映射表项添加到快表中(可能存在快表换出算法)。

此外，由于逻辑地址可能非常大，会占用较大的连续内存空间，因此又引入了两级页表和多级页表的方法。

### 12. 分段存储管理方式

**分段分页方式的比较**

页是信息的物理单位，是出于系统内存利用率的角度提出的离散分配机制；段是信息的逻辑单位，每个段含有一组意义完整的信息，是出于用户角度提出的内存管理机制

页的大小是固定的，由系统决定；段的大小是不确定的，由用户决定



### 13. 虚拟内存

**虚拟内存**的提出主要是为了解决一个程序，所需内存空间超过了计算机可以提供的实际内存而无法运行的情况

基于局部性原理，**在程序装入时，可以将程序的一部分装入内存，而将其余部分留在外存**，就可以启动程序执行。在程序执行过程中，**当所访问的信息不在内存时，由操作系统将所需要的部分调入内存,然后继续执行程序**。另一方面，操作系统将内存中**暂时不使用的内容换出到外存上，从而腾出空间存放将要调入内存的信息**。这样，系统好像为用户提供了一个比实际内存大得多的存储器，称为虚拟存储器。



### 14. 页面置换算法

**最佳置换算法：**只具有理论意义的算法，用来评价其他页面置换算法。置换策略是将当前页面中在未来最长时间内不会被访问的页置换出去。

**先进先出置换算法：**简单粗暴的一种置换算法，没有考虑页面访问频率信息。每次淘汰最早调入的页面。

**最近最久未使用算法LRU：**算法赋予每个页面一个访问字段，用来记录上次页面被访问到现在所经历的时间t，每次置换的时候把t值最大的页面置换出去(实现方面可以采用寄存器或者栈的方式实现)。

**时钟算法clock(也被称为是最近未使用算法NRU)：**页面设置一个访问位，并将页面链接为一个环形队列，页面被访问的时候访问位设置为1。页面置换的时候，如果当前指针所指页面访问为为0，那么置换，否则将其置为0，循环直到遇到一个访问为位0的页面。

**改进型Clock算法：**在Clock算法的基础上添加一个修改位，替换时根究访问位和修改位综合判断。优先替换访问位和修改位都是0的页面，其次是访问位为0修改位为1的页面。

**最少使用算法LFU：**设置寄存器记录页面被访问次数，每次置换的时候置换当前访问次数最少的。



## 9. select poll epoll的区别

<font color=red>**区别：**</font>

他们三者都是利用一个线程监控多个socket链接，当有数据到达时，对包含数据的socket进行进一步的处理。poll和epoll相当于对select的一个改进。

select是使用轮询的方式检测是否有数据到达，主要存在三个缺陷：

- select支持的文件描述符数量太小了，默认是1024。
- 每次调用select，都需要把文件描述符集合从用户态拷贝到内核态
- 通过遍历得知哪一个文件描述符已经就绪，开销比较大

poll针对select的第一个缺点进行改进，不再使用bitmap来存储fd集合，而是使用链表，这就消除了1024的限制，但是后面的操作是一样的。

epoll对poll又做出了进一步的改进，他的fd集合是共享与用户态和内核态的，并且他不再需要使用轮询的方式去检测是否哪个fd就绪，而是采用回调函数的形式来确定就绪的文件描述符。

<font color=red>**epoll两种工作模式（LT和ET）的区别：**</font>

**LT(level triggered)是缺省的工作方式**，并且同时支持block（阻塞）和no-block（非阻塞） socket。在这种做法中，内核告诉你一个文件描述符是否就绪了，然后你可以对这个就绪的fd进行I/O操作。如果你不作任何操作，内核还是会继续通知你的，所以，这种模式编程出错误可能性要小一点。传统的select/poll都是这种模型的代表．

**ET(edge-triggered)是高速工作方式**，只支持no-block（非阻塞） socket。在这种模式下，当描述符从未就绪变为就绪时，内核通过epoll告诉你。然后它会假设你知道文件描述符已经就绪，并且不会再为那个文件描述符发送更多的就绪通知，直到你做了某些操作导致那个文件描述符不再为就绪状态了。但是请注意，如果一直不对这个fd作IO操作(从而导致它再次变成未就绪)，内核不会发送更多的通知 (only once）。



<font color=red>**select和epoll如何选择**</font>

如果任务不是很多，但是绝大多数的文件描述符都比较活跃，这个时候使用select的效果就是比epoll好。epoll适用于连接数量多，但是活跃链接比较少的情况。

<font color=red>**select的优点**</font>

- 跨平台性和兼容性
- 当文件描述符大部分都比较活跃时，select的性能优于epoll

<font color=red>**epoll的原理**</font>

调用顺序：

int epoll_create(int size);
int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event);
int epoll_wait(int epfd, struct epoll_event *events,int maxevents, int timeout);

首先创建一个epoll对象，然后使用epoll_ctl对这个对象进行操作，把需要监控的描述添加进去，这些描述如将会以epoll_event结构体的形式组成一颗红黑树，接着阻塞在epoll_wait，进入大循环，当某个fd上有事件发生时，内核将会把其对应的结构体放入到一个链表中，返回有事件发生的链表。



## 10. 堆和栈的区别

1、内存分配方面：

​    堆：一般由程序员分配释放， 若程序员不释放，程序结束时可能由OS回收 。注意它与数据结构中的堆是两回事，分配方式是类似于链表。可能用到的关键字如下：new、malloc、delete、free等等。

​    栈：由编译器(Compiler)自动分配释放，存放函数的参数值，局部变量的值等。其操作方式类似于数据结构中的栈。

2、申请方式方面：

​    堆：需要程序员自己申请，并指明大小。在c中malloc函数如p1 = (char *)malloc(10)；在C++中用new运算符，但是注意p1、p2本身是在栈中的。因为他们还是可以认为是局部变量。

​    栈：由系统自动分配。 例如，声明在函数中一个局部变量 int b；系统自动在栈中为b开辟空间。

3、系统响应方面：

​    堆：操作系统有一个记录空闲内存地址的链表，当系统收到程序的申请时，会遍历该链表，寻找第一个空间大于所申请空间的堆结点，然后将该结点从空闲结点链表中删除，并将该结点的空间分配给程序，另外，对于大多数系统，会在这块内存空间中的首地址处记录本次分配的大小，这样代码中的delete语句才能正确的释放本内存空间。另外由于找到的堆结点的大小不一定正好等于申请的大小，系统会自动的将多余的那部分重新放入空闲链表中。

​    栈：只要栈的剩余空间大于所申请空间，系统将为程序提供内存，否则将报异常提示栈溢出。

4、大小限制方面：

​    堆：是向高地址扩展的数据结构，是不连续的内存区域。这是由于系统是用链表来存储的空闲内存地址的，自然是不连续的，而链表的遍历方向是由低地址向高地址。堆的大小受限于计算机系统中有效的虚拟内存。由此可见，堆获得的空间比较灵活，也比较大。

​    栈：在Windows下, 栈是向低地址扩展的数据结构，是一块连续的内存的区域。这句话的意思是栈顶的地址和栈的最大容量是系统预先规定好的，在WINDOWS下，栈的大小是固定的（是一个编译时就确定的常数），如果申请的空间超过栈的剩余空间时，将提示overflow。因此，能从栈获得的空间较小。

5、效率方面：

​    堆：是由new分配的内存，一般速度比较慢，而且容易产生内存碎片，不过用起来最方便，另外，在WINDOWS下，最好的方式是用VirtualAlloc分配内存，他不是在堆，也不是在栈是直接在进程的地址空间中保留一快内存，虽然用起来最不方便。但是速度快，也最灵活。

​    栈：由系统自动分配，速度较快。但程序员是无法控制的。

6、存放内容方面：

​    堆：一般是在堆的头部用一个字节存放堆的大小。堆中的具体内容有程序员安排。

​    栈：在函数调用时第一个进栈的是主函数中后的下一条指令（函数调用语句的下一条可执行语句）的地址然后是函数的各个参数，在大多数的C编译器中，参数是由右往左入栈，然后是函数中的局部变量。 注意: 静态变量是不入栈的。当本次函数调用结束后，局部变量先出栈，然后是参数，最后栈顶指针指向最开始存的地址，也就是主函数中的下一条指令，程序由该点继续运行。

7、存取效率方面：

​    堆：char *s1 = "Hellow Word"；是在编译时就确定的；

​    栈：char s1[] = "Hellow Word"； 是在运行时赋值的；用数组比用指针速度要快一些，因为指针在底层汇编中需要用edx寄存器中转一下，而数组在栈上直接读取。

## 11. 操作系统的缺页中断





## 12. 多线程锁机制和种类

同步的时候用一个互斥量，在访问共享资源前对互斥量进行加锁，在访问完成后释放互斥量上的锁。对
互斥量进行加锁以后，任何其他试图再次对互斥量加锁的线程将会被阻塞直到当前线程释放该互斥锁。
如果释放互斥锁时有多个线程阻塞，所有在该互斥锁上的阻塞线程都会变成可运行状态，第一个变为运
行状态的线程可以对互斥量加锁，其他线程将会看到互斥锁依然被锁住，只能回去再次等待它重新变为
可用。在这种方式下，每次只有一个线程可以向前执行。 

**Linux的4种锁机制：**

- 互斥锁：mutex，用于保证在任何时刻，都只能有一个线程访问该对象。当获取锁操作失败时，线程会
  进入睡眠，等待锁释放时被唤醒
- 读写锁：rwlock，分为读锁和写锁。处于读操作时，可以允许多个线程同时获得读操作。但是同一时刻
  只能有一个线程可以获得写锁。其它获取写锁失败的线程都会进入睡眠状态，直到写锁释放时被唤醒。
  注意：写锁会阻塞其它读写锁。当有一个线程获得写锁在写时，读锁也不能被其它线程获取；写者优先
  于读者（一旦有写者，则后续读者必须等待，唤醒时优先考虑写者）。适用于读取数据的频率远远大于
  写数据的频率的场合。
- 自旋锁：spinlock，在任何时刻同样只能有一个线程访问对象。但是当获取锁操作失败时，不会进入睡
  眠，而是会在原地自旋，直到锁被释放。这样节省了线程从睡眠状态到被唤醒期间的消耗，在加锁时间
  短暂的环境下会极大的提高效率。但如果加锁时间过长，则会非常浪费CPU资源。
- RCU：即read-copy-update，在修改数据时，首先需要读取数据，然后生成一个副本，对副本进行修
  改。修改完成后，再将老数据update成新的数据。使用RCU时，读者几乎不需要同步开销，既不需要获
  得锁，也不使用原子指令，不会导致锁竞争，因此就不用考虑死锁问题了。而对于写者的同步开销较
  大，它需要复制被修改的数据，还必须使用锁机制同步并行其它写者的修改操作。在有大量读操作，少
  量写操作的情况下效率非常高。 



## 13. 互斥机制以及互斥锁和读写锁的区别

- 互斥锁：mutex，用于保证在任何时刻，都只能有一个线程访问该对象。当获取锁操作失败时，线程会
  进入睡眠，等待锁释放时被唤醒 。
  
- 读写锁：rwlock， 分为读锁和写锁。处于读操作时，可以允许多个线程同时获得读操作。但是同一时刻
  只能有一个线程可以获得写锁。其它获取写锁失败的线程都会进入睡眠状态，直到写锁释放时被唤醒。
  注意：写锁会阻塞其它读写锁。当有一个线程获得写锁在写时，读锁也不能被其它线程获取；写者优先
  于读者（一旦有写者，则后续读者必须等待，唤醒时优先考虑写者）。适用于读取数据的频率远远大于
  写数据的频率的场合。
  
- 互斥锁和读写锁的**区别：**
  1）读写锁区分读者和写者，而互斥锁不区分
  2）互斥锁同一时间只允许一个线程访问该对象，无论读写；读写锁同一时间内只允许一个写者，但是
  允许多个读者同时读对象。 
  
  

## 14. 基于多进程服务器和基于多线程服务器的优缺点

**多进程服务器优点**

1. 由操作系统进行调度，运行比较稳定强壮

2. 能够方便地通过操作系统进行监控和管理

   例如对每个进程的内存变化状况,甚至某个进程处理什么web请求进行监控.同时可以通过给进程发送信号量,实现对应用的各种管理

3. 隔离性好

   一个进程出现问题只有杀掉它重启就可以,不影响整体服务的可用性。

4. 充分利用多核cpu,实现并行处理

 

**多进程服务器的缺点:**

1. 内存消耗比较大,每个进程都独立加载完整的应用环境

2. cpu消耗偏高,高并发下,进程之间频繁进行上下文切换,需要大量的内存换页操作

3. 很低的io并发处理能力,只适合处理短请求,不适合处理长请求



**基于多线程服务器的优点:**

​    1. 对内存的消耗小

​       线程之间共享整个应用环境,每个线程栈都比较小,一般不到1M

​    2. cpu上下文切换比较快

​    3. io的并发能力强

​    4. 有效利用多核cpu进行并行计算

**基于多线程服务器的缺点:**

​    1. 不方便操作系统的管理

​    2. VM对内存的管理要求非常高,GC的策略会影响多线程并发能力和系统吞吐量

    3. 由于存在对共享资源操作,一旦出现线程"死锁"和线程阻塞,很容易使整个应用失去可用性

## 15. 如何保证线程安全

**15.1 线程安全是什么**

如果你的代码所在的进程中有多个线程在同时运行，而这些线程可能会同时运行这段代码。如果每次运行结果和[单线程](https://baike.baidu.com/item/单线程)运行的结果是一样的，而且其他的变量的值也和预期的是一样的，就是线程安全的。或者说:一个类或者程序所提供的接口对于线程来说是[原子操作](https://baike.baidu.com/item/原子操作)或者多个线程之间的切换不会导致该接口的执行结果存在二义性,也就是说我们不用考虑同步的问题。

线程安全问题都是由[全局变量](https://baike.baidu.com/item/全局变量)及[静态变量](https://baike.baidu.com/item/静态变量)引起的。

若每个线程中对全局变量、静态变量只有读操作，而无写操作，一般来说，这个全局变量是线程安全的；若有多个线程同时执行写操作，一般都需要考虑[线程同步](https://baike.baidu.com/item/线程同步)，否则的话就可能影响线程安全。



**15.2 如何保证线程安全**
 <font color=blue>一般说来，确保线程安全的方法有这几个：竞争与原子操作、同步与锁、可重入、过度优化。</font>

- **竞争与原子操作** 
   多个线程同时访问和修改一个数据，可能造成很严重的后果。出现严重后果的原因是很多操作作系统编译为汇编代码之后不止一条指令，因此在执行的时候可能执行了一半就被调度系统打断了而去执行别的代码了。一般将单指令的操作称为原子的(Atomic)，因为不管怎样，单条指令的执行是不会被打断的。因此，为了避免出现多线程操作数据的出现异常，Linux系统提供了一些常用操作的原子指令，确保了线程的安全。但是，它们只适用于比较简单的场合，在复杂的情况下就要选用其他的方法了。

- **同步与锁** 
   为了避免多个线程同时读写一个数据而产生不可预料的后果，开发人员要将各个线程对同一个数据的访问同步，也就是说，在一个线程访问数据未结束的时候，其他线程不得对同一个数据进行访问。同步的最常用的方法是使用锁(Lock)，它是一种非强制机制，每个线程在访问数据或资源之前首先试图获取锁，并在访问结束之后释放锁；在锁已经被占用的时候试图获取锁时，线程会等待，直到锁重新可用。二元信号量是最简单的一种锁，它只有两种状态：占用与非占用，它适合只能被唯一一个线程独占访问的资源。对于允许多个线程并发访问的资源，要使用多元信号量(简称信号量)。

- 可重入 
   一个函数被重入，表示这个函数没有执行完成，但由于外部因素或内部因素，又一次进入该函数执行。一个函数称为可重入的，表明该函数被重入之后不会产生任何不良后果。可重入是并发安全的强力保障，一个可重入的函数可以在多线程环境下放心使用。

- 过度优化 
   在很多情况下，即使我们合理地使用了锁，也不一定能够保证线程安全，因此，我们可能对代码进行过度的优化以确保线程安全。 我们可以使用volatile关键字试图阻止过度优化，它可以做两件事：第一，阻止编译器为了提高速度将一个变量缓存到寄存器而不写回；第二，阻止编译器调整操作volatile变量的指令顺序。在另一种情况下，CPU的乱序执行让多线程安全保障的努力变得很困难，通常的解决办法是调用CPU提供的一条常被称作barrier的指令，它会阻止CPU将该指令之前的指令交换到barrier之后，反之亦然。  

## 16. 为什么进程上下文切换比线程上下文切换代价高

进程切换分两步：

1.切换页目录以使用新的地址空间

2.切换内核栈和硬件上下文

对于linux来说，线程和进程的最大区别就在于地址空间，对于线程切换，第1步是不需要做的，第2是进程和线程切换都要做的。

切换的性能消耗：

1、线程上下文切换和进程上下问切换一个最主要的区别是线程的切换虚拟内存空间依然是相同的，但是进程切换是不同的。这两种上下文切换的处理都是通过操作系统内核来完成的。内核的这种切换过程伴随的最显著的性能损耗是将寄存器中的内容切换出。

2、另外一个隐藏的损耗是上下文的切换会扰乱处理器的缓存机制。简单的说，一旦去切换上下文，处理器中所有已经缓存的内存地址一瞬间都作废了。还有一个显著的区别是当你改变虚拟内存空间的时候，处理的页表缓冲（processor's Translation Lookaside Buffer (TLB)）或者相当的神马东西会被全部刷新，这将导致内存的访问在一段时间内相当的低效。但是在线程的切换中，不会出现这个问题。

 

## 17. 临界资源

- 在操作系统中，进程是占有资源的最小单位（线程可以访问其所在进程内的所有资源，但线程本身并不占有资源或仅仅占有一点必须资源）。但**对于某些资源来说，其在同一时间只能被一个进程所占用。这些一次只能被一个进程所占用的资源就是所谓的临界资源**。典型的临界资源比如物理上的打印机，或是存在硬盘或内存中被多个进程所共享的一些变量和数据等(如果这类资源不被看成临界资源加以保护，那么很有可能造成丢数据的问题)。
- **对于临界资源的访问，必须是互斥进行。**也就是当临界资源被占用时，另一个申请临界资源的进程会被阻塞，直到其所申请的临界资源被释放。**而进程内访问临界资源的代码被成为临界区。**

## 18. 内存池、进程池、线程池

首先介绍一个概念“池化技术 ”。池化技术就是：提前保存大量的资源，以备不时之需以及重复使用。池化技术应用广泛，如内存池，线程池，连接池等等。由于在实际应用当做，分配内存、创建进程、线程都会设计到一些系统调用，系统调用需要导致程序从用户态切换到内核态，是非常耗时的操作。因此，当程序中需要频繁的进行内存申请释放，进程、线程创建销毁等操作时，通常会使用内存池、进程池、线程池技术来提升程序的性能。

  　　**线程池**：线程池的原理很简单，类似于操作系统中的缓冲区的概念，它的流程如下：先启动若干数量的线程，并让这些线程都处于睡眠状态，当需要一个开辟一个线程去做具体的工作时，就会唤醒线程池中的某一个睡眠线程，让它去做具体工作，当工作完成后，线程又处于睡眠状态，而不是将线程销毁。

  　　**进程池**与线程池同理。

  　　**内存池**：内存池是指程序预先从操作系统申请一块足够大内存，此后，当程序中需要申请内存的时候，不是直接向操作系统申请，而是直接从内存池中获取；同理，当程序释放内存的时候，并不真正将内存返回给操作系统，而是返回内存池。当程序退出(或者特定时间)时，内存池才将之前申请的内存真正释放。

## 19. 中断和系统调用

**所谓的中断就是在计算机执行程序的过程中，由于出现了某些特殊事情，使得CPU暂停对程序的执行，转而去执行处理这一事件的程序。等这些特殊事情处理完之后再回去执行之前的程序。**中断一般分为三类：

- 由计算机硬件异常或故障引起的中断，称为**内部异常中断**；
- 由程序中执行了引起中断的指令而造成的中断，称为**软中断**（这也是和我们将要说明的系统调用相关的中断）；
- 由外部设备请求引起的中断，称为**外部中断**。简单来说，对中断的理解就是对一些特殊事情的处理。

与中断紧密相连的一个概念就是**中断处理程序**了。当中断发生的时候，系统需要去对中断进行处理，对这些中断的处理是由操作系统内核中的特定函数进行的，这些处理中断的特定的函数就是我们所说的中断处理程序了。

另一个与中断紧密相连的概念就是**中断的优先级**。中断的优先级说明的是当一个中断正在被处理的时候，处理器能接受的中断的级别。中断的优先级也表明了中断需要被处理的紧急程度。**每个中断都有一个对应的优先级，当处理器在处理某一中断的时候，只有比这个中断优先级高的中断可以被处理器接受并且被处理。**优先级比这个当前正在被处理的中断优先级要低的中断将会被忽略。

**典型的中断优先级如下所示：**

- **机器错误 > 时钟 > 磁盘 > 网络设备 > 终端 > 软件中断**

 

在讲系统调用之前，先说下**进程的执行在系统上的两个级别**：用户级和核心级，也称为**用户态和系统态(user mode and kernel mode)**。

​        **用户空间就是用户进程所在的内存区域**，相对的，**系统空间就是操作系统占据的内存区域**。用户进程和系统进程的所有数据都在内存中。**处于用户态的程序只能访问用户空间，而处于内核态的程序可以访问用户空间和内核空间。**



## 20. 同步、异步、阻塞、非阻塞

**同步**：当一个同步调用发出后，调用者要一直等待返回结果。通知后，才能进行后续的执行。

**异步**：当一个异步过程调用发出后，调用者不能立刻得到返回结果。实际处理这个调用的部件在完成后，通过状态、通知和回调来通知调用者。

**阻塞**：是指调用结果返回前，当前线程会被挂起，即阻塞。

**非阻塞**：是指即使调用结果没返回，也不会阻塞当前线程。

**形象比喻**：

- 小Q去钓鱼，抛完线后就傻傻的看着有没有动静，有则拉杆(同步阻塞)
- 小Q去钓鱼，拿鱼网捞一下，有没有鱼立即知道，不用等，直接就捞(同步非阻塞)
- 小Q去钓鱼，这个鱼缸比较牛皮，扔了后自己就打王者荣耀去了，因为鱼上钩了这个鱼缸带的报警器会通知我。这样实现异步(异步非阻塞）

## 21. 什么是缓冲区溢出

缓冲区溢出是指当计算机向缓冲区内填充数据时超过了缓冲区本身的容量，溢出的数据覆盖在合法数据上

## 22. 内部碎片和外部碎片

- **内部碎片**是已经被分配出去的的内存空间大于请求所需的内存空间。

- **外部碎片**是指还没有分配出去，但是由于大小太小而无法分配给申请空间的新进程的内存空间空闲块。

- 固定分区存在内部碎片，可变式分区分配会存在外部碎片；
- **页式虚拟存储**系统存在**内部碎片**；**段式虚拟存储**系统，存在**外部碎片**

## 23. 同步和互斥

​        当有多个线程的时候，经常需要去同步这些线程以访问同一个数据或资源。例如，假设有一个程序，其中一个线程用于把文件读到内存，而另一个线程用于统计文件中的字符数。当然，在把整个文件调入内存之前，统计它的计数是没有意义的。但是，由于每个操作都有自己的线程，操作系统会把两个线程当作是互不相干的任务分别执行，这样就可能在没有把整个文件装入内存时统计字数。为解决此问题，你必须使两个线程同步工作。

​      所谓**同步**，是指散步在不同进程之间的若干程序片断，它们的运行必须严格按照规定的某种先后次序来运行，这种先后次序依赖于要完成的特定的任务。如果**用对资源的访问来定义的话，同步是指在互斥的基础上（大多数情况），通过其它机制实现访问者对资源的有序访问。在大多数情况下，同步已经实现了互斥，特别是所有写入资源的情况必定是互斥的。少数情况是指可以允许多个访问者同时访问资源。**

​      所谓**互斥**，是指散布在不同进程之间的若干程序片断，当某个进程运行其中一个程序片段时，其它进程就不能运行它们之中的任一程序片段，只能等到该进程运行完这个程序片段后才可以运行。如果**用对资源的访问来定义的话，互斥某一资源同时只允许一个访问者对其进行访问，具有唯一性和排它性。但互斥无法限制访问者对资源的访问顺序，即访问是无序的。**

## 24. 同步和异步

**同步**：

- 同步的定义：是指一个进程在执行某个请求的时候，若该请求需要一段时间才能返回信息，那么，这个进程将会一直等待下去，直到收到返回信息才继续执行下去。
- 特点：

1. 同步是阻塞模式；
2. 同步是按顺序执行，执行完一个再执行下一个，需要等待，协调运行；

**异步：**

- 是指进程不需要一直等下去，而是继续执行下面的操作，不管其他进程的状态。当有消息返回时系统会通知进程进行处理，这样可以提高执行的效率。
- 特点：

1. 异步是非阻塞模式，无需等待；
2. 异步是彼此独立，在等待某事件的过程中，继续做自己的事，不需要等待这一事件完成后再工作。线程是异步实现的一个方式。

**同步与异步的优缺点：**

- 同步可以避免出现死锁，读脏数据的发生。一般共享某一资源的时候，如果每个人都有修改权限，同时修改一个文件，有可能使一个读取另一个人已经删除了内容，就会出错，同步就不会出错。但，同步需要等待资源访问结束，浪费时间，效率低。
- 异步可以提高效率，但，安全性较低。

## 25 守护进程、僵尸进程、孤儿进程

- **守护进程**：运行在后台的一种特殊进程，**独立于控制终端并周期性地执行某些任务**。
- **僵尸进程**：一个进程 fork 子进程，子进程退出，而父进程没有wait/waitpid子进程，那么**子进程的进程描述符仍保存在系统中**，这样的进程称为僵尸进程。僵尸进程是一个进程必然会经历的进程
- **孤儿进程**：一个**父进程退出，而它的一个或多个子进程还在运行**，这些子进程称为孤儿进程。（孤儿进程将由 init 进程收养并对它们完成状态收集工作）

## 26. 线程的独占资源和共享资源

**共享资源**

**1、进程申请的堆内存**
**2、进程打开的文件描述符**
**3、进程的全局数据(可用于线程之间通信)**
**4、进程ID、进程组ID**
**5、进程目录**
**6、信号处理器**

**独占资源**

**1、线程ID**
同一进程中每个线程拥有唯一的线程ID。
**2、寄存器组的值**
由于线程间是并发运行的，每个线程有自己不同的运行线索，当从一个线 程切换到另一个线程上 时，必须将原有的线程的寄存器集合的状态保存，以便将来该线程在被重新切换到时能得以恢复。
**3、线程堆栈**
线程可以进行函数调用，必然会使用大函数堆栈。
**4、错误返回码**
线程执行出错时，必须明确是哪个线程出现何种错误，因此不同的线程应该拥有自己的错误返回码变量。
**5、信号屏蔽码**
由于每个线程所感兴趣的信号不同，所以线程的信号屏蔽码应该由线程自己管理。但所有的线程都共享同样的信号处理器。
**6、线程的优先级**
由于线程需要像进程那样能够被调度，那么就必须要有可供调度使用的参数，这个参数就是线程的优先级。



## 27. 挂起和阻塞的区别

- **挂起**是一种主动行为，因此恢复也应该要主动完成，而**阻塞**则是一种被动行为，是在等待事件或资源时任务的表现，你不知道他什么时候被阻塞(pend)，也就不能确切 的知道他什么时候恢复阻塞。而且挂起队列在操作系统里可以看成一个，而阻塞队列则是不同的事件或资源（如信号量）就有自己的队列。
- 阻塞（pend）就是任务释放CPU，其他任务可以运行，一般在等待某种资源或信号量的时候出现。挂起（suspend）不释放CPU，如果任务优先级高就永远轮不到其他任务运行，一般挂起用于程序调试中的条件中断，当出现某个条件的情况下挂起，然后进行单步调试。

**挂起、阻塞、睡眠的区别**

首先这些术语都是对于线程来说的。对线程的控制就好比你控制了一个雇工为你干活。你对雇工的控制是通过编程来实现的。

​     **挂起线程**的意思就是你对主动对雇工说：“你睡觉去吧，用着你的时候我主动去叫你，然后接着干活”。

​     使**线程睡眠**的意思就是你主动对雇工说：“你睡觉去吧，某时某刻过来报到，然后接着干活”。

​     **线程阻塞**的意思就是，你突然发现，你的雇工不知道在什么时候没经过你允许，自己睡觉呢，但是你不能怪雇工，肯定你这个雇主没注意，本来你让雇工扫地，结果扫帚被偷了或被邻居家借去了，你又没让雇工继续干别的活，他就只好睡觉了。至于扫帚回来后，雇工会不会知道，会不会继续干活，你不用担心，雇工一旦发现扫帚回来了，他就会自己去干活的。因为雇工受过良好的培训。这个培训机构就是操作系统。



## 28. 进程和线程上下文切换

**28.1 进程**

> 进程上下文切换只发生在内核态中

**进程的上下文切换不仅包含了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的资源。**

**进程上下文切换发生的场景**

- CPU时间片耗尽
- 资源不足
- 通过sleep主动挂起
- 优先级更高的进程进来要优先运行此进程
- 发生硬件中断

**28.2 线程**

- 当属于不同的进程发生上下文切换的时候和进程之间的上下文切换相同
- 当相同进程的中的线程进行切换时，共享的资源保持不变，但是私有的数据和寄存器等不共享的数据要进行切换

## 29. 用户级/内核级线程

- **用户线程**是基于用户态的线程管理库来实现的，那么**线程控制块（Thread Control Block, TCB）** 也是在库里面来实现的，对于操作系统而言是看不到这个 TCB 的，它只能看到整个进程的 PCB。所以，**用户线程的整个线程管理和调度，操作系统是不直接参与的，而是由用户级线程库函数来完成线程的管理，包括线程的创建、终止、同步和调度等。**
- **内核线程是由操作系统管理的，线程对应的 TCB 自然是放在操作系统里的，这样线程的创建、终止和管理都是由操作系统负责。**

## 30. 内存管理

### **30.1** 虚拟地址和物理地址

- 虚拟地址：我们程序所使用的内存地址叫做**虚拟内存地址**
- 物理地址：实际存在硬件里面的空间地址叫**物理内存地址**

操作系统引入了虚拟内存，进程持有的虚拟地址会通过 CPU 芯片中的内存管理单元（MMU）的映射关系，来转换变成物理地址，然后再通过物理地址访问内存。



![img](https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZfVYxicDjAjl4nMxlmyJk7rkpVTcOZj4JJSyYlSMyiaC66pP2q1QiafglrtO0tmZHCkBB0RvCsfVOTIA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



### **30.2 交换技术**

- **概念**，使得该进程运行一段时间，然后把他存回磁盘。空闲进程主要存储在磁盘上，所以当他不运行的时候就不会占用内存。
- **缺点：**
  - 程序太大，无法装进内存，那么程序就无法运行
  - 由于数据段可能处于动态增长的状态，因此可能导致内存空间不够用，或者导致多个进程无法正常运行
  - 内存空间有可能产生极大的浪费

> 扩展知识：
>
> **空闲内存管理：位图和空闲区链表**
>
> 1. **位图**
>
> 2. **空闲区链表**
>

### **30.3 虚拟内存**

**虚拟内存**的提出主要是为了解决运行一个程序时所需内存空间超过了计算机可以提供的实际内存而无法运行的情况。基于局部性原理，**在程序装入时，可以将程序的一部分装入内存，而将其余部分留在外存**，就可以启动程序执行。在程序执行过程中，**当所访问的信息不在内存时，由操作系统将所需要的部分调入内存,然后继续执行程序**。另一方面，操作系统将内存中**暂时不使用的内容换出到外存上，从而腾出空间存放将要调入内存的信息**。这样，系统好像为用户提供了一个比实际内存大得多的存储器，称为虚拟存储器。



<font color=red>分页和分段的由来: 操作系统是如何管理虚拟地址与物理地址之间的关系？主要有两种方式，分别是**内存分段和内存分页**</font>



### **30.4 内存分段**

> 分段就是将一个程序分成代码段、数据段和堆栈段等

1. 程序是由若干个逻辑分段组成的，如**可由代码段、数据段、栈段、堆段**组成。**不同的段是有不同的属性的，所以就用分段（Segmentation）的形式把这些段分离出来。**



<font color=blue>分段机制下，虚拟地址和物理地址是如何映射的？</font>

2. 分段机制下的虚拟地址由两部分组成，**段选择子**和**段内偏移量**

   - **段选择子**就保存在段寄存器里面。段选择子里面最重要的是**段号**，用作段表的索引。**段表**里面保存的是这个**段的基地址、段的界限和特权等级**等。

   - 虚拟地址中的**段内偏移量**应该位于 0 和段界限之间，如果段内偏移量是合法的，就将段基地址加上段内偏移量得到物理内存地址。
   - ![img](https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZfVYxicDjAjl4nMxlmyJk7rkTX5icicl09hKPabMh2LHcfiapeTumDtOUB3fydDdsIGuNKI0uUWia4k5oA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



3. 内存分段的缺陷
   - 第一个就是**内存碎片**的问题。
   - 第二个就是**内存交换的效率低**的问题。



### 30.5 内存分页

>  为了解决内存分段的内存碎片和内存交换效率低的问题，就出现了**内存分页**。

1. 什么是分页？

   <font color=blue>**分页是把整个虚拟和物理内存空间切成一段段固定尺寸的大小**。这样一个连续并且尺寸固定的内存空间，我们叫**页**（*Page*）。</font>

2. 分页机制下虚拟地址是如何映射到物理地址的?

   在分页机制下，虚拟地址分为两部分，**页号**和**页内偏移**。页号作为页表的索引，**页表**包含物理页每页所在**物理内存的基地址**，这个基地址与页内偏移的组合就形成了物理内存地址，见下图。

   ![img](https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZfVYxicDjAjl4nMxlmyJk7rkib51qUwtaEsS3asnE6jbeEuibuvlFr72mTPbiaGEs2E4S9ktuGs0NYziaQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

#### 30.5.1 缺页中断

当访问的虚拟地址不在页表中时，系统会产生一个缺页异常，这时就引发了一个缺页中断，操作系统会在外存中找到所缺的一页，将其调入内存。



### 30.6 段页式内存管理

段页式内存管理实现的方式：

- 先将程序划分为多个有逻辑意义的段，也就是前面提到的分段机制；
- 接着再把每个段划分为多个页，也就是对分段划分出来的连续空间，再划分固定大小的页；

这样，地址结构就由**段号、段内页号和页内位移**三部分组成。用于段页式地址变换的数据结构是每一个程序一张段表，每个段又建立一张页表，段表中的地址是页表的起始地址，而页表中的地址则为某页的物理页号，

段页式地址变换中要得到物理地址须经过三次内存访问：

- 第一次访问段表，得到页表起始地址；
- 第二次访问页表，得到物理页号；
- 第三次将物理页号与页内位移组合，得到物理地址。

![img](https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZfVYxicDjAjl4nMxlmyJk7rkibwZfO6ibiaiaoRoiaCSu16NoWkpEVUVG0hHbBVJKdsveIL4J1446ZIc6vw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

### 30.7 位图

> 1.[位图实现，处理大数据](https://blog.csdn.net/wenqiang1208/article/details/76724338)

位图法就是bitmap的缩写。所谓bitmap，就是用每一位来存放某种状态，适用于大规模数据，但数据状态又不是很多的情况。通常是用来判断某个数据存不存在的。

例如，要判断一千万个人的状态，每个人只有两种状态：男人，女人，可以用0，1表示。那么就可以开一个int数组，一个int有32个位，就可以表示32个人。操作的时候可以使用位操作。



#### **30.7.1 位图应用**

**1、给定100亿个整数，设计算法找到只出现一次的整数 。**

解决方法

将100亿个数分拆成1000份文件，再将每份文件里使用位图，并用两位bit表示数字出现的次数，00存出现0次的数，01存放出现1次的数，10存放出现多次的数，11舍弃，再将1000份中出现一次的数全部合并到一个文件里存放即可。

**2、给两个文件，分别有100亿个整数，我们只有1G内存，如何找到两个文件交集**

解决方法

将第一个文件里的数用哈希映射到1000个文件中，将第二个文件用同样的哈希映射到另1000个文件中，然后比较每个哈希映射相同的文件即

**3、1个文件有100亿个int，1G内存，设计算法找到出现次数不超过2次的所有整数**

解决方法：其实和问题1是一样的

将100亿个数分拆成1000份文件，再将每份文件里使用位图，并用两位bit表示数字出现的次数，00存出现0次的数，01存放出现1次的数，10存放出现2次的数，11舍弃，再将1000份中出现次数不超过二的数全部合并到一个文件里存放即可

**4、给40亿个不重复的unsigned int的整数，没排过序的，然后再给一个数，如何快速判断这个数是否在那40亿个数当中**

可以考虑使用位图bitmap，1个bit存储一个数字，那么40亿数据需要40亿bit 大约就是500M内存。
1M=1024*1024 * 8bit 大概8千万

用一个bit位来表示这个数据是否存在，1表示存在，0表示不存在。

**5、使用位图法进行整形数组排序**

首先遍历数组，得到数组的最大最小值，然后根据这个最大最小值来缩小bitmap的范围。这里需要注意对于int的负数，都要转化为unsigned int来处理，而且取位的时候，数字要减去最小值。



## 31. 文件系统

## 32. 什么是抢占

进程切换有自愿(Voluntary)和强制(Involuntary)之分，简单来说，自愿切换意味着进程需要等待某种资源，强制切换则与抢占(Preemption)有关。

抢占(Preemption)是指内核强行切换正在CPU上运行的进程，在抢占的过程中并不需要得到进程的配合，在随后的某个时刻被抢占的进程还可以恢复运行。发生抢占的原因主要有：进程的时间片用完了，或者优先级更高的进程来争夺CPU了。

抢占的过程分两步，第一步触发抢占，第二步执行抢占，这两步中间不一定是连续的，有些特殊情况下甚至会间隔相当长的时间：

1. 触发抢占：给正在CPU上运行的当前进程设置一个请求重新调度的标志(TIF_NEED_RESCHED)，仅此而已，此时进程并没有切换。
2. 执行抢占：在随后的某个时刻，内核会检查TIF_NEED_RESCHED标志并调用schedule()执行抢占。

抢占只在某些特定的时机发生，这是内核的代码决定的。



## 33. 操作系统的中断是什么

中断是指CPU对系统发生的某个事件做出的一种反应，CPU暂停正在执行的程序，保存现场后自动去执行相应的处理程序，处理完该事件后再返回中断处继续执行原来的程序。中断一般三类，**一种是由CPU外部引起的**，如I/O中断、时钟中断，**一种是来自CPU内部事件或程序执行中引起的中断**，例如程序非法操作，地址越界、浮点溢出），**最后一种是在程序中使用了系统调用引起的**。而中断处理一般分为中断响应和中断处理两个步骤，中断响应由硬件实施，中断处理主要由软件实施。

## 34. 什么时候使用多线程或者单线程

对于**处理时间短的服务**或者**启动频率高**的要用单线程，相反用多线程！无论什么情况下单线程能达到要求就不用多线程



## 35. 单核CPU上实现多线程程序对否要考虑加锁

在单核机器上写多线程程序，仍然需要线程锁。因为线程锁通常用来实现线程的同步和通信。在单核机器上的多线程程序，仍然存在线程同步的问题。因为在抢占式操作系统中，通常为每个线程分配一个时间片，当某个线程时间片耗尽时，操作系统会将其挂起，然后运行另一个线程。如果这两个线程共享某些数据，不使用线程锁的前提下，可能会导致共享数据修改引起冲突。

## 36. 操作系统中程序的内存结构

- 程序的内存结构包括**BSS段、数据段、代码段、栈区、堆区**
- 一个程序本质上都是由**BSS段、数据段、代码段**三个组成的
- BSS段
  使用来存放未初始化的全局变量和静态变量的一块内存区域。BSS段属于一块静态分配，程序结束后静态变量资源由系统自动释放。
- 数据段
  用来存放已经初始化的全局变量。
- 代码区
  存放程序执行代码的一块内存区域。这一块区域是只读区域。
- 栈区
  由编译器自动释放，存放函数的参数值、局部变量等。
- 堆区
  用于动态分配内存。由程序员申请分配和释放

## 37. pthread.h（多线程实现）常用API

1、创建

int pthread_create( pthread_t *tid, const pthread_attr_t *attr, void *(* func) (void *), void *arg );

attr: 线程属性包括：优先级、初始栈大小，是否应该成为一个守护线程。

缺省设置，NULL

后面是线程要执行的函数和参数

成功返回 0

2、等待一个给定线程终止

int pthread_join( pthread_t tid, void **status);

statues返回等待线程的返回值

3、得到自身的pid

pthread_t pthread_self(void);

4、pthread_detach函数

int pthread_detach( pthread_t pid );

把指定的线程转变为脱离状态

一个线程或者是可汇合的（joinable，缺省值），或者是脱离的（detached）。当一个可汇合的线程终止时，它的线程ID和退出状态将留到另一个线程对它调用pthread_join。脱离线程却象守护进程：当它们终止的时，所有相关资源都被释放，我们不能等待它们终止。如果一个线程需要知道另一个线程什么时候终止，那就最好好吃第二个线程的可汇合状态。

本函数通常由想让自己脱离的线程调用，如下语句

pthread_detach( pthread_self() );

5、终止一个线程

void pthread_exit( void *statue );

指针sttus不能指向局部于调用对象，因为线程终止时这样的对象也消失

# 四、算法

## 1. 十大经典排序算法

![img](https://images2018.cnblogs.com/blog/849589/201804/849589-20180402133438219-1946132192.png)

稳定排序：归并排序、冒泡排序、插入排序

$[Math Processing Error]O(nlogn)$的算法：堆排序、快速排序、归并排序

## 2. 什么是哈希冲突，如何解决

> 1. [什么是哈希冲突，如何解决](https://zhuanlan.zhihu.com/p/29520044)

**什么是哈希冲突**

​        假设hash表的大小为9（即有9个槽），现在要把一串数据（5,28,19,15,20,33,12,17,10）存到表里。简单计算一下：hash(5)=5, 所以数据5应该放在hash表的第5个槽里；hash(28)=1，所以数据28应该放在hash表的第1个槽里；hash(19)=1，也就是说，数据19也应该放在hash表的第1个槽里——于是就造成了碰撞（也称为冲突）。

**如何解决哈希冲突**

- 开放定址法

  ​        这种方法也称再散列法，其基本思想是：当关键字key的哈希地址p=H（key）出现冲突时，以p为基础，产生另一个哈希地址p1，如果p1仍然冲突，再以p为基础，产生另一个哈希地址p2，…，直到找出一个不冲突的哈希地址pi ，将相应元素存入其中。

  - **线性探测再散列**
  - **二次探测再散列**
  - **伪随机探测再散列**

- 再哈希法

  这种方法是同时构造多个不同的哈希函数：

  $$H_i=RH1（ key ）   i=1，2，…，k$$

  当哈希地址$Hi=RH1（key）$发生冲突时，再计算 $Hi=RH2（key）……，$ 直到冲突不再产生。这种方法不易产生聚集，但增加了计算时间。

- 链地址法

  ​        这种方法的基本思想是将所有哈希地址为i的元素构成一个称为同义词链的单链表，并将单链表的头指针存在哈希表的第i个单元中，因而查找、插入和删除主要在同义词链中进行。链地址法适用于经常进行插入和删除的情况。

- 建立公共溢出区

  ​        这种方法的基本思想是：将哈希表分为基本表和溢出表两部分，凡是和基本表发生冲突的元素，一律填入溢出表。





# 五、数据库

> 1. [数据库面试题](https://swenfang.github.io/2019/05/12/%E9%9D%A2%E8%AF%95%E6%80%BB%E7%BB%93/%E6%95%B0%E6%8D%AE%E5%BA%93%E9%9D%A2%E8%AF%95%E9%A2%98/)
> 2. [MySQL索引背后的数据结构及算法原理](http://blog.codinglabs.org/articles/theory-of-mysql-index.html)

## 数据库中的数据结构

### 1. B-Tree和B+Tree

目前大部分数据库系统及文件系统都采用B-Tree或其变种B+Tree作为索引结构，在本文的下一节会结合存储器原理及计算机存取原理讨论为什么B-Tree和B+Tree在被如此广泛用于索引，这一节先单纯从数据结构角度描述它们。

#### 1.1 B-Tree

为了描述B-Tree，首先定义一条数据记录为一个二元组[key, data]，key为记录的键值，对于不同数据记录，key是互不相同的；data为数据记录除key外的数据。那么B-Tree是满足下列条件的数据结构：

- d为大于1的一个正整数，称为B-Tree的度。

- h为一个正整数，称为B-Tree的高度。

- 每个非叶子节点由n-1个key和n个指针组成，其中d<=n<=2d。

- 每个叶子节点最少包含一个key和两个指针，最多包含2d-1个key和2d个指针，叶节点的指针均为null 。

- 所有叶节点具有相同的深度，等于树高h。

- key和指针互相间隔，节点两端是指针。

- 一个节点中的key从左到右非递减排列。

- 所有节点组成树结构。

- 每个指针要么为null，要么指向另外一个节点。

- 如果某个指针在节点node最左边且不为null，则其指向节点的所有key小于v(key1)，其中v(key1)为node的第一个key的值。

- 如果某个指针在节点node最右边且不为null，则其指向节点的所有key大于v(keym)，其中v(keym)为node的最后一个key的值。

- 如果某个指针在节点node的左右相邻key分别是keyi和keyi+1且不为null，则其指向节点的所有key小于v(keyi+1)且大于v(keyi)。

图2是一个d=2的B-Tree示意图。

![img](http://blog.codinglabs.org/uploads/pictures/theory-of-mysql-index/2.png)

图2

#### 1.2 B+Tree

B-Tree有许多变种，其中最常见的是B+Tree，例如MySQL就普遍使用B+Tree实现其索引结构。

与B-Tree相比，B+Tree有以下不同点：

- <font color=red>每个节点的指针上限为2d而不是2d+1，也就是只有节点的右侧存在指针</font>

- <font color=red>内节点不存储data，只存储key；叶子节点不存储指针。</font>

图3是一个简单的B+Tree示意。

![img](http://blog.codinglabs.org/uploads/pictures/theory-of-mysql-index/3.png)

图3

由于并不是所有节点都具有相同的域，因此B+Tree中叶节点和内节点一般大小不同。这点与B-Tree不同，虽然B-Tree中不同节点存放的key和指针可能数量不一致，但是每个节点的域和上限是一致的，所以在实现中B-Tree往往对每个节点申请同等大小的空间。

一般来说，B+Tree比B-Tree更适合实现外存储索引结构，具体原因与外存储器原理及计算机存取原理有关，将在下面讨论。

#### 1.3 带有顺序访问指针的B+Tree

一般在数据库系统或文件系统中使用的B+Tree结构都在经典B+Tree的基础上进行了优化，增加了顺序访问指针。

![img](http://blog.codinglabs.org/uploads/pictures/theory-of-mysql-index/4.png)

图4

如图4所示，在B+Tree的每个叶子节点增加一个指向相邻叶子节点的指针，就形成了带有顺序访问指针的B+Tree。做这个优化的目的是为了提高区间访问的性能，例如图4中如果要查询key为从18到49的所有数据记录，当找到18后，只需顺着节点和指针顺序遍历就可以一次性访问到所有数据节点，极大提到了区间查询效率。

这一节对B-Tree和B+Tree进行了一个简单的介绍，下一节结合存储器存取原理介绍为什么目前B+Tree是数据库系统实现索引的首选数据结构。

### 2. 为什么使用B-Tree（B+Tree）

上文说过，红黑树等数据结构也可以用来实现索引，但是文件系统及数据库系统普遍采用B-/+Tree作为索引结构，这一节将结合计算机组成原理相关知识讨论B-/+Tree作为索引的理论基础。

一般来说，索引本身也很大，不可能全部存储在内存中，因此索引往往以索引文件的形式存储的磁盘上。这样的话，索引查找过程中就要产生磁盘I/O消耗，相对于内存存取，I/O存取的消耗要高几个数量级，所以评价一个数据结构作为索引的优劣最重要的指标就是在查找过程中磁盘I/O操作次数的渐进复杂度。换句话说，索引的结构组织要尽量减少查找过程中磁盘I/O的存取次数。下面先介绍内存和磁盘存取原理，然后再结合这些原理分析B-/+Tree作为索引的效率。

#### 2.1 主存存取原理

目前计算机使用的主存基本都是随机读写存储器（RAM），现代RAM的结构和存取原理比较复杂，这里本文抛却具体差别，抽象出一个十分简单的存取模型来说明RAM的工作原理。

![img](http://blog.codinglabs.org/uploads/pictures/theory-of-mysql-index/5.png)

图5

从抽象角度看，主存是一系列的存储单元组成的矩阵，每个存储单元存储固定大小的数据。每个存储单元有唯一的地址，现代主存的编址规则比较复杂，这里将其简化成一个二维地址：通过一个行地址和一个列地址可以唯一定位到一个存储单元。图5展示了一个4 x 4的主存模型。

主存的存取过程如下：

当系统需要读取主存时，则将地址信号放到地址总线上传给主存，主存读到地址信号后，解析信号并定位到指定存储单元，然后将此存储单元数据放到数据总线上，供其它部件读取。

写主存的过程类似，系统将要写入单元地址和数据分别放在地址总线和数据总线上，主存读取两个总线的内容，做相应的写操作。

这里可以看出，主存存取的时间仅与存取次数呈线性关系，因为不存在机械操作，两次存取的数据的“距离”不会对时间有任何影响，例如，先取A0再取A1和先取A0再取D3的时间消耗是一样的。

#### 2.2 磁盘存取原理

上文说过，索引一般以文件形式存储在磁盘上，索引检索需要磁盘I/O操作。与主存不同，磁盘I/O存在机械运动耗费，因此磁盘I/O的时间消耗是巨大的。

图6是磁盘的整体结构示意图。

![img](http://blog.codinglabs.org/uploads/pictures/theory-of-mysql-index/6.png)

图6

一个磁盘由大小相同且同轴的圆形盘片组成，磁盘可以转动（各个磁盘必须同步转动）。在磁盘的一侧有磁头支架，磁头支架固定了一组磁头，每个磁头负责存取一个磁盘的内容。磁头不能转动，但是可以沿磁盘半径方向运动（实际是斜切向运动），每个磁头同一时刻也必须是同轴的，即从正上方向下看，所有磁头任何时候都是重叠的（不过目前已经有多磁头独立技术，可不受此限制）。

图7是磁盘结构的示意图。

![img](http://blog.codinglabs.org/uploads/pictures/theory-of-mysql-index/7.png)

图7

盘片被划分成一系列同心环，圆心是盘片中心，每个同心环叫做一个磁道，所有半径相同的磁道组成一个柱面。磁道被沿半径线划分成一个个小的段，每个段叫做一个扇区，每个扇区是磁盘的最小存储单元。为了简单起见，我们下面假设磁盘只有一个盘片和一个磁头。

当需要从磁盘读取数据时，系统会将数据逻辑地址传给磁盘，磁盘的控制电路按照寻址逻辑将逻辑地址翻译成物理地址，即确定要读的数据在哪个磁道，哪个扇区。为了读取这个扇区的数据，需要将磁头放到这个扇区上方，为了实现这一点，磁头需要移动对准相应磁道，这个过程叫做寻道，所耗费时间叫做寻道时间，然后磁盘旋转将目标扇区旋转到磁头下，这个过程耗费的时间叫做旋转时间。

#### 2.3 局部性原理与磁盘预读

由于存储介质的特性，磁盘本身存取就比主存慢很多，再加上机械运动耗费，磁盘的存取速度往往是主存的几百分分之一，因此为了提高效率，要尽量减少磁盘I/O。为了达到这个目的，磁盘往往不是严格按需读取，而是每次都会预读，即使只需要一个字节，磁盘也会从这个位置开始，顺序向后读取一定长度的数据放入内存。这样做的理论依据是计算机科学中著名的局部性原理：

当一个数据被用到时，其附近的数据也通常会马上被使用。

程序运行期间所需要的数据通常比较集中。

由于磁盘顺序读取的效率很高（不需要寻道时间，只需很少的旋转时间），因此对于具有局部性的程序来说，预读可以提高I/O效率。

预读的长度一般为页（page）的整倍数。页是计算机管理存储器的逻辑块，硬件及操作系统往往将主存和磁盘存储区分割为连续的大小相等的块，每个存储块称为一页（在许多操作系统中，页得大小通常为4k），主存和磁盘以页为单位交换数据。当程序要读取的数据不在主存中时，会触发一个缺页异常，此时系统会向磁盘发出读盘信号，磁盘会找到数据的起始位置并向后连续读取一页或几页载入内存中，然后异常返回，程序继续运行。

#### 2.4 B-/+Tree索引的性能分析

到这里终于可以分析B-/+Tree索引的性能了。

上文说过一般使用磁盘I/O次数评价索引结构的优劣。先从B-Tree分析，根据B-Tree的定义，可知检索一次最多需要访问h个节点。数据库系统的设计者巧妙利用了磁盘预读原理，将一个节点的大小设为等于一个页，这样每个节点只需要一次I/O就可以完全载入。为了达到这个目的，在实际实现B-Tree还需要使用如下技巧：

每次新建节点时，直接申请一个页的空间，这样就保证一个节点物理上也存储在一个页里，加之计算机存储分配都是按页对齐的，就实现了一个node只需一次I/O。

B-Tree中一次检索最多需要h-1次I/O（根节点常驻内存），渐进复杂度为O(h)=O(logdN)O(h)=O(logdN)。一般实际应用中，出度d是非常大的数字，通常超过100，因此h非常小（通常不超过3）。

综上所述，用B-Tree作为索引结构效率是非常高的。

而红黑树这种结构，h明显要深的多。由于逻辑上很近的节点（父子）物理上可能很远，无法利用局部性，所以红黑树的I/O渐进复杂度也为O(h)，效率明显比B-Tree差很多。

上文还说过，B+Tree更适合外存索引，原因和内节点出度d有关。从上面分析可以看到，d越大索引的性能越好，而出度的上限取决于节点内key和data的大小：

dmax=floor(pagesize/(keysize+datasize+pointsize))dmax=floor(pagesize/(keysize+datasize+pointsize))

floor表示向下取整。由于B+Tree内节点去掉了data域，因此可以拥有更大的出度，拥有更好的性能。

这一章从理论角度讨论了与索引相关的数据结构与算法问题，下一章将讨论B+Tree是如何具体实现为MySQL中索引，同时将结合MyISAM和InnDB存储引擎介绍非聚集索引和聚集索引两种不同的索引实现形式。









## 1. 事务

### 1.1 什么是事务

事务指的是满足 ACID 特性的一组操作，可以通过 Commit 提交一个事务，也可以使用 Rollback 进行回滚。

**数据库ACID**

- 原子性（Atomicity）

> 原子性是指事务是一个不可分割的工作单位，事务中的操作要么全部成功，要么全部失败。比如在同一个事务中的SQL语句，要么全部执行成功，要么全部执行失败。

回滚可以用日志来实现，日志记录着事务所执行的修改操作，在回滚时反向执行这些修改操作即可。

- 一致性（Consistency）

> 事务必须使数据库从一个一致性状态变换到另外一个一致性状态。

以转账为例子，A向B转账，假设转账之前这两个用户的钱加起来总共是2000，那么A向B转账之后，不管这两个账户怎么转，A用户的钱和B用户的钱加起来的总额还是2000，这个就是事务的一致性。

- 隔离性（Isolation）

> 隔离性是当多个用户并发访问数据库时，比如操作同一张表时，数据库为每一个用户开启的事务，不能被其他事务的操作所干扰，多个并发事务之间要相互隔离。

即要达到这么一种效果：对于任意两个并发的事务 T1 和 T2，在事务 T1 看来，T2 要么在 T1 开始之前就已经结束，要么在 T1 结束之后才开始，这样每个事务都感觉不到有其他事务在并发地执行。

- 持久性（Durability）

> 一旦事务提交，则其所做的修改将会永远保存到数据库中。即使系统发生崩溃，事务执行的结果也不能丢失。

```
可以通过数据库备份和恢复来实现，在系统发生奔溃时，使用备份的数据库进行数据恢复。
```

事务的 ACID 特性概念简单，但不是很好理解，主要是因为这几个特性不是一种平级关系：

- 只有满足一致性，事务的执行结果才是正确的。
- 在无并发的情况下，事务串行执行，隔离性一定能够满足。此时要只要能满足原子性，就一定能满足一致性。
- 在并发的情况下，多个事务并发执行，事务不仅要满足原子性，还需要满足隔离性，才能满足一致性。
- 事务满足持久化是为了能应对数据库奔溃的情况。

[![img](https://github.com/frank-lam/fullstack-tutorial/raw/master/notes/assets/a58e294a-615d-4ea0-9fbf-064a6daec4b2-1534474592177.png)](https://github.com/frank-lam/fullstack-tutorial/blob/master/notes/assets/a58e294a-615d-4ea0-9fbf-064a6daec4b2-1534474592177.png)

### 1.2 事务的隔离级别

- 串行化 (Serializable)

　　所有事务一个接着一个的执行，这样可以避免幻读 (phantom read)，对于基于锁来实现并发控制的数据库来说，串行化要求在执行范围查询的时候，需要获取范围锁，如果不是基于锁实现并发控制的数据库，则检查到有违反串行操作的事务时，需回滚该事务。

-  可重复读 (Repeated Read)

　　所有被 Select 获取的数据都不能被修改，这样就可以避免一个事务前后读取数据不一致的情况。但是却没有办法控制幻读，因为这个时候其他事务不能更改所选的数据，但是可以增加数据，即前一个事务有读锁但是没有范围锁，为什么叫做可重复读等级呢？那是因为该等级解决了下面的不可重复读问题。

　　引申：现在主流数据库都使用 MVCC 并发控制，使用之后RR（可重复读）隔离级别下是不会出现幻读的现象。

- 读已提交 (Read Committed)

　　被读取的数据可以被其他事务修改，这样可能导致不可重复读。也就是说，事务读取的时候获取读锁，但是在读完之后立即释放(不需要等事务结束)，而写锁则是事务提交之后才释放，释放读锁之后，就可能被其他事务修改数据。该等级也是 SQL Server 默认的隔离等级。

- 读未提交 (Read Uncommitted)

　　最低的隔离等级，允许其他事务看到没有提交的数据，会导致脏读。

**总结**

- 四个级别逐渐增强，每个级别解决一个问题，每个级别解决一个问题，事务级别遇到，性能越差，大多数环境(Read committed 就可以用了)

| 隔离级别 | 脏读 | 不可重复读 | 幻读 |
| :------- | :--- | :--------- | :--- |
| 未提交读 | √    | √          | √    |
| 提交读   | ×    | √          | √    |
| 可重复读 | ×    | ×          | √    |
| 可串行化 | ×    | ×          | ×    |



### 1.3 什么时候用到事务


举个例子：把一条数据插入到俩张表的时候，就要用到事务了。

如果数据在插入第一张表的时候成功了，在插入第二张表的时候失败了，怎么办？要么保证全部成功（提交），要么就回滚（一条也别成功）。才能保证数据的准确性。

## 2. 存储引擎

### 1. MyISAM

MySQL 5.5 版本之前的默认存储引擎，在 `5.0` 以前最大表存储空间最大 `4G`，`5.0` 以后最大 `256TB`。

Myisam 存储引擎由 `.myd`（数据）和 `.myi`（索引文件）组成，`.frm`文件存储表结构（所以存储引擎都有）

**特性**

- 并发性和锁级别 （对于读写混合的操作不好，为表级锁，写入和读互斥）
- 表损坏修复
- Myisam 表支持的索引类型（全文索引）
- Myisam 支持表压缩（压缩后，此表为只读，不可以写入。使用 myisampack 压缩）

**应用场景**

- 没有事务
- 只读类应用（插入不频繁，查询非常频繁）
- 空间类应用（唯一支持空间函数的引擎）
- 做很多 count 的计算

### 2. InnoDB

MySQL 5.5 及之后版本的默认存储引擎

**特性**

- InnoDB为事务性存储引擎
- 完全支持事物的 ACID 特性
- Redo log （实现事务的持久性） 和 Undo log（为了实现事务的原子性，存储未完成事务log，用于回滚）
- InnoDB支持行级锁
- 行级锁可以最大程度的支持并发
- 行级锁是由存储引擎层实现的

**应用场景**

- 可靠性要求比较高，或者要求事务
- 表更新和查询都相当的频繁，并且行锁定的机会比较大的情况。

### 3. MyISAM和InnoDB引擎的区别

**区别：**

- MyISAM 不支持外键，而 InnoDB 支持
- MyISAM 是非事务安全型的，而 InnoDB 是事务安全型的。
- MyISAM 锁的粒度是表级，而 InnoDB 支持行级锁定。
- MyISAM 支持全文类型索引，而 InnoDB 不支持全文索引。
- MyISAM 相对简单，所以在效率上要优于 InnoDB，小型应用可以考虑使用 MyISAM。
- MyISAM 表是保存成文件的形式，在跨平台的数据转移中使用 MyISAM 存储会省去不少的麻烦。
- InnoDB 表比 MyISAM 表更安全，可以在保证数据不会丢失的情况下，切换非事务表到事务表（alter table tablename type=innodb）。

**应用场景：**

- MyISAM 管理非事务表。它提供高速存储和检索，以及全文搜索能力。如果应用中需要执行大量的 SELECT 查询，那么 MyISAM 是更好的选择。

- InnoDB 用于事务处理应用程序，具有众多特性，包括 ACID 事务支持。如果应用中需要执行大量的 INSERT 或 UPDATE 操作，则应该使用 InnoDB，这样可以提高多用户并发操作的性能。


### 4. MyISAM索引和InnoDB索引的区别

- InnoDB索引是聚簇索引，MyISAM索引是非聚簇索引。
- InnoDB的主键索引的叶子节点存储着行数据，因此主键索引非常高效。
- MyISAM索引的叶子节点存储的是行数据地址，需要再寻址一次才能得到数据。
- InnoDB非主键索引的叶子节点存储的是主键和其他带索引的列数据，因此查询时做到覆盖索引会非常高效。

## 2. 索引

> 1. [Mysql索引面试题](https://www.cnblogs.com/williamjie/p/11187470.html)
> 2. [MySQL面试题](https://blog.csdn.net/ThinkWon/article/details/104778621?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param)

### 1. 索引分类

**概念**：**索引**(类似于书的目录)其实是一种数据结构，能够帮助我们快速的检索数据库中的数据。常见的MySQL主要有两种结构：Hash索引和B+ Tree索引。**InnoDB引擎**，默认的是**B+树**。

|                              |                                                 |        |        |        |
| :--------------------------- | :---------------------------------------------- | :----- | :----- | :----- |
| 特性                         | 说明                                            | InnoDB | MyISAM | MEMORY |
| B树索引 (B-tree indexes)     | 自增ID物理连续性更高， 二叉树，红黑树高度不可控 | √      | √      | √      |
| R树索引 (R-tree indexes)     | 空间索引                                        |        | √      |        |
| 哈希索引 (Hash indexes)      | 无法做范围查询                                  | √      |        | √      |
| 全文索引 (Full-text indexes) |                                                 | √      | √      |        |



### 2. mysql中的索引类型有哪些

**2.1 从数据结构角度**

- B+树索引(O(log(n)))：

  关于B+树索引，可以参考 [MySQL索引背后的数据结构及算法原理](http://blog.codinglabs.org/articles/theory-of-mysql-index.html)

- hash索引：
  a、 仅仅能满足”=”,”IN”和”<=>”查询，不能使用范围查询
  b、 其检索效率非常高，索引的检索可以一次定位，不像B-Tree 索引需要从根节点到枝节点，最后才能访问到页节点这样多次的IO访问，所以 Hash 索引的查询效率要远高于 B-Tree 索引
  c、只有Memory存储引擎显示支持hash索引

- fulltext索引（现在MyISAM和InnoDB引擎都支持了）

- R-Tree索引（用于对GIS数据类型创建SPATIAL索引）

**2.2 从物理存储角度**

- **聚簇索引**：将数据存储与索引放到了一块，找到索引也就找到了数据
- **非聚簇索引**：将数据存储于索引分开结构，索引结构的叶子节点指向了数据的对应行

**2.3 从逻辑角度**

- 主键索引：主键索引是一种特殊的唯一索引，不允许有空值

- 普通索引或者单列索引 : 即一个索引只包含单个列，一个表可以有多个单列索引

- 多列索引（复合索引）：复合索引指多个字段上创建的索引，只有在查询条件中使用了创建索引时的第一个字段，索引才会被使用。使用复合索引时遵循最左前缀集合

- 唯一索引或者非唯一索引

- 空间索引：空间索引是对空间数据类型的字段建立的索引，MYSQL中的空间数据类型有4种，分别是GEOMETRY、POINT、LINESTRING、POLYGON。

  MYSQL使用SPATIAL关键字进行扩展，使得能够用于创建正规索引类型的语法创建空间索引。创建空间索引的列，必须将其声明为NOT NULL，空间索引只能在存储引擎为MYISAM的表中创建

### 3. **为什么采用B+ 树？相对Hash索引的优势是什么**

- 因为Hash索引底层是哈希表，哈希表是一种以key-value存储数据的结构，所以**多个数据在存储关系上是完全没有任何顺序关系的**，所以，对于区间查询是无法直接通过索引查询的，就需要全表扫描。**所以，哈希索引只适用于等值查询的场景。**
- **而B+ 树是一种多路平衡查询树，所以他的节点是天然有序的**（左子节点小于父节点、父节点小于右子节点），所以对于范围查询的时候不需要做全表扫描，因此**支持范围查找**。

### 4. B+ Tree索引和Hash索引

#### 4.1 Hash索引和B+索引的区别：

- 哈希索引适合等值查询，但是无法进行范围查询 
- 哈希索引没办法利用索引完成排序 
- 哈希索引不支持多列联合索引的最左匹配规则 
- 如果有大量重复键值的情况下，哈希索引的效率会很低，因为存在哈希碰撞问题

#### 4.2 Hash索引和B+索引的应用场景

1. 大多数场景下，都会有组合查询，范围查询、排序、分组、模糊查询等查询特征，Hash 索引无法满足要求，建议数据库使用B+树索引。
2. 在离散型高，数据基数大，且等值查询时候，Hash索引有优势。

#### 4.3 如何解决Hash冲突问题

> 1. [什么是哈希冲突，如何解决](https://zhuanlan.zhihu.com/p/29520044)

**什么是哈希冲突**

假设hash表的大小为9（即有9个槽），现在要把一串数据（5,28,19,15,20,33,12,17,10）存到表里。简单计算一下：hash(5)=5, 所以数据5应该放在hash表的第5个槽里；hash(28)=1，所以数据28应该放在hash表的第1个槽里；hash(19)=1，也就是说，数据19也应该放在hash表的第1个槽里——于是就造成了碰撞（也称为冲突）。

**如何解决哈希冲突**

> - 开放定址法
>
> ​        这种方法也称再散列法，其基本思想是：当关键字key的哈希地址p=H（key）出现冲突时，以p为基础，产生另一个哈希地址p1，如果p1仍然冲突，再以p为基础，产生另一个哈希地址p2，…，直到找出一个不冲突的哈希地址pi ，将相应元素存入其中。
>
>   - **线性探测再散列**
> - **二次探测再散列**
>   - **伪随机探测再散列**
>
>   - 再哈希法
> 
> 这种方法是同时构造多个不同的哈希函数：
>
> $$H_i=RH1（ key ）   i=1，2，…，k$$
>
> 当哈希地址$Hi=RH1（key）$发生冲突时，再计算 $Hi=RH2（key）……，$ 直到冲突不再产生。这种方法不易产生聚集，但增加了计算时间。
> 
>   - 链地址法
>
> ​        这种方法的基本思想是将所有哈希地址为i的元素构成一个称为同义词链的单链表，并将单链表的头指针存在哈希表的第i个单元中，因而查找、插入和删除主要在同义词链中进行。链地址法适用于经常进行插入和删除的情况。
>
>   - 建立公共溢出区
>
>   ​        这种方法的基本思想是：将哈希表分为基本表和溢出表两部分，凡是和基本表发生冲突的元素，一律填入溢出表。
>
> 

### 4. **B+ Tree的叶子节点都可以存哪些东西**

可以是主键的值，也可以是整行的数据。

### 5. 聚簇索引和非聚簇索引

#### 5.1 什么是聚簇索引和非聚簇索引

- 索引B+ Tree的叶子节点存储了整行数据的是**主键索引**，也被称之为**聚簇索引**。

- 索引B+ Tree的叶子节点存储了主键的值的是**非主键索引**，也被称之为**非聚簇索引**。

  > - 聚簇索引：将数据存储与索引放到了一块，找到索引也就找到了数据
  > - 非聚簇索引：将数据存储于索引分开结构，索引结构的叶子节点指向了数据的对应行

#### 5.2 聚簇索引和非聚簇索引的查找过程

![img](https://blog.haohtml.com/wp-content/uploads/2017/01/mysql_0.jpg)

![img](https://blog.haohtml.com/wp-content/uploads/2017/01/timg.jpg)

**聚簇索引的查找方式过程**

1. InnoDB使用的是聚簇索引，将**主键组织到一棵B+树**中，而**行数据就储存在叶子节点**上，若使用"where id = 14"这样的条件查找主键，则**按照B+树的检索算法即可查找到对应的叶节点，之后获得行数据**。
2. 若**对Name列进行条件搜索，则需要两个步骤**：**第一步在辅助索引B+树中检索Name，到达其叶子节点获取对应的主键**。第二步**使用主键在主索引B+树种再执行一次B+树检索操作，最终到达叶子节点即可获取整行数据**。（**重点在于通过其他键需要建立辅助索引**）

**非聚簇索引的查找过程**

1. MyISM使用的是非聚簇索引，**非聚簇索引的两棵B+树看上去没什么不同**，节点的结构完全一致只是存储的内容不同而已，主键索引B+树的节点存储了主键，辅助键索引B+树存储了辅助键。表数据存储在独立的地方，这两颗B+树的叶子节点都使用一个地址指向真正的表数据，对于表数据来说，这两个键没有任何差别。由于**索引树是独立的，通过辅助键检索无需访问主键的索引树**。



当通过聚簇索引查找目标数据时理论上比非聚簇索引要快，因为非聚簇索引定位到对应主键时还要多一次目标记录查找。

> 为什么？
>
> 因为主键索引树的叶子节点直接就是我们要查询的整行数据了。而非主键索引的叶子节点是主键的值，查到主键的值以后，还需要再通过主键的值再进行一次查询。
>

### 6. 聚簇索引的优势和劣势

**6.1 聚簇索引的优势**

看上去聚簇索引的效率明显要低于非聚簇索引，因为**每次使用辅助索引检索都要经过两次B+树查找**，这不是多此一举吗？聚簇索引的优势在哪？

1. 由于**行数据和叶子节点存储在一起，同一页中会有多条行数据，访问同一数据页不同行记录时，已经把页加载到了Buffer中，再次访问的时候，会在内存中完成访问**，不必访问磁盘。这样**主键和行数据是一起被载入内存的，找到叶子节点就可以立刻将行数据返回**了，**如果按照主键Id来组织数据，获得数据更快**。
2. **辅助索引使用主键作为"指针"而不是使用地址值作为指针的好处**是，**减少了当出现行移动或者数据页分裂时辅助索引的维护工作**，**使用主键值当作指针会让辅助索引占用更多的空间，换来的好处是InnoDB在移动行时无须更新辅助索引中的这个"指针"**。**也就是说行的位置（实现中通过16K的Page来定位）会随着数据库里数据的修改而发生变化（前面的B+树节点分裂以及Page的分裂），使用聚簇索引就可以保证不管这个主键B+树的节点如何变化，辅助索引树都不受影响**。
3. 聚簇索引适合用在排序的场合，非聚簇索引不适合
4. 取出一定范围数据的时候，使用用聚簇索引
5. 二级索引需要两次索引查找，而不是一次才能取到数据，因为存储引擎第一次需要通过二级索引找到索引的叶子节点，从而找到数据的主键，然后在聚簇索引中用主键再次查找索引，再找到数据
6. 可以把**相关数据保存在一起**。例如实现电子邮箱时，可以根据用户 ID 来聚集数据，这样只需要从磁盘读取少数的数据页就能获取某个用户的全部邮件。如果没有使用聚簇索引，则每封邮件都可能导致一次磁盘 I/O。  

**6.2 聚簇索引的劣势**

1. **维护索引很昂贵，特别是插入新行或者主键被更新导至要分页(page split)的时候**。建议在大量插入新行后，选在负载较低的时间段，通过OPTIMIZE TABLE优化表，因为必须被移动的行数据可能造成碎片。使用独享表空间可以弱化碎片
2. 表因为使用UUId（随机ID）作为主键，使数据存储稀疏，这就会出现聚簇索引有可能有比全表扫面更慢，

![img](https://ask.qcloudimg.com/http-save/yehe-2823867/iywj5q0imm.jpeg?imageView2/2/w/1620)

所以建议使用int的auto_increment作为主键

![img](https://ask.qcloudimg.com/http-save/yehe-2823867/td2fso5cth.jpeg?imageView2/2/w/1620)

主键的值是顺序的，所以 InnoDB 把每一条记录都存储在上一条记录的后面。当达到页的最大填充因子时（InnoDB 默认的最大填充因子是页大小的 15/16，留出部分空间用于以后修改），下一条记录就会写入新的页中。一旦数据按照这种顺序的方式加载，主键页就会近似于被顺序的记录填满（二级索引页可能是不一样的）

1. 如果主键比较大的话，那辅助索引将会变的更大，因为**辅助索引的叶子存储的是主键值；过长的主键值，会导致非叶子节点占用占用更多的物理空间**

## 3. mysql的优化，三种删除之间的区别



# Linux

## 1. fork()和vfork()的区别

- fork( )的子进程拷贝父进程的数据段和代码段；vfork( )的子进程与父进程共享数据段
- fork( )的父子进程的执行次序不确定；vfork( )保证子进程先运行，在调用exec或exit之前与父进程数据是共享的，在它调用exec或exit之后父进程才可能被调度运行。
- vfork( )保证子进程先运行，在它调用exec或exit之后父进程才可能被调度运行。如果在调用这两个函数之前子进程依赖于父进程的进一步动作，则会导致死锁。
- 当需要改变共享数据段中变量的值，则拷贝父进程。

## 2. 常用的Linux命令

**常用指令**

ls　　        显示文件或目录

​     -l           列出文件详细信息l(list)

​     -a          列出当前目录下所有文件及目录，包括隐藏的a(all)

mkdir         创建目录

​     -p           创建目录，若无父目录，则创建p(parent)

cd               切换目录

touch          创建空文件

echo            创建带有内容的文件。

cat              查看文件内容

cp                拷贝

mv               移动或重命名

rm               删除文件

​     -r            递归删除，可删除子目录及文件

​     -f            强制删除

find              在文件系统中搜索某文件

wc                统计文本中行数、字数、字符数

grep             在文本文件中查找某个字符串

rmdir           删除空目录

tree             树形结构显示目录，需要安装tree包

pwd              显示当前目录

ln                  创建链接文件

more、less  分页显示文本文件内容

head、tail    显示文件头、尾内容

ctrl+alt+F1  命令行全屏模式

 

**系统管理命令**

stat              显示指定文件的详细信息，比ls更详细

who               显示在线登陆用户

whoami          显示当前操作用户

hostname      显示主机名

uname           显示系统信息

top                动态显示当前耗费资源最多进程信息

ps                  显示瞬间进程状态 ps -aux

du                  查看目录大小 du -h /home带有单位显示目录信息；

df                  查看磁盘大小 df -h 带有单位显示磁盘信息
                      df -k：以KB为单位显示磁盘使用量和占用率；
                      df -m：以Mb为单位显示磁盘使用量和占用率；

ifconfig          查看网络情况

ping                测试网络连通

netstat          显示网络状态信息

man                命令不会用了，找男人  如：man ls

clear              清屏

alias               对命令重命名 如：alias showmeit="ps -aux" ，另外解除使用unaliax showmeit

kill                 杀死进程，可以先用ps 或 top命令查看进程的id，然后再用kill命令杀死进程。

 

**打包压缩相关命令**

gzip：

bzip2：

tar:                打包压缩

​     -c              归档文件

​     -x              压缩文件

​     -z              gzip压缩文件

​     -j              bzip2压缩文件

​     -v              显示压缩或解压缩过程 v(view)

​     -f              使用档名

例：

tar -cvf /home/abc.tar /home/abc              只打包，不压缩

tar -zcvf /home/abc.tar.gz /home/abc        打包，并用gzip压缩

tar -jcvf /home/abc.tar.bz2 /home/abc      打包，并用bzip2压缩

当然，如果想解压缩，就直接替换上面的命令  tar -cvf  / tar -zcvf  / tar -jcvf 中的“c” 换成“x” 就可以了。

 

**关机/重启机器**

shutdown

​     -r             关机重启

​     -h             关机不重启

​     now          立刻关机

halt               关机

reboot          重启

 

**Linux管道**

将一个命令的标准输出作为另一个命令的标准输入。也就是把几个命令组合起来使用，后一个命令除以前一个命令的结果。

例：grep -r "close" /home/* | more       在home目录下所有文件中查找，包括close的文件，并分页输出。

 

**Linux软件包管理**

**dpkg** (Debian Package)管理工具，软件包名以.deb后缀。这种方法适合系统不能联网的情况下。

比如安装tree命令的安装包，先将tree.deb传到Linux系统中。再使用如下命令安装。

sudo dpkg -i tree_1.5.3-1_i386.deb         安装软件

sudo dpkg -r tree                                     卸载软件

 

注：将tree.deb传到Linux系统中，有多种方式。VMwareTool，使用挂载方式；使用winSCP工具等；

**APT**（Advanced Packaging Tool）高级软件工具。这种方法适合系统能够连接互联网的情况。

依然以tree为例

sudo apt-get install tree                         安装tree

sudo apt-get remove tree                       卸载tree

sudo apt-get update                                 更新软件

sudo apt-get upgrade        

 

将.**rpm**文件转为.**deb**文件

.rpm为RedHat使用的软件格式。在Ubuntu下不能直接使用，所以需要转换一下。

sudo alien abc.rpm

 

**vim使用**

vim三种模式：命令模式、插入模式、编辑模式。使用ESC或i或：来切换模式。

命令模式下：

:q                      退出

:q!                     强制退出

:wq                   保存并退出

:set number     显示行号

:set nonumber  隐藏行号

/apache            在文档中查找apache 按n跳到下一个，shift+n上一个

yyp                   复制光标所在行，并粘贴

h(左移一个字符←)、j(下一行↓)、k(上一行↑)、l(右移一个字符→)

 

**用户及用户组管理**

/etc/passwd    存储用户账号

/etc/group       存储组账号

/etc/shadow    存储用户账号的密码

/etc/gshadow  存储用户组账号的密码

useradd 用户名

userdel 用户名

adduser 用户名

groupadd 组名

groupdel 组名

passwd root     给root设置密码

su root

su - root 

/etc/profile     系统环境变量

bash_profile     用户环境变量

.bashrc              用户环境变量

su user              切换用户，加载配置文件.bashrc

su - user            切换用户，加载配置文件/etc/profile ，加载bash_profile

**更改文件的用户及用户组**

sudo chown [-R] owner[:group] {File|Directory}

例如：还以jdk-7u21-linux-i586.tar.gz为例。属于用户hadoop，组hadoop

要想切换此文件所属的用户及组。可以使用命令。

sudo chown root:root jdk-7u21-linux-i586.tar.gz

 

**文件权限管理**

三种基本权限

R           读         数值表示为4

W          写         数值表示为2

X           可执行  数值表示为1

![img](https://images0.cnblogs.com/blog/352072/201402/091549405142313.png)

如图所示，jdk-7u21-linux-i586.tar.gz文件的权限为-rw-rw-r--

-rw-rw-r--一共十个字符，分成四段。

第一个字符“-”表示普通文件；这个位置还可能会出现“l”链接；“d”表示目录

第二三四个字符“rw-”表示当前所属用户的权限。   所以用数值表示为4+2=6

第五六七个字符“rw-”表示当前所属组的权限。      所以用数值表示为4+2=6

第八九十个字符“r--”表示其他用户权限。              所以用数值表示为2

所以操作此文件的权限用数值表示为662 

**更改权限**

sudo chmod [u所属用户  g所属组  o其他用户  a所有用户]  [+增加权限  -减少权限]  [r  w  x]   目录名 

例如：有一个文件filename，权限为“-rw-r----x” ,将权限值改为"-rwxrw-r-x"，用数值表示为765

sudo chmod u+x g+w o+r  filename

上面的例子可以用数值表示

sudo chmod 765 filename



# 设计模式

## 1. 了解哪些设计模式

- 单例模式：单例模式主要解决一个全局使用的类频繁的创建和销毁的问题。单例模式下可以确保某一个类只有一个实例，而且自行实例化并向整个系统提供这个实例。单例模式有三个要素：一是某个类只能有一个实例；二是它必须自行创建这个实例；三是它必须自行向整个系统提供这个实例。
- 工厂模式：工厂模式主要解决接口选择的问题。该模式下定义一个创建对象的接口，让其子类自己决定实例化哪一个工厂类，使其创建过程延迟到子类进行。
- 观察者模式：定义对象间的一种一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都得到通知并被自动更新。
- 装饰器模式：对已经存在的某些类进行装饰，以此来扩展一些功能，从而动态的为一个对象增加新的功能。装饰器模式是一种用于代替继承的技术，无需通过继承增加子类就能扩展对象的新功能。使用对象的关联关系代替继承关系，更加灵活，同时避免类型体系的快速膨胀。

## 2. 单例模式

**定义：**单例模式(Singleton Pattern，也称为单件模式)，使用最广泛的设计模式之一。其意图是保证一个类仅有一个实例，并提供一个访问它的全局访问点，该实例被所有程序模块共享。

**如何定义一个单例类：**

1. 私有化它的构造函数，以防止外界创建单例类的对象；
2. 使用类的私有静态指针变量指向类的唯一实例；
3. 使用一个公有的静态方法获取该实例。

**单例模式的应用场景：**

- Windows 是多进程多线程的，在操作一个文件的时候，就不可避免地出现多个进程或线程同时操作一个文件的现象，所以所有文件的处理必须通过唯一的实例来进行。 
- 一些设备管理器常常设计为单例模式，比如一个电脑有两台打印机，在输出的时候就要处理不能两台打
  印机打印同一个文件。 

> ```C++
> 
> #include <string>
> #include <iostream>
>  
> using namespace std;
>  
> class HelloWorld
> {
> 	public:
> 		static HelloWorld *GetInstance();
> 		static void Dispose();
> 		~HelloWorld();
> 		void Init(string &s);
> 		void Print();
> 	private:
> 		static HelloWorld *m_pInstance;
> 		HelloWorld();
> 		string m_str;
> };
>  
> HelloWorld::~HelloWorld()
> {
>  
> }
>  
> HelloWorld::HelloWorld()
> {
>  
> }
>  
> void HelloWorld::Print()
> {
> 	cout << m_str << endl;
> }
>  
> void HelloWorld::Init(string &s)
> {
> 	m_str = s;
> }
>  
> HelloWorld *HelloWorld::m_pInstance = NULL;
>  
> HelloWorld *HelloWorld::GetInstance()
> {
> 	if(m_pInstance)
> 	{
> 		return m_pInstance;
> 	}
> 	else
> 	{
> 		m_pInstance = new HelloWorld();
> 		return m_pInstance;
> 	}
> }
>  
> void HelloWorld::Dispose()
> {
> 	if(m_pInstance)
> 	{
> 		delete m_pInstance;
> 	}
> }
>  
> int main()
> {
> 	HelloWorld::GetInstance()->Init(*(new string("hello, world")));
> 	HelloWorld::GetInstance()->Print();
> 	HelloWorld::Dispose();
> 
> ```
>
> 

## 3. 观察者模式





# Redis

> 1. [Redis是什么？看这一篇就够了](https://www.cnblogs.com/powertoolsteam/p/redis.html)









# 场景题

> 1. [海量数据的处理问题](https://blog.csdn.net/v_JULY_v/article/details/6279498)

## 1.面对一个服务器集群，如何到达某一个服务实例中

## 2. 请问海量数据如何去取最大的k个

- 快排的变形：首先选择一个划分元，将比这个划分元大的元素放到它的前面，比划分元小的元素放到它的后面，此时完成了一趟排序。如果此时这个划分元的序号index刚好等于K，那么这个划分元以及它左边的数，刚好就是前K个最大的元素；如果index  > K，那么前K大的数据在index的左边，那么就继续递归的从index-1个数中进行一趟排序；如果index < K，那么再从划分元的右边继续进行排序，直到找到序号index刚好等于K为止。再将前K个数进行排序后，返回Top K个元素。这种方法就避免了对除了Top K个元素以外的数据进行排序所带来的不必要的开销。
- 使用最小堆
- **分治算法：** 将全部数据分成N份，前提是每份的数据都可以读到内存中进行处理，找到每份数据中最大的K个数。此时剩下N\*K个数据，如果内存不能容纳N\*K个数据，则再继续分治处理，分成M份，找出每份数据中最大的K个数，如果M\*K个数仍然不能读到内存中，则继续分治处理。直到剩余的数可以读入内存中，那么可以对这些数使用快速排序的变形或者归并排序进行处理。
- Hash法：如果这些数据中有很多重复的数据，可以先通过hash法，把重复的数去掉。这样如果重复率很高的话，会减少很大的内存用量，从而缩小运算空间。处理后的数据如果能够读入内存，则可以直接排序；否则可以使用分治法或者最小堆法来处理数据。

## 3.如何设计一个秒杀系统

**回答一： **

设计思路：将请求拦截在系统上游，降低下游压力。在一个并发量大，实际需求小的系统中，应当尽量在前端拦截无效流量，降低下游服务器和数据库的压力，不然很可能造成数据库读写锁冲突，甚至导致死锁，最终请求超时。

限流：前端直接限流，允许少部分流量流向后端。

削峰：瞬时大流量峰值容易压垮系统，解决这个问题是重中之重。常用的消峰方法有异步处理、缓存和消息中间件等技术。

异步处理：秒杀系统是一个高并发系统，采用异步处理模式可以极大地提高系统并发量，其实异步处理就是削峰的一种实现方式。

内存缓存：秒杀系统最大的瓶颈一般都是数据库读写，由于数据库读写属于磁盘IO，性能很低，如果能够把部分数据或业务逻辑转移到内存缓存，效率会有极大地提升。

消息队列：消息队列可以削峰，将拦截大量并发请求，这也是一个异步处理过程，后台业务根据自己的处理能力，从消息队列中主动的拉取请求消息进行业务处理。



**回答二：**

Redis是一个分布式缓存系统，支持多种数据结构，我们可以利用Redis轻松实现一个强大的秒杀系统。

我们可以采用Redis 最简单的`key-value`数据结构，用一个原子类型的变量值(`AtomicInteger`)作为key，把用户id作为value，库存数量便是原子变量的最大值。对于每个用户的秒杀，我们使用 `RPUSH key value`插入秒杀请求， 当插入的秒杀请求数达到上限时，停止所有后续插入。

然后我们可以在台启动多个工作线程，使用 `LPOP key` 读取秒杀成功者的用户id，然后再操作数据库做最终的下订单减库存操作。