

> 1. [操作系统常见面试题](https://www.cnblogs.com/inception6-lxc/p/9073983.html)
> 2. [常见操作系统面试题]([https://blog.csdn.net/qq_39207948/article/details/80677811?ops_request_misc=%7B%22request_id%22:%22158338765919726867828830%22,%22scm%22:%2220140713.130056874..%22%7D&request_id=158338765919726867828830&biz_id=0&utm_source=distribute.pc_search_result.none-task](https://blog.csdn.net/qq_39207948/article/details/80677811?ops_request_misc={"request_id":"158338765919726867828830","scm":"20140713.130056874.."}&request_id=158338765919726867828830&biz_id=0&utm_source=distribute.pc_search_result.none-task))

## 1. 线程、进程、协程

> 1.同步和互斥的概念：
>
> **同步就是两个线程是有先后关系的，例如B必须在A之后执行，A未完成的情况下，B就不可以执行。**
> **互斥就是A和B无论先后，但是需要满足一点就是A执行的时候B不可以执行，B执行的时候A不可以执行**



### **1.1 概念**：

> **进程**是**具有独立功能程序在某个数据集合上的一次执行过程**。**线程**是**进程内的一个执行实体或执行单元**。

- **进程**是具有独立功能程序在某个数据集合上的一次执行过程。
  - 各个进程之间相互独立，实现了操作系统的并发。
- **线程**是进程内的一个执行实体或执行单元。
  - 线程是操作系统可识别的最小执行和调度单位。每个线程都独自占用一个虚拟处理器：独自的寄存器组，指令计数器和处理器状态。每个线程完成不同的任务，但是共享同一地址空间（也就是同样的动态内存，映射文件，目标代码等等），打开的文件队列和其他内核资源。
  - 线程之间是相互影响的，一个线程的崩溃可能导致其所在进程的崩溃，进而导致该进程下所有线程的崩溃。

### **1.2 线程和进程区别**

- 一个线程只能属于一个进程，而一个进程可以有多个线程，但至少有一个线程。线程依赖于进程而存在。
- 进程在执行过程中拥有独立的内存单元，而多个线程共享进程的内存。（资源分配给进程，同一进程的所有线程共享该进程的所有资源。同一进程中的多个线程共享代码段（代码和常量），数据段（全局变量和静态变量），扩展段（堆存储）。但是每个线程拥有自己的栈段，栈段又叫运行时段，用来存放所有局部变量和临时变量。）
- 进程是资源分配的最小单位，线程是CPU调度的最小单位；
- **系统开销：** 
  - 由于在**创建或撤消进程时**，系统都要为之分配或回收资源。因此，操作系统所付出的开销将显著地大于在创建或撤消线程时的开销。
  - 类似地，在**进行进程切换时**，涉及到整个当前进程CPU环境的保存以及新被调度运行的进程的CPU环境的设置。
  - 而线程切换只须保存和设置少量寄存器的内容，并不涉及存储器管理方面的操作。
  - 因此进程切换的开销也远大于线程切换的开销。
- **通信**：由于同一进程中的多个线程具有相同的地址空间，致使它们之间的同步和通信的实现，也变得比较容易。进程间通信IPC，线程间可以直接读写进程数据段（如全局变量）来进行通信——需要进程同步和互斥手段的辅助，以保证数据的一致性。在有的系统中，线程的切换、同步和通信都无须操作系统内核的干预
- 进程编程调试简单可靠性高，但是创建销毁开销大；线程正相反，开销小，切换速度快，但是编程调试相对复杂。
- 进程间不会相互影响 ；一个线程挂掉可能将导致整个进程挂掉
- 进程适应于多核、多机分布；线程适用于多核

### **1.3 进程间通信的方式**

**<font color=blue>进程间通信主要包括管道、系统IPC（包括消息队列、信号量、信号、共享内存等）、以及套接字socket</font>**。

#### 1.3.1 <font color=blue>管道</font>

管道是一种半双工的通信方式，数据只能单向流动。

- **匿名管道**：只能父子进程之间通信
- **有名管道** (namedpipe) ： 有名管道也是半双工的通信方式，但是它允许无亲缘关系进程间的通信。
- **缺点**：效率比较低，不适合进程间频繁地交换数据。

#### 1.3.2 <font color=blue>信号量</font>

信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。<font color=red>信号量既可以实现进程间的互斥，也可以实现进程间的同步</font>.

信号量表示资源的数量，控制信号量的方式有两种原子操作：

- 一个是 **P 操作**，这个操作会把信号量减去 -1，相减后如果信号量 < 0，则表明资源已被占用，进程需阻塞等待；相减后如果信号量 >= 0，则表明还有资源可使用，进程可正常继续执行。
- 另一个是 **V 操作**，这个操作会把信号量加上 1，相加后如果信号量 <= 0，则表明当前有阻塞中的进程，于是会将该进程唤醒运行；相加后如果信号量 > 0，则表明当前没有阻塞中的进程；

P 操作是用在进入共享资源之前，V 操作是用在离开共享资源之后，这两个操作是必须成对出现的。

![img](https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZckxn1SzJ697nE1m1wJzmPQ5UocfiaqAGx3FLcc1c0u29F6vL79KiaERHUibna0Fw6OvoI7sO72IKF8Q/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

具体的过程如下：

- 进程 A 在访问共享内存前，先执行了 P 操作，由于信号量的初始值为 1，故在进程 A 执行 P 操作后信号量变为 0，表示共享资源可用，于是进程 A 就可以访问共享内存。
- 若此时，进程 B 也想访问共享内存，执行了 P 操作，结果信号量变为了 -1，这就意味着临界资源已被占用，因此进程 B 被阻塞。
- 直到进程 A 访问完共享内存，才会执行 V 操作，使得信号量恢复为 0，接着就会唤醒阻塞中的线程 B，使得进程 B 可以访问共享内存，最后完成共享内存的访问后，执行 V 操作，使信号量恢复到初始值 1。

可以发现，信号初始化为 `1`，就代表着是**互斥信号量**，它可以保证共享内存在任何时刻只有一个进程在访问，这就很好的保护了共享内存。

另外，在多进程里，每个进程并不一定是顺序执行的，它们基本是以各自独立的、不可预知的速度向前推进，但有时候我们又希望多个进程能密切合作，以实现一个共同的任务。

例如，进程 A 是负责生产数据，而进程 B 是负责读取数据，这两个进程是相互合作、相互依赖的，进程 A 必须先生产了数据，进程 B 才能读取到数据，所以执行是有前后顺序的。

那么这时候，就可以用信号量来实现多进程同步的方式，我们可以初始化信号量为 `0`。

![img](https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZckxn1SzJ697nE1m1wJzmPQlO6zu8K0xlLpDBbew0jVibibhVm59TQy4ibJSZKxqKsWOrcLIibZE6RAVg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

具体过程：

- 如果进程 B 比进程 A 先执行了，那么执行到 P 操作时，由于信号量初始值为 0，故信号量会变为 -1，表示进程 A 还没生产数据，于是进程 B 就阻塞等待；
- 接着，当进程 A 生产完数据后，执行了 V 操作，就会使得信号量变为 0，于是就会唤醒阻塞在 P 操作的进程 B；
- 最后，进程 B 被唤醒后，意味着进程 A 已经生产了数据，于是进程 B 就可以正常读取数据了。

可以发现，信号初始化为 `0`，就代表着是**同步信号量**，它可以保证进程 A 应在进程 B 之前执行。

#### 1.3.3 <font color=blue>消息队列</font> 

消息队列是由消息的链表，存放在内核中并由消息队列标识符标识。

- 优点：消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。
- 缺点：一是通信不及时，二是附件也有大小限制。因此消息队列不适合大数据的传输，并且消息队列也存在用户态和内核态拷贝的开销。

#### 1.3.4 信号 

信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。**Linux下的kill命令的实现机制就是信号。**

#### 1.3.5 <font color=blue>共享内存</font>

共享内存的机制，就是拿出一块虚拟地址空间来，映射到相同的物理内存中。这样这个进程写入的东西，另外一个进程马上就能看到了，都不需要拷贝来拷贝去，传来传去，大大提高了进程间通信的速度。

![img](https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZckxn1SzJ697nE1m1wJzmPQicu3anA4icCr5sY8I4CWsXBUSsGQQGlWuWgNSNJThhyNrpaourrwITQQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

- 缺点：如果多个进程同时修改同一个共享内存，很有可能就冲突了



#### 1.3.6 套接字(socket ) 

套解口也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同及其间的进程通信。

![img](https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZckxn1SzJ697nE1m1wJzmPQOIIKS58Z9r7rE99UGdDF2fHVwxY76wNCVCGVgm4Z395UibkacZTUJPw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

### **1.4 线程间通信的方式:**

- <font color=blue>临界区</font>：通过多线程的串行化来访问公共资源或一段代码，速度快，适合控制数据访问；
- <font color=blue>互斥量Synchronized/Lock(**也称为互斥锁**)</font>：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问
- <font color=blue>信号量 Semphare</font>：为控制具有有限数量的用户资源而设计的，它允许多个线程在同一时刻去访问同一个资源，但一般需要限制同一时刻访问此资源的最大线程数目。
- <font color=blue>事件(信号)，Wait/Notify</font>：通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操作

#### 1.4.1 多线程间锁机制和种类

同步的时候用一个互斥量，在访问共享资源前对互斥量进行加锁，在访问完成后释放互斥量上的锁。对
互斥量进行加锁以后，任何其他试图再次对互斥量加锁的线程将会被阻塞直到当前线程释放该互斥锁。
如果释放互斥锁时有多个线程阻塞，所有在该互斥锁上的阻塞线程都会变成可运行状态，第一个变为运
行状态的线程可以对互斥量加锁，其他线程将会看到互斥锁依然被锁住，只能回去再次等待它重新变为
可用。在这种方式下，每次只有一个线程可以向前执行。 

**Linux的4种锁机制：**

- 互斥锁：mutex，用于保证在任何时刻，都只能有一个线程访问该对象。当获取锁操作失败时，线程会
  进入睡眠，等待锁释放时被唤醒
- 读写锁：rwlock，分为读锁和写锁。处于读操作时，可以允许多个线程同时获得读操作。但是同一时刻
  只能有一个线程可以获得写锁。其它获取写锁失败的线程都会进入睡眠状态，直到写锁释放时被唤醒。
  注意：写锁会阻塞其它读写锁。当有一个线程获得写锁在写时，读锁也不能被其它线程获取；写者优先
  于读者（一旦有写者，则后续读者必须等待，唤醒时优先考虑写者）。适用于读取数据的频率远远大于
  写数据的频率的场合。
- 自旋锁：spinlock，在任何时刻同样只能有一个线程访问对象。但是当获取锁操作失败时，不会进入睡
  眠，而是会在原地自旋，直到锁被释放。这样节省了线程从睡眠状态到被唤醒期间的消耗，在加锁时间
  短暂的环境下会极大的提高效率。但如果加锁时间过长，则会非常浪费CPU资源。
- RCU：即read-copy-update，在修改数据时，首先需要读取数据，然后生成一个副本，对副本进行修
  改。修改完成后，再将老数据update成新的数据。使用RCU时，读者几乎不需要同步开销，既不需要获
  得锁，也不使用原子指令，不会导致锁竞争，因此就不用考虑死锁问题了。而对于写者的同步开销较
  大，它需要复制被修改的数据，还必须使用锁机制同步并行其它写者的修改操作。在有大量读操作，少
  量写操作的情况下效率非常高。 

#### 1.4.2 互斥机制以及互斥锁和读写锁的区别

- 互斥锁：mutex，用于保证在任何时刻，都只能有一个线程访问该对象。当获取锁操作失败时，线程会
  进入睡眠，等待锁释放时被唤醒 。

- 读写锁：rwlock， 分为读锁和写锁。处于读操作时，可以允许多个线程同时获得读操作。但是同一时刻
  只能有一个线程可以获得写锁。其它获取写锁失败的线程都会进入睡眠状态，直到写锁释放时被唤醒。
  注意：写锁会阻塞其它读写锁。当有一个线程获得写锁在写时，读锁也不能被其它线程获取；写者优先
  于读者（一旦有写者，则后续读者必须等待，唤醒时优先考虑写者）。适用于读取数据的频率远远大于
  写数据的频率的场合。

- 互斥锁和读写锁的**区别：**
  1）读写锁区分读者和写者，而互斥锁不区分
  2）互斥锁同一时间只允许一个线程访问该对象，无论读写；读写锁同一时间内只允许一个写者，但是
  允许多个读者同时读对象。 

  

### **1.5 有了进程为什么还要有线程**

**线程产生的原因：**

- 进程可以使多个程序能并发执行，以提高资源的利用率和系统的吞吐量；但是其具有一些缺点：
  1）进程在同一时间只能干一件事
  2）进程在执行的过程中如果阻塞，整个进程就会挂起，即使进程中有些工作不依赖于等待的资源，仍然不会执行。
  因此，操作系统引入了比进程粒度更小的线程，作为并发执行的基本单位，从而减少程序在并发执行时所付出的时空开销，提高并发性。

**和进程相比，线程的优势如下：**

- 从资源上来讲，线程是一种非常"节俭"的多任务操作方式。在linux系统下，启动一个新的进程必须分配给它独立的地址空间，建立众多的数据表来维护它的代码段、堆栈段和数据段，这是一种"昂贵"的多任务工作方式。
- 从切换效率上来讲，运行于一个进程中的多个线程，它们之间使用相同的地址空间，而且线程间彼此切换所需时间也远远小于进程间切换所需要的时间。
- 从通信机制上来讲，线程间方便的通信机制。对不同进程来说，它们具有独立的数据空间，要进行数据的传递只能通过进程间通信的方式进行，这种方式不仅费时，而且很不方便。线程则不然，由于同一进城下的线程之间贡献数据空间，所以一个线程的数据可以直接为其他线程所用，这不仅快捷，而且方便。
- 除以上优点外，多线程程序作为一种多任务、并发的工作方式，还有如下优点：
  1）使多CPU系统更加有效。操作系统会保证当线程数不大于CPU数目时，不同的线程运行于不同的CPU上
  2）改善程序结构。一个既长又复杂的进程可以考虑分为多个线程，成为几个独立或半独立的运行部分，这样的程序才会利于理解和修改。

> 引入进程和线程的目的是什么?
>
> 进程引入的目的：进程引入的目的是为了提高系统的资源利用率和增加系统的吞吐量。
>
> 线程引入的目的：线程引入是为了在进程的基础上节省系统的时空开销，进一步提高操作系统的并发性。
>
> 进程与线程的比较：
>
> 1. 进程是操作系统进行资源调度和独立运行的基本单位，引入线程之后，进程只是操作系统资源调度的基本单位，线程成为独立运行的基本单位。
> 2. 多个线程共享同一进程的所有资源，表现在同一进程的所有线程都具有相同的地址空间。
> 3. 创建或撤销进程时所付出的开销明显大于线程创建或撤销时所付出的时空开销。
> 4. 对于多处理机系统，对于进程而言，不管有多少处理机，该进程只能运行在一个处理机上，而对于多线程进程，可以将一个进程中的多个线程非配多个处理机上，是它们并行的执行。

### **1.6 多线程一定比多进程高效吗？**

- 不一定，因为线程间的切换也是有开销的

### **1.7 多线程和多进程各自的优点**

**多进程：**

- 由于不同的进程地址空间相互独立，所以有比较高的安全性。也具有更高的容错性
- 具有更好的多核可伸缩性，因为进程将地址空间，页表等进行了隔离，在多核的系统上可伸缩性更强

**多线程：**

- 更加高效的内存共享。多进程下内存共享不便
- 较轻的上下文切换。因为不用切换地址空间，CR3寄存器和清空TLB

### **1.8 如何让提升多线程的效率**

- 尽量使用池化技术，也就是线程池，从而不用频繁的创建，销毁线程
- 减少线程之间的同步和通信
- 通过Huge Page的方式避免产生大量的缺页异常
- 避免需要频繁共享写的数据

### 1.9 上下文切换

**什么是上下文切换呢,上下文切换时需要履行的步骤：**

1. 将前一个 CPU 的上下文（也就是 CPU 寄存器和程序计数器里边的内容）保存起来；
2. 然后加载新任务的上下文到寄存器和程序计数器；
3. 最后跳转到程序计数器所指的新位置，运行新任务。

被保存起来的上下文会存储到**系统内核**中，等待任务重新调度执行时再次加载进来。CPU 的上下文切换分三种：**进程上下文切换、线程上下文切换、中断上下文切换**。

#### 1.9.1 **进程的上下文切换**

> <font color=blue>进程切换需要分两步：</font>
>
> 1. 切换页目录、刷新TLB以使用新的地址空间；
> 2. 切换内核栈和硬件上下文（寄存器）

1. **进程上下文切换只发生在内核态中**

2. **进程的上下文切换不仅包含了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的资源。**

3. **进程上下文切换发生的场景**

   CPU时间片耗尽、资源不足、通过sleep主动挂起、优先级更高的进程进来要优先运行此进程、发生硬件中断

#### **1.9.2 线程的上下文切换**

> <font color=blue>线程在切换的过程中需要保存当前线程Id、线程状态、堆栈、寄存器状态等信息</font>

- 当属于不同的进程发生上下文切换的时候和进程之间的上下文切换相同
- 当相同进程的中的线程进行切换时，共享的资源保持不变，但是私有的数据和寄存器等不共享的数据要进行切换

### 1.10 协程

#### 1.10.1 协程的概念

协程看上去也是子程序，但执行过程中，在子程序内部可中断，然后转而执行别的子程序，在适当的时候再返回来接着执行。

#### 1.10.2 协程的优点

- 协程执行效率极高。因为子程序切换不是线程切换，而是由程序自身控制，因此，没有线程切换的开销，和多线程比，线程数量越多，协程的性能优势就越明显。

- 第二大优势就是不需要多线程的锁机制，因为只有一个线程，也不存在同时写变量冲突，在协程中控制共享资源不加锁，只需要判断状态就好了，所以执行效率比多线程高很多。

#### 1.10.3 如何使用多核CPU

在协程上利用多核CPU呢——多进程+协程，既充分利用多核，又充分发挥协程的高效率，可获得极高的性能。

## 2. 进程调度算法

> <font color=red> 先来先服务、最短作业优先、时间片轮转调度、优先级调度、多级队列</font>

**1、先来先服务**
先来先服务(FCFS)调度算法是一种最简单的调度算法，该算法既可用于作业调度，也可用于进程调度。当在作业调度中采用该算法时，每次调度都是从后备作业队列中选择一个或多个最先进入该队列的作业，将它们调入内存，为它们分配资源、创建进程，然后放入就绪队列。在进程调度中采用FCFS算法时，则每次调度是从就绪队列中选择一个最先进入该队列的进程，为之分配处理机，使之投入运行。该进程一直运行到完成或发生某事件而阻塞后才放弃处理机。

 

**2、最短作业(进程)优先**
短作业(进程)优先调度算法，是指对短作业或短进程优先调度的算法。它们可以分别用于作业调度和进程调度。短作业优先(SJF)的调度算法是从后备队列中选择一个或若干个估计运行时间最短的作业，将它们调入内存运行。而短进程优先(SPF)调度算法则是从就绪队列中选出一个估计运行时间最短的进程，将处理机分配给它，使它立即执行并一直执行到完成，或发生某事件而被阻塞放弃处理机时再重新调度。

 

**3、时间片轮转调度**
在早期的时间片轮转法中，系统将所有的就绪进程按先来先服务的原则排成一个队列，每次调度时，把CPU分配给队首进程，并令其执行一个时间片。时间片的大小从几ms到几百ms。当执行的时间片用完时，由一个计时器发出时钟中断请求，调度程序便据此信号来停止该进程的执行，并将它送往就绪队列的末尾；然后，再把处理机分配给就绪队列中新的队首进程，同时也让它执行一个时间片。这样就可以保证就绪队列中的所有进程在一给定的时间内均能获得一时间片的处理机执行时间。换言之，系统能在给定的时间内响应所有用户的请求。

**4、优先级调度**

**5、多级队列**
前面介绍的各种用作进程调度的算法都有一定的局限性。如短进程优先的调度算法，仅照顾了短进程而忽略了长进程，而且如果并未指明进程的长度，则短进程优先和基于进程长度的抢占式调度算法都将无法使用。而多级反馈队列调度算法则不必事先知道各种进程所需的执行时间，而且还可以满足各种类型进程的需要，因而它是目前被公认的一种较好的进程调度算法。在采用多级反馈队列调度算法的系统中，调度算法的实施过程如下所述：

1）应设置多个就绪队列，并为各个队列赋予不同的优先级。第一个队列的优先级最高，第二个队列次之，其余各队列的优先权逐个降低。该算法赋予各个队列中进程执行时间片的大小也各不相同，在优先权愈高的队列中，为每个进程所规定的执行时间片就愈小。例如，第二个队列的时间片要比第一个队列的时间片长一倍，第i+1个队列的时间片要比第i个队列的时间片长一倍。

2）当一个新进程进入内存后，首先将它放入第一队列的末尾，按FCFS原则排队等待调度。当轮到该进程执行时，如它能在该时间片内完成，便可准备撤离系统；如果它在一个时间片结束时尚未完成，调度程序便将该进程转入第二队列的末尾，再同样地按FCFS原则等待调度执行；如果它在第二队列中运行一个时间片后仍未完成，再依次将它放入第三队列，……，如此下去，当一个长作业(进程)从第一队列依次降到第n队列后，在第n队列便采取按时间片轮转的方式运行。

3）仅当第一队列空闲时，调度程序才调度第二队列中的进程运行；仅当第1～(i-1)队列均空时，才会调度第i队列中的进程运行。如果处理机正在第i队列中为某进程服务时，又有新进程进入优先权较高的队列(第1～(i-1)中的任何一个队列)，则此时新进程将抢占正在运行进程的处理机，即第i队列中某个正在运行的进程的时间片用完后，由调度程序选择优先权较高的队列中的那一个进程，把处理机分配给它。

 

**6、优先权调度算法**
为了照顾紧迫型作业，使之在进入系统后便获得优先处理，引入了最高优先权优先(FPF)调度算法。此算法常被用于批处理系统中，作为作业调度算法，也作为多种操作系统中的进程调度算法，还可用于实时系统中。当把该算法用于作业调度时，系统将从后备队列中选择若干个优先权最高的作业装入内存。当用于进程调度时，该算法是把处理机分配给就绪队列中优先权最高的进程，这时，又可进一步把该算法分成如下两种。

1) 非抢占式优先权算法

在这种方式下，系统一旦把处理机分配给就绪队列中优先权最高的进程后，该进程便一直执行下去，直至完成；或因发生某事件使该进程放弃处理机时，系统方可再将处理机重新分配给另一优先权最高的进程。这种调度算法主要用于批处理系统中；也可用于某些对实时性要求不严的实时系统中。

2) 抢占式优先权调度算法

在这种方式下，系统同样是把处理机分配给优先权最高的进程，使之执行。但在其执行期间，只要又出现了另一个其优先权更高的进程，进程调度程序就立即停止当前进程(原优先权最高的进程)的执行，重新将处理机分配给新到的优先权最高的进程。因此，在采用这种调度算法时，是每当系统中出现一个新的就绪进程i时，就将其优先权Pi与正在执行的进程j的优先权Pj进行比较。如果Pi≤Pj，原进程Pj便继续执行；但如果是Pi>Pj，则立即停止Pj的执行，做进程切换，使i进程投入执行。显然，这种抢占式的优先权调度算法能更好地满足紧迫作业的要求，故而常用于要求比较严格的实时系统中，以及对性能要求较高的批处理和分时系统中。

## 3. 并发和并行

**并发（concurrency）**：指宏观上看起来两个程序在同时运行，比如说在单核cpu上的多任务。但是从微观上看两个程序的指令是交织着运行的，你的指令之间穿插着我的指令，我的指令之间穿插着你的，在单个周期内只运行了一个指令。这种并发并不能提高计算机的性能，只能提高效率。

**并行（parallelism）**：指严格物理意义上的同时运行，比如多核cpu，两个程序分别运行在两个核上，两者之间互不影响，单个周期内每个程序都运行了自己的指令，也就是运行了两条指令。这样说来并行的确提高了计算机的效率。所以现在的cpu都是往多核方面发展。

## 4. 缺页中断

malloc()和mmap()等内存分配函数，在分配时只是建立了进程虚拟地址空间，并没有分配虚拟内存对应的物理内存。当进程访问这些没有建立映射关系的虚拟内存时，处理器自动触发一个缺页异常。

缺页中断：**在请求分页系统中，可以通过查询页表中的状态位来确定所要访问的页面是否存在于内存中。每当所要访问的页面不在内存时，会产生一次缺页中断，此时操作系统会根据页表中的外存地址在外存中找到所缺的一页，将其调入内存。**

缺页本身是一种中断，与一般的中断一样，需要经过4个处理步骤：

1、保护CPU现场

2、分析中断原因

3、转入缺页中断处理程序进行处理

4、恢复CPU现场，继续执行

但是缺页中断是由于所要访问的页面不存在于内存时，由硬件所产生的一种特殊的中断，因此，与一般的中断存在区别：

1、在指令执行期间产生和处理缺页中断信号

2、一条指令在执行期间，可能产生多次缺页中断

3、缺页中断返回是，执行产生中断的一条指令，而一般的中断返回是，执行下一条指令。



## 5. 缺页置换算法

当访问一个内存中不存在的页，并且内存已满，则需要从内存中调出一个页或将数据送至磁盘对换区，替换一个页，这种现象叫做缺页置换。当前操作系统最常采用的缺页置换算法如下：

**最佳置换算法：**只具有理论意义的算法，用来评价其他页面置换算法。置换策略是将当前页面中在未来最长时间内不会被访问的页置换出去。

**先进先出置换算法：**简单粗暴的一种置换算法，没有考虑页面访问频率信息。每次淘汰最早调入的页面。

**最近最久未使用算法LRU：**算法赋予每个页面一个访问字段，用来记录上次页面被访问到现在所经历的时间t，每次置换的时候把t值最大的页面置换出去(实现方面可以采用寄存器或者栈的方式实现)。

**时钟算法clock(也被称为是最近未使用算法NRU)：**页面设置一个访问位，并将页面链接为一个环形队列，页面被访问的时候访问位设置为1。页面置换的时候，如果当前指针所指页面访问为为0，那么置换，否则将其置为0，循环直到遇到一个访问为位0的页面。

**改进型Clock算法：**在Clock算法的基础上添加一个修改位，替换时根究访问位和修改位综合判断。优先替换访问位和修改位都是0的页面，其次是访问位为0修改位为1的页面。

**最少使用算法LFU：**设置寄存器记录页面被访问次数，每次置换的时候置换当前访问次数最少的。

## 6. fork()和vfork()的区别

1. fork( )的子进程拷贝父进程的数据段和代码段；vfork( )的子进程与父进程共享数据段
2. fork( )的父子进程的执行次序不确定；vfork( )保证子进程先运行，在调用exec或exit之前与父进程数据是共享的，在它调用exec或exit之后父进程才可能被调度运行。如果在调用这两个函数之前子进程依赖于父进程的进一步动作，则会导致死锁。
3. 当需要改变共享数据段中变量的值，则拷贝父进程。



## 7. 生产者-消费者问题

**1. 利用信号量解决生产者和消费者问题**

```C++
// 单生产者-单消费者问题
#define N 100;
int count = 0;

void producer(void){
    int item;
    while(true){
        item = produce_item();
        if(count==N) sleep();
        insert(item);
        count++;
        if(count==1) wakeup(consumer);
    }
}

void consumer(void){
    int item;
    while(true){
        if(count==0) sleep();
        item = remove_item();
        count--;
        if(count==N-1) wakeup(producer);
        consume_item(item);
    }
}
```

**2. 利用信号量解决生产者-消费者问题**

> 信号量的pv操作

## 8. 一个总结

> https://juejin.im/entry/6844903478859431943

### 1. 操作系统的四个特性

并发、共享、虚拟、异步

### 2. OS的主要功能

- 处理机管理：
- 存储器管理
- 设备管理
- 文件管理
- 提供用户接口

### 3. 进程的状态和转换

**就绪态、运行态、阻塞态**

- 就绪态到运行态(进程调度)
- 阻塞态到就绪态（某个事件已经发生）
- 运行态到就绪态（时间片用完）
- 运行态到阻塞态（等待某个事件发生）

### 4. 进程与线程的区别

**进程**：进程是进程实体的运行过程，是系统进行资源分配和调度的基本单位；引入进程为了使得多个程序可以并发的执行，以提高系统的资源利用率和吞吐量。

**线程**：是比进程更小的可独立运行的基本单位，是CPU调度的基本单位；引入的目的是为了减少程序在并发执行过程中的开销，使得OS并发效率更高。

**两者对比**

- 进程是资源分配和调度的基本单位，线程是CPU调度的基本单位
- 一个线程只能属于一个进程，但是一个进程可以有多个进程。各个进程之间是独立的，但是一个进程中的线程之间可能是相互影响的。
- 进程是基本的资源拥有单位，线程只拥有很少的基本的资源，但是线程可以访问所隶属的进程的资源（进程的代码段，数据段和所拥有的系统资源）
- 系统开销：创建或撤销进程的时候，系统要为之创建或者回收PCB，系统资源等，切换时也需要保存和回复CPU环境。而线程的切换只需要保存和恢复少量的寄存器，不涉及存储器管理方面的工作，所以开销比较小。
- 通信的方式：由于同一个进程中的线程共享地址空间，所以通信同步等变得比较简单。

### 5. 进程间通信的方式

> 同步和通信是一会事吗?

socket、管道、信号量、信号、消息队列、共享内存

信号量机制和信号机制傻傻分不清：

**5.1 Linux信号（signal) 机制** 

signal，又简称为信号（软中断信号）用来通知进程发生了异步事件。

**原理：**

​     一个进程收到一个信号与处理器收到一个中断请求可以说是一样的。信号是进程间通信机制中唯一的异步通信机制，一个进程不必通过任何操作来等待信号的到达，事实上，进程也不知道信号到底什么时候到达。进程之间可以互相通过系统调用kill发送软中断信号。内核也可以因为内部事件而给进程发送信号，通知进程发生了某个事件。信号机制除了基本通知功能外，还可以传递附加信息。

**分类：**

从两个不同的分类角度对信号进行：

可靠性方面：可靠信号与不可靠信号；

与时间的关系上：实时信号与非实时信号。

**5.2 Linux信号量（semaphore）机制**

**Linux内核的信号量用来操作系统进程间同步访问共享资源。**

 **原理：**信号量在创建时需要设置一个初始值，表示同时可以有几个任务可以访问该信号量保护的共享资源，初始值为1就变成互斥锁（Mutex），即同时只能有一个任务可以访问信号量保护的共享资源。

一个任务要想访问共享资源，首先必须得到信号量，获取信号量的操作将把信号量的值减1，若当前信号量的值为负数，表明无法获得信号量，该任务必须挂起在该信号量的等待队列等待该信号量可用；若当前信号量的值为非负数，表示可以获得信号量，因而可以立刻访问被该信号量保护的共享资源。

当任务访问完被信号量保护的共享资源后，必须释放信号量，释放信号量通过把信号量的值加1实现，如果信号量的值为非正数，表明有任务等待当前信号量，因此它也唤醒所有等待该信号量的任务。

### 6. 线程间通信的方式

- 信号量
- 互斥量
- 临界区
- 事件

### 7. 用户态和内核态

**内核态：**cpu可以访问内存的所有数据，包括外围设备，例如硬盘，网卡，cpu也可以将自己从一个程序切换到另一个程序。

**用户态：**只能受限的访问内存，且不允许访问外围设备，占用cpu的能力被剥夺，cpu资源可以被其他程序获取。

> 为什么要有用户态和内核态？
>
> 解释一：
>
> 由于需要限制不同的程序之间的访问能力, 防止他们获取别的程序的内存数据, 或者获取外围设备的数据, 并发送到网络, CPU划分出两个权限等级 -- 用户态和内核态。
>
> 解释二：
>
> 由于用户可能会对操作系统内核进行错误的修改导致系统的崩溃，因此限定了用户的访问权限，因此也就把操作系统分为了用户态和内核态。用户态的访问权限是受限的，但是内核态的访问权限是不受限的。



**用户态切换到内核态的方式如下：**

- **系统调用**：程序的执行一般是在用户态下执行的，但当程序需要使用操作系统提供的服务时，比如说打开某一设备、创建文件、读写文件（这些均属于系统调用）等，就需要向操作系统发出调用服务的请求，这就是系统调用。
- **异常**：当CPU在执行运行在用户态下的程序时，发生了某些事先不可知的异常，这时会触发由当前运行进程切换到处理此异常的内核相关程序中，也就转到了内核态，比如缺页异常。
- **外围设备的中断：**当外围设备完成用户请求的操作后，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条即将要执行的指令转而去执行与中断信号对应的处理程序，如果先前执行的指令是用户态下的程序，那么这个转换的过程自然也就发生了由用户态到内核态的切换。比如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后续操作等。

### 8.死锁

死锁是指多个进程在运行过程中，因为争夺资源而造成的一种僵局，如果没有外力推动，处于僵局中的进程就无法继续执行。

![img](https://mmbiz.qpic.cn/mmbiz_png/NdsdouZwicaeY0fdOUxrwTABu5sAN6O6uBAoxiaZ9EWWlpXLWKoMX2kiaODoEu4uJwJBMg4fy7YVzYfYeYzzVVcug/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

> 线程 1 已经成功拿到了**互斥量 1** ，正在申请**互斥量 2** ，而同时在另一个  CPU   上，线程 2 已经拿到了互**斥量 2** ，正在申请**互斥量 1** 。彼此占有对方正在申请的互斥量，结局就是谁也没办法拿到想要的互斥量，于是死锁就发生了。



**死锁的原因：**

- 资源竞争
- 进程推进的顺序非法

**死锁产生的必要条件**：

- 不可剥条件:进程对于已经申请到的资源在使用完成之前不可以被剥夺
- 互斥条件:进程对所分配的资源进行排他性的使用
- 请求和保持条件:进程被阻塞的时候并不释放锁申请到的资源
- 环路等待条件:发生死锁的时候存在的一个 进程-资源 环形等待链



**死锁处理：**

1. 预防死锁：破坏产生死锁的4个必要条件中的一个或者多个；实现起来比较简单，但是如果限制过于严格会降低系统资源利用率以及吞吐量

   - **破坏互斥**

   > 通过与锁完全不同的同步方式CAS，CAS提供原子性支持，实现各种无锁的数据结构，不仅可以避免互斥锁带来的开销也可避免死锁问题。

   - **破坏不可剥夺**

   > 如果一个线程已经获取到了一些锁，那么在这个线程释放锁之前这些锁是不会被强制剥夺的。但是为了防止死锁的发生，我们可以选择让线程在获取后续的锁失败时主动放弃自己已经持有的锁并在之后重试整个任务，这样其他等待这些锁的线程就可以继续执行了。

   - **破坏环路等待**

   > 在实践的过程中，采用破坏环路等待的方式非常常见，这种技术叫做"锁排序"。很好理解，我们假设现在有个数组A，采用单向访问的方式(从前往后)，依次访问并加锁，这样一来，线程只会向前单向等待锁释放，自然也就无法形成一个环路了。

2. 避免死锁：在资源的动态分配中，防止系统进入不安全状态(可能产生死锁的状态)-如银行家算法

   - **银行家算法**

     当进程首次申请资源时，要测试该进程对资源的**最大需求量**，如果系统现存的资源可以满足它的最大需求量则按当前的申请量分配资源，否则就推迟分配。

     当进程在执行中继续申请资源时，先测试该进程已占用的资源数与本次申请资源数之和是否超过了该进程对资源的最大需求量。若超过则拒绝分配资源。若没超过则再测试系统现存的资源能否满足该进程尚需的最大资源量，若满足则按当前的申请量分配资源，否则也要推迟分配。

   - **安全序列**

     是指系统能按某种进程推进顺序（P1, P2, P3, …, Pn），为每个进程 Pi 分配其所需要的资源，直至满足每个进程对资源的最大需求，使每个进程都可以顺序地完成。这种推进顺序就叫安全序列【银行家算法的核心就是找到一个安全序列】。

   - **系统安全状态**

     如果系统能找到一个安全序列，就称系统处于安全状态，否则，就称系统处于不安全状态。

3. 检测死锁：允许系统运行过程中产生死锁，在死锁发生之后，采用一定的算法进行检测，并确定与死锁相关的资源和进程，采取相关方法清除检测到的死锁。实现难度大

4. 解除死锁：与死锁检测配合，将系统从死锁中解脱出来（撤销进程或者剥夺资源）。对检测到的和死锁相关的进程以及资源，通过撤销或者挂起的方式，释放一些资源并将其分配给处于阻塞状态的进程，使其转变为就绪态。

   - 资源剥夺：挂起某些死锁进程，并抢占它的资源，将这些资源分配给其他死锁进程（但应该防止被挂起的进程长时间得不到资源）；
   - 撤销进程：强制撤销部分、甚至全部死锁进程并剥夺这些进程的资源（撤销的原则可以按进程优先级和撤销进程代价的高低进行）；
   - 进程回退：让一个或多个进程回退到足以避免死锁的地步。进程回退时自愿释放资源而不是被剥夺。要求系统保持进程的历史信息，设置还原点。

### 9. 进程调度算法

- 先来先服务
- 短作业优先
- 时间片轮转
- 优先级调度
- 多级队列

### 10. 内存连续分配

主要是指几种动态分区分配时所采用的几种算法。

动态分区分配又称为可变分区分配，是一种动态划分内存的分区方法。这种分区方法不预先将内存划分，而是在进程装入内存时，根据进程的大小动态地建立分区，并使分区的大小正好适合进程的需要。因此系统中分区的大小和数目是可变的

- 首次适应
- 最佳适应算法
- 最坏适应算法

### 11. 分页存储管理方式

把主存空间划分为大小相等且固定的块，块相对较小，作为主存的基本单位。每个进程也以块为单位进行划分，进程在执行时，以块为单位逐个申请主存中的块空间。

因为程序数据存储在不同的页面中，而页面又离散的分布在内存中，**因此需要一个页表来记录逻辑地址和实际存储地址之间的映射关系，以实现从页号到物理块号的映射。**

由于页表也是存储在内存中的，因此和不适用分页管理的存储方式相比，访问分页系统中内存数据需要**两次的内存访问**(一次是从内存中访问页表，从中找到指定的物理块号，加上页内偏移得到实际物理地址；第二次就是根据第一次得到的物理地址访问内存取出数据)。

![img](https://user-gold-cdn.xitu.io/2017/5/22/c453381c57fa4d0804b2c7dd35c55099?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)



为了减少两次访问内存导致的效率影响，分页管理中引入了**快表机制**，包含快表机制的内存管理中，当要访问内存数据的时候，首先将页号在快表中查询，如果查找到说明要访问的页表项在快表中，那么直接从快表中读取相应的物理块号；如果没有找到，那么访问内存中的页表，从页表中得到物理地址，同时将页表中的该映射表项添加到快表中(可能存在快表换出算法)。

此外，由于逻辑地址可能非常大，会占用较大的连续内存空间，因此又引入了两级页表和多级页表的方法。

### 12. 分段存储管理方式

**分段分页方式的比较**

页是信息的物理单位，是出于系统内存利用率的角度提出的离散分配机制；段是信息的逻辑单位，每个段含有一组意义完整的信息，是出于用户角度提出的内存管理机制

页的大小是固定的，由系统决定；段的大小是不确定的，由用户决定



### 13. 虚拟内存

**虚拟内存**的提出主要是为了解决一个程序，所需内存空间超过了计算机可以提供的实际内存而无法运行的情况

基于局部性原理，**在程序装入时，可以将程序的一部分装入内存，而将其余部分留在外存**，就可以启动程序执行。在程序执行过程中，**当所访问的信息不在内存时，由操作系统将所需要的部分调入内存,然后继续执行程序**。另一方面，操作系统将内存中**暂时不使用的内容换出到外存上，从而腾出空间存放将要调入内存的信息**。这样，系统好像为用户提供了一个比实际内存大得多的存储器，称为虚拟存储器。



### 14. 页面置换算法

**最佳置换算法：**只具有理论意义的算法，用来评价其他页面置换算法。置换策略是将当前页面中在未来最长时间内不会被访问的页置换出去。

**先进先出置换算法：**简单粗暴的一种置换算法，没有考虑页面访问频率信息。每次淘汰最早调入的页面。

**最近最久未使用算法LRU：**算法赋予每个页面一个访问字段，用来记录上次页面被访问到现在所经历的时间t，每次置换的时候把t值最大的页面置换出去(实现方面可以采用寄存器或者栈的方式实现)。

**时钟算法clock(也被称为是最近未使用算法NRU)：**页面设置一个访问位，并将页面链接为一个环形队列，页面被访问的时候访问位设置为1。页面置换的时候，如果当前指针所指页面访问为为0，那么置换，否则将其置为0，循环直到遇到一个访问为位0的页面。

**改进型Clock算法：**在Clock算法的基础上添加一个修改位，替换时根究访问位和修改位综合判断。优先替换访问位和修改位都是0的页面，其次是访问位为0修改位为1的页面。

**最少使用算法LFU：**设置寄存器记录页面被访问次数，每次置换的时候置换当前访问次数最少的。



## 9. select poll epoll的区别

<font color=red>**区别：**</font>

他们三者都是利用一个线程监控多个socket链接，当有数据到达时，对包含数据的socket进行进一步的处理。poll和epoll相当于对select的一个改进。

select是使用轮询的方式检测是否有数据到达，主要存在三个缺陷：

- select支持的文件描述符数量太小了，默认是1024。
- 每次调用select，都需要把文件描述符集合从用户态拷贝到内核态
- 通过遍历得知哪一个文件描述符已经就绪，开销比较大

poll针对select的第一个缺点进行改进，不再使用bitmap来存储fd集合，而是使用链表，这就消除了1024的限制，但是后面的操作是一样的。

epoll对poll又做出了进一步的改进，他的fd集合是共享与用户态和内核态的，并且他不再需要使用轮询的方式去检测是否哪个fd就绪，而是采用回调函数的形式来确定就绪的文件描述符。

<font color=red>**epoll两种工作模式（LT和ET）的区别：**</font>

**LT(level triggered)是缺省的工作方式**，并且同时支持block（阻塞）和no-block（非阻塞） socket。在这种做法中，内核告诉你一个文件描述符是否就绪了，然后你可以对这个就绪的fd进行I/O操作。如果你不作任何操作，内核还是会继续通知你的，所以，这种模式编程出错误可能性要小一点。传统的select/poll都是这种模型的代表．

**ET(edge-triggered)是高速工作方式**，只支持no-block（非阻塞） socket。在这种模式下，当描述符从未就绪变为就绪时，内核通过epoll告诉你。然后它会假设你知道文件描述符已经就绪，并且不会再为那个文件描述符发送更多的就绪通知，直到你做了某些操作导致那个文件描述符不再为就绪状态了。但是请注意，如果一直不对这个fd作IO操作(从而导致它再次变成未就绪)，内核不会发送更多的通知 (only once）。



<font color=red>**select和epoll如何选择**</font>

如果任务不是很多，但是绝大多数的文件描述符都比较活跃，这个时候使用select的效果就是比epoll好。epoll适用于连接数量多，但是活跃链接比较少的情况。

<font color=red>**select的优点**</font>

- 跨平台性和兼容性
- 当文件描述符大部分都比较活跃时，select的性能优于epoll

<font color=red>**epoll的原理**</font>

调用顺序：

int epoll_create(int size);
int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event);
int epoll_wait(int epfd, struct epoll_event *events,int maxevents, int timeout);

首先创建一个epoll对象，然后使用epoll_ctl对这个对象进行操作，把需要监控的描述添加进去，这些描述如将会以epoll_event结构体的形式组成一颗红黑树，接着阻塞在epoll_wait，进入大循环，当某个fd上有事件发生时，内核将会把其对应的结构体放入到一个链表中，返回有事件发生的链表。



## 10. 堆和栈的区别

1、内存分配方面：

​    堆：一般由程序员分配释放， 若程序员不释放，程序结束时可能由OS回收 。注意它与数据结构中的堆是两回事，分配方式是类似于链表。可能用到的关键字如下：new、malloc、delete、free等等。

​    栈：由编译器(Compiler)自动分配释放，存放函数的参数值，局部变量的值等。其操作方式类似于数据结构中的栈。

2、申请方式方面：

​    堆：需要程序员自己申请，并指明大小。在c中malloc函数如p1 = (char *)malloc(10)；在C++中用new运算符，但是注意p1、p2本身是在栈中的。因为他们还是可以认为是局部变量。

​    栈：由系统自动分配。 例如，声明在函数中一个局部变量 int b；系统自动在栈中为b开辟空间。

3、系统响应方面：

​    堆：操作系统有一个记录空闲内存地址的链表，当系统收到程序的申请时，会遍历该链表，寻找第一个空间大于所申请空间的堆结点，然后将该结点从空闲结点链表中删除，并将该结点的空间分配给程序，另外，对于大多数系统，会在这块内存空间中的首地址处记录本次分配的大小，这样代码中的delete语句才能正确的释放本内存空间。另外由于找到的堆结点的大小不一定正好等于申请的大小，系统会自动的将多余的那部分重新放入空闲链表中。

​    栈：只要栈的剩余空间大于所申请空间，系统将为程序提供内存，否则将报异常提示栈溢出。

4、大小限制方面：

​    堆：是向高地址扩展的数据结构，是不连续的内存区域。这是由于系统是用链表来存储的空闲内存地址的，自然是不连续的，而链表的遍历方向是由低地址向高地址。堆的大小受限于计算机系统中有效的虚拟内存。由此可见，堆获得的空间比较灵活，也比较大。

​    栈：在Windows下, 栈是向低地址扩展的数据结构，是一块连续的内存的区域。这句话的意思是栈顶的地址和栈的最大容量是系统预先规定好的，在WINDOWS下，栈的大小是固定的（是一个编译时就确定的常数），如果申请的空间超过栈的剩余空间时，将提示overflow。因此，能从栈获得的空间较小。

5、效率方面：

​    堆：是由new分配的内存，一般速度比较慢，而且容易产生内存碎片，不过用起来最方便，另外，在WINDOWS下，最好的方式是用VirtualAlloc分配内存，他不是在堆，也不是在栈是直接在进程的地址空间中保留一快内存，虽然用起来最不方便。但是速度快，也最灵活。

​    栈：由系统自动分配，速度较快。但程序员是无法控制的。

6、存放内容方面：

​    堆：一般是在堆的头部用一个字节存放堆的大小。堆中的具体内容有程序员安排。

​    栈：在函数调用时第一个进栈的是主函数中后的下一条指令（函数调用语句的下一条可执行语句）的地址然后是函数的各个参数，在大多数的C编译器中，参数是由右往左入栈，然后是函数中的局部变量。 注意: 静态变量是不入栈的。当本次函数调用结束后，局部变量先出栈，然后是参数，最后栈顶指针指向最开始存的地址，也就是主函数中的下一条指令，程序由该点继续运行。

7、存取效率方面：

​    堆：char *s1 = "Hellow Word"；是在编译时就确定的；

​    栈：char s1[] = "Hellow Word"； 是在运行时赋值的；用数组比用指针速度要快一些，因为指针在底层汇编中需要用edx寄存器中转一下，而数组在栈上直接读取。

## 11. 操作系统的缺页中断





## 12. 多线程锁机制和种类

同步的时候用一个互斥量，在访问共享资源前对互斥量进行加锁，在访问完成后释放互斥量上的锁。对
互斥量进行加锁以后，任何其他试图再次对互斥量加锁的线程将会被阻塞直到当前线程释放该互斥锁。
如果释放互斥锁时有多个线程阻塞，所有在该互斥锁上的阻塞线程都会变成可运行状态，第一个变为运
行状态的线程可以对互斥量加锁，其他线程将会看到互斥锁依然被锁住，只能回去再次等待它重新变为
可用。在这种方式下，每次只有一个线程可以向前执行。 

**Linux的4种锁机制：**

- 互斥锁：mutex，用于保证在任何时刻，都只能有一个线程访问该对象。当获取锁操作失败时，线程会
  进入睡眠，等待锁释放时被唤醒
- 读写锁：rwlock，分为读锁和写锁。处于读操作时，可以允许多个线程同时获得读操作。但是同一时刻
  只能有一个线程可以获得写锁。其它获取写锁失败的线程都会进入睡眠状态，直到写锁释放时被唤醒。
  注意：写锁会阻塞其它读写锁。当有一个线程获得写锁在写时，读锁也不能被其它线程获取；写者优先
  于读者（一旦有写者，则后续读者必须等待，唤醒时优先考虑写者）。适用于读取数据的频率远远大于
  写数据的频率的场合。
- 自旋锁：spinlock，在任何时刻同样只能有一个线程访问对象。但是当获取锁操作失败时，不会进入睡
  眠，而是会在原地自旋，直到锁被释放。这样节省了线程从睡眠状态到被唤醒期间的消耗，在加锁时间
  短暂的环境下会极大的提高效率。但如果加锁时间过长，则会非常浪费CPU资源。
- RCU：即read-copy-update，在修改数据时，首先需要读取数据，然后生成一个副本，对副本进行修
  改。修改完成后，再将老数据update成新的数据。使用RCU时，读者几乎不需要同步开销，既不需要获
  得锁，也不使用原子指令，不会导致锁竞争，因此就不用考虑死锁问题了。而对于写者的同步开销较
  大，它需要复制被修改的数据，还必须使用锁机制同步并行其它写者的修改操作。在有大量读操作，少
  量写操作的情况下效率非常高。 



## 13. 互斥机制以及互斥锁和读写锁的区别

- 互斥锁：mutex，用于保证在任何时刻，都只能有一个线程访问该对象。当获取锁操作失败时，线程会
  进入睡眠，等待锁释放时被唤醒 。

- 读写锁：rwlock， 分为读锁和写锁。处于读操作时，可以允许多个线程同时获得读操作。但是同一时刻
  只能有一个线程可以获得写锁。其它获取写锁失败的线程都会进入睡眠状态，直到写锁释放时被唤醒。
  注意：写锁会阻塞其它读写锁。当有一个线程获得写锁在写时，读锁也不能被其它线程获取；写者优先
  于读者（一旦有写者，则后续读者必须等待，唤醒时优先考虑写者）。适用于读取数据的频率远远大于
  写数据的频率的场合。

- 互斥锁和读写锁的**区别：**
  1）读写锁区分读者和写者，而互斥锁不区分
  2）互斥锁同一时间只允许一个线程访问该对象，无论读写；读写锁同一时间内只允许一个写者，但是
  允许多个读者同时读对象。 

  

## 14. 基于多进程服务器和基于多线程服务器的优缺点

**多进程服务器优点**

1. 由操作系统进行调度，运行比较稳定强壮

2. 能够方便地通过操作系统进行监控和管理

   例如对每个进程的内存变化状况,甚至某个进程处理什么web请求进行监控.同时可以通过给进程发送信号量,实现对应用的各种管理

3. 隔离性好

   一个进程出现问题只有杀掉它重启就可以,不影响整体服务的可用性。

4. 充分利用多核cpu,实现并行处理

 

**多进程服务器的缺点:**

1. 内存消耗比较大,每个进程都独立加载完整的应用环境

2. cpu消耗偏高,高并发下,进程之间频繁进行上下文切换,需要大量的内存换页操作

3. 很低的io并发处理能力,只适合处理短请求,不适合处理长请求



**基于多线程服务器的优点:**

​    1. 对内存的消耗小

​       线程之间共享整个应用环境,每个线程栈都比较小,一般不到1M

​    2. cpu上下文切换比较快

​    3. io的并发能力强

​    4. 有效利用多核cpu进行并行计算

**基于多线程服务器的缺点:**

​    1. 不方便操作系统的管理

​    2. VM对内存的管理要求非常高,GC的策略会影响多线程并发能力和系统吞吐量

    3. 由于存在对共享资源操作,一旦出现线程"死锁"和线程阻塞,很容易使整个应用失去可用性

## 15. 如何保证线程安全

**15.1 线程安全是什么**

如果你的代码所在的进程中有多个线程在同时运行，而这些线程可能会同时运行这段代码。如果每次运行结果和[单线程](https://baike.baidu.com/item/单线程)运行的结果是一样的，而且其他的变量的值也和预期的是一样的，就是线程安全的。或者说:一个类或者程序所提供的接口对于线程来说是[原子操作](https://baike.baidu.com/item/原子操作)或者多个线程之间的切换不会导致该接口的执行结果存在二义性,也就是说我们不用考虑同步的问题。

线程安全问题都是由[全局变量](https://baike.baidu.com/item/全局变量)及[静态变量](https://baike.baidu.com/item/静态变量)引起的。

若每个线程中对全局变量、静态变量只有读操作，而无写操作，一般来说，这个全局变量是线程安全的；若有多个线程同时执行写操作，一般都需要考虑[线程同步](https://baike.baidu.com/item/线程同步)，否则的话就可能影响线程安全。



**15.2 如何保证线程安全**
 <font color=blue>一般说来，确保线程安全的方法有这几个：竞争与原子操作、同步与锁、可重入、过度优化。</font>

- **竞争与原子操作** 
  多个线程同时访问和修改一个数据，可能造成很严重的后果。出现严重后果的原因是很多操作作系统编译为汇编代码之后不止一条指令，因此在执行的时候可能执行了一半就被调度系统打断了而去执行别的代码了。一般将单指令的操作称为原子的(Atomic)，因为不管怎样，单条指令的执行是不会被打断的。因此，为了避免出现多线程操作数据的出现异常，Linux系统提供了一些常用操作的原子指令，确保了线程的安全。但是，它们只适用于比较简单的场合，在复杂的情况下就要选用其他的方法了。

- **同步与锁** 
  为了避免多个线程同时读写一个数据而产生不可预料的后果，开发人员要将各个线程对同一个数据的访问同步，也就是说，在一个线程访问数据未结束的时候，其他线程不得对同一个数据进行访问。同步的最常用的方法是使用锁(Lock)，它是一种非强制机制，每个线程在访问数据或资源之前首先试图获取锁，并在访问结束之后释放锁；在锁已经被占用的时候试图获取锁时，线程会等待，直到锁重新可用。二元信号量是最简单的一种锁，它只有两种状态：占用与非占用，它适合只能被唯一一个线程独占访问的资源。对于允许多个线程并发访问的资源，要使用多元信号量(简称信号量)。

- 可重入 
  一个函数被重入，表示这个函数没有执行完成，但由于外部因素或内部因素，又一次进入该函数执行。一个函数称为可重入的，表明该函数被重入之后不会产生任何不良后果。可重入是并发安全的强力保障，一个可重入的函数可以在多线程环境下放心使用。

- 过度优化 
  在很多情况下，即使我们合理地使用了锁，也不一定能够保证线程安全，因此，我们可能对代码进行过度的优化以确保线程安全。 我们可以使用volatile关键字试图阻止过度优化，它可以做两件事：第一，阻止编译器为了提高速度将一个变量缓存到寄存器而不写回；第二，阻止编译器调整操作volatile变量的指令顺序。在另一种情况下，CPU的乱序执行让多线程安全保障的努力变得很困难，通常的解决办法是调用CPU提供的一条常被称作barrier的指令，它会阻止CPU将该指令之前的指令交换到barrier之后，反之亦然。  

## 16. 为什么进程上下文切换比线程上下文切换代价高

进程切换分两步：

1.切换页目录以使用新的地址空间

2.切换内核栈和硬件上下文

对于linux来说，线程和进程的最大区别就在于地址空间，对于线程切换，第1步是不需要做的，第2是进程和线程切换都要做的。

切换的性能消耗：

1、线程上下文切换和进程上下问切换一个最主要的区别是线程的切换虚拟内存空间依然是相同的，但是进程切换是不同的。这两种上下文切换的处理都是通过操作系统内核来完成的。内核的这种切换过程伴随的最显著的性能损耗是将寄存器中的内容切换出。

2、另外一个隐藏的损耗是上下文的切换会扰乱处理器的缓存机制。简单的说，一旦去切换上下文，处理器中所有已经缓存的内存地址一瞬间都作废了。还有一个显著的区别是当你改变虚拟内存空间的时候，处理的页表缓冲（processor's Translation Lookaside Buffer (TLB)）或者相当的神马东西会被全部刷新，这将导致内存的访问在一段时间内相当的低效。但是在线程的切换中，不会出现这个问题。

 

## 17. 临界资源

- 在操作系统中，进程是占有资源的最小单位（线程可以访问其所在进程内的所有资源，但线程本身并不占有资源或仅仅占有一点必须资源）。但**对于某些资源来说，其在同一时间只能被一个进程所占用。这些一次只能被一个进程所占用的资源就是所谓的临界资源**。典型的临界资源比如物理上的打印机，或是存在硬盘或内存中被多个进程所共享的一些变量和数据等(如果这类资源不被看成临界资源加以保护，那么很有可能造成丢数据的问题)。
- **对于临界资源的访问，必须是互斥进行。**也就是当临界资源被占用时，另一个申请临界资源的进程会被阻塞，直到其所申请的临界资源被释放。**而进程内访问临界资源的代码被成为临界区。**

## 18. 内存池、进程池、线程池

首先介绍一个概念“池化技术 ”。池化技术就是：提前保存大量的资源，以备不时之需以及重复使用。池化技术应用广泛，如内存池，线程池，连接池等等。由于在实际应用当做，分配内存、创建进程、线程都会设计到一些系统调用，系统调用需要导致程序从用户态切换到内核态，是非常耗时的操作。因此，当程序中需要频繁的进行内存申请释放，进程、线程创建销毁等操作时，通常会使用内存池、进程池、线程池技术来提升程序的性能。

  　　**线程池**：线程池的原理很简单，类似于操作系统中的缓冲区的概念，它的流程如下：先启动若干数量的线程，并让这些线程都处于睡眠状态，当需要一个开辟一个线程去做具体的工作时，就会唤醒线程池中的某一个睡眠线程，让它去做具体工作，当工作完成后，线程又处于睡眠状态，而不是将线程销毁。

  　　**进程池**与线程池同理。

  　　**内存池**：内存池是指程序预先从操作系统申请一块足够大内存，此后，当程序中需要申请内存的时候，不是直接向操作系统申请，而是直接从内存池中获取；同理，当程序释放内存的时候，并不真正将内存返回给操作系统，而是返回内存池。当程序退出(或者特定时间)时，内存池才将之前申请的内存真正释放。

## 19. 中断和系统调用

**所谓的中断就是在计算机执行程序的过程中，由于出现了某些特殊事情，使得CPU暂停对程序的执行，转而去执行处理这一事件的程序。等这些特殊事情处理完之后再回去执行之前的程序。**中断一般分为三类：

- 由计算机硬件异常或故障引起的中断，称为**内部异常中断**；
- 由程序中执行了引起中断的指令而造成的中断，称为**软中断**（这也是和我们将要说明的系统调用相关的中断）；
- 由外部设备请求引起的中断，称为**外部中断**。简单来说，对中断的理解就是对一些特殊事情的处理。

与中断紧密相连的一个概念就是**中断处理程序**了。当中断发生的时候，系统需要去对中断进行处理，对这些中断的处理是由操作系统内核中的特定函数进行的，这些处理中断的特定的函数就是我们所说的中断处理程序了。

另一个与中断紧密相连的概念就是**中断的优先级**。中断的优先级说明的是当一个中断正在被处理的时候，处理器能接受的中断的级别。中断的优先级也表明了中断需要被处理的紧急程度。**每个中断都有一个对应的优先级，当处理器在处理某一中断的时候，只有比这个中断优先级高的中断可以被处理器接受并且被处理。**优先级比这个当前正在被处理的中断优先级要低的中断将会被忽略。

**典型的中断优先级如下所示：**

- **机器错误 > 时钟 > 磁盘 > 网络设备 > 终端 > 软件中断**

 

在讲系统调用之前，先说下**进程的执行在系统上的两个级别**：用户级和核心级，也称为**用户态和系统态(user mode and kernel mode)**。

​        **用户空间就是用户进程所在的内存区域**，相对的，**系统空间就是操作系统占据的内存区域**。用户进程和系统进程的所有数据都在内存中。**处于用户态的程序只能访问用户空间，而处于内核态的程序可以访问用户空间和内核空间。**



## 20. 同步、异步、阻塞、非阻塞

**同步**：当一个同步调用发出后，调用者要一直等待返回结果。通知后，才能进行后续的执行。

**异步**：当一个异步过程调用发出后，调用者不能立刻得到返回结果。实际处理这个调用的部件在完成后，通过状态、通知和回调来通知调用者。

**阻塞**：是指调用结果返回前，当前线程会被挂起，即阻塞。

**非阻塞**：是指即使调用结果没返回，也不会阻塞当前线程。

**形象比喻**：

- 小Q去钓鱼，抛完线后就傻傻的看着有没有动静，有则拉杆(同步阻塞)
- 小Q去钓鱼，拿鱼网捞一下，有没有鱼立即知道，不用等，直接就捞(同步非阻塞)
- 小Q去钓鱼，这个鱼缸比较牛皮，扔了后自己就打王者荣耀去了，因为鱼上钩了这个鱼缸带的报警器会通知我。这样实现异步(异步非阻塞）

## 21. 什么是缓冲区溢出

缓冲区溢出是指当计算机向缓冲区内填充数据时超过了缓冲区本身的容量，溢出的数据覆盖在合法数据上

## 22. 内部碎片和外部碎片

- **内部碎片**是已经被分配出去的的内存空间大于请求所需的内存空间。

- **外部碎片**是指还没有分配出去，但是由于大小太小而无法分配给申请空间的新进程的内存空间空闲块。

- 固定分区存在内部碎片，可变式分区分配会存在外部碎片；
- **页式虚拟存储**系统存在**内部碎片**；**段式虚拟存储**系统，存在**外部碎片**

## 23. 同步和互斥

​        当有多个线程的时候，经常需要去同步这些线程以访问同一个数据或资源。例如，假设有一个程序，其中一个线程用于把文件读到内存，而另一个线程用于统计文件中的字符数。当然，在把整个文件调入内存之前，统计它的计数是没有意义的。但是，由于每个操作都有自己的线程，操作系统会把两个线程当作是互不相干的任务分别执行，这样就可能在没有把整个文件装入内存时统计字数。为解决此问题，你必须使两个线程同步工作。

​      所谓**同步**，是指散步在不同进程之间的若干程序片断，它们的运行必须严格按照规定的某种先后次序来运行，这种先后次序依赖于要完成的特定的任务。如果**用对资源的访问来定义的话，同步是指在互斥的基础上（大多数情况），通过其它机制实现访问者对资源的有序访问。在大多数情况下，同步已经实现了互斥，特别是所有写入资源的情况必定是互斥的。少数情况是指可以允许多个访问者同时访问资源。**

​      所谓**互斥**，是指散布在不同进程之间的若干程序片断，当某个进程运行其中一个程序片段时，其它进程就不能运行它们之中的任一程序片段，只能等到该进程运行完这个程序片段后才可以运行。如果**用对资源的访问来定义的话，互斥某一资源同时只允许一个访问者对其进行访问，具有唯一性和排它性。但互斥无法限制访问者对资源的访问顺序，即访问是无序的。**

## 24. 同步和异步

**同步**：

- 同步的定义：是指一个进程在执行某个请求的时候，若该请求需要一段时间才能返回信息，那么，这个进程将会一直等待下去，直到收到返回信息才继续执行下去。
- 特点：

1. 同步是阻塞模式；
2. 同步是按顺序执行，执行完一个再执行下一个，需要等待，协调运行；

**异步：**

- 是指进程不需要一直等下去，而是继续执行下面的操作，不管其他进程的状态。当有消息返回时系统会通知进程进行处理，这样可以提高执行的效率。
- 特点：

1. 异步是非阻塞模式，无需等待；
2. 异步是彼此独立，在等待某事件的过程中，继续做自己的事，不需要等待这一事件完成后再工作。线程是异步实现的一个方式。

**同步与异步的优缺点：**

- 同步可以避免出现死锁，读脏数据的发生。一般共享某一资源的时候，如果每个人都有修改权限，同时修改一个文件，有可能使一个读取另一个人已经删除了内容，就会出错，同步就不会出错。但，同步需要等待资源访问结束，浪费时间，效率低。
- 异步可以提高效率，但，安全性较低。

## 25 守护进程、僵尸进程、孤儿进程

- **守护进程**：运行在后台的一种特殊进程，**独立于控制终端并周期性地执行某些任务**。
- **僵尸进程**：一个进程 fork 子进程，子进程退出，而父进程没有wait/waitpid子进程，那么**子进程的进程描述符仍保存在系统中**，这样的进程称为僵尸进程。僵尸进程是一个进程必然会经历的进程
- **孤儿进程**：一个**父进程退出，而它的一个或多个子进程还在运行**，这些子进程称为孤儿进程。（孤儿进程将由 init 进程收养并对它们完成状态收集工作）

## 26. 线程的独占资源和共享资源

**共享资源**

**1、进程申请的堆内存**
**2、进程打开的文件描述符**
**3、进程的全局数据(可用于线程之间通信)**
**4、进程ID、进程组ID**
**5、进程目录**
**6、信号处理器**

**独占资源**

**1、线程ID**
同一进程中每个线程拥有唯一的线程ID。
**2、寄存器组的值**
由于线程间是并发运行的，每个线程有自己不同的运行线索，当从一个线 程切换到另一个线程上 时，必须将原有的线程的寄存器集合的状态保存，以便将来该线程在被重新切换到时能得以恢复。
**3、线程堆栈**
线程可以进行函数调用，必然会使用大函数堆栈。
**4、错误返回码**
线程执行出错时，必须明确是哪个线程出现何种错误，因此不同的线程应该拥有自己的错误返回码变量。
**5、信号屏蔽码**
由于每个线程所感兴趣的信号不同，所以线程的信号屏蔽码应该由线程自己管理。但所有的线程都共享同样的信号处理器。
**6、线程的优先级**
由于线程需要像进程那样能够被调度，那么就必须要有可供调度使用的参数，这个参数就是线程的优先级。



## 27. 挂起和阻塞的区别

- **挂起**是一种主动行为，因此恢复也应该要主动完成，而**阻塞**则是一种被动行为，是在等待事件或资源时任务的表现，你不知道他什么时候被阻塞(pend)，也就不能确切 的知道他什么时候恢复阻塞。而且挂起队列在操作系统里可以看成一个，而阻塞队列则是不同的事件或资源（如信号量）就有自己的队列。
- 阻塞（pend）就是任务释放CPU，其他任务可以运行，一般在等待某种资源或信号量的时候出现。挂起（suspend）不释放CPU，如果任务优先级高就永远轮不到其他任务运行，一般挂起用于程序调试中的条件中断，当出现某个条件的情况下挂起，然后进行单步调试。

**挂起、阻塞、睡眠的区别**

首先这些术语都是对于线程来说的。对线程的控制就好比你控制了一个雇工为你干活。你对雇工的控制是通过编程来实现的。

​     **挂起线程**的意思就是你对主动对雇工说：“你睡觉去吧，用着你的时候我主动去叫你，然后接着干活”。

​     使**线程睡眠**的意思就是你主动对雇工说：“你睡觉去吧，某时某刻过来报到，然后接着干活”。

​     **线程阻塞**的意思就是，你突然发现，你的雇工不知道在什么时候没经过你允许，自己睡觉呢，但是你不能怪雇工，肯定你这个雇主没注意，本来你让雇工扫地，结果扫帚被偷了或被邻居家借去了，你又没让雇工继续干别的活，他就只好睡觉了。至于扫帚回来后，雇工会不会知道，会不会继续干活，你不用担心，雇工一旦发现扫帚回来了，他就会自己去干活的。因为雇工受过良好的培训。这个培训机构就是操作系统。



## 28. 进程和线程上下文切换

**28.1 进程**

> 进程上下文切换只发生在内核态中

**进程的上下文切换不仅包含了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的资源。**

**进程上下文切换发生的场景**

- CPU时间片耗尽
- 资源不足
- 通过sleep主动挂起
- 优先级更高的进程进来要优先运行此进程
- 发生硬件中断

**28.2 线程**

- 当属于不同的进程发生上下文切换的时候和进程之间的上下文切换相同
- 当相同进程的中的线程进行切换时，共享的资源保持不变，但是私有的数据和寄存器等不共享的数据要进行切换

## 29. 用户级/内核级线程

- **用户线程**是基于用户态的线程管理库来实现的，那么**线程控制块（Thread Control Block, TCB）** 也是在库里面来实现的，对于操作系统而言是看不到这个 TCB 的，它只能看到整个进程的 PCB。所以，**用户线程的整个线程管理和调度，操作系统是不直接参与的，而是由用户级线程库函数来完成线程的管理，包括线程的创建、终止、同步和调度等。**
- **内核线程是由操作系统管理的，线程对应的 TCB 自然是放在操作系统里的，这样线程的创建、终止和管理都是由操作系统负责。**

## 30. 内存管理

### **30.1** 虚拟地址和物理地址

- 虚拟地址：我们程序所使用的内存地址叫做**虚拟内存地址**
- 物理地址：实际存在硬件里面的空间地址叫**物理内存地址**

操作系统引入了虚拟内存，进程持有的虚拟地址会通过 CPU 芯片中的内存管理单元（MMU）的映射关系，来转换变成物理地址，然后再通过物理地址访问内存。



![img](https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZfVYxicDjAjl4nMxlmyJk7rkpVTcOZj4JJSyYlSMyiaC66pP2q1QiafglrtO0tmZHCkBB0RvCsfVOTIA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



### **30.2 交换技术**

- **概念**，使得该进程运行一段时间，然后把他存回磁盘。空闲进程主要存储在磁盘上，所以当他不运行的时候就不会占用内存。
- **缺点：**
  - 程序太大，无法装进内存，那么程序就无法运行
  - 由于数据段可能处于动态增长的状态，因此可能导致内存空间不够用，或者导致多个进程无法正常运行
  - 内存空间有可能产生极大的浪费

> 扩展知识：
>
> **空闲内存管理：位图和空闲区链表**
>
> 1. **位图**
>
> 2. **空闲区链表**

### **30.3 虚拟内存**

**虚拟内存**的提出主要是为了解决运行一个程序时所需内存空间超过了计算机可以提供的实际内存而无法运行的情况。基于局部性原理，**在程序装入时，可以将程序的一部分装入内存，而将其余部分留在外存**，就可以启动程序执行。在程序执行过程中，**当所访问的信息不在内存时，由操作系统将所需要的部分调入内存,然后继续执行程序**。另一方面，操作系统将内存中**暂时不使用的内容换出到外存上，从而腾出空间存放将要调入内存的信息**。这样，系统好像为用户提供了一个比实际内存大得多的存储器，称为虚拟存储器。



<font color=red>分页和分段的由来: 操作系统是如何管理虚拟地址与物理地址之间的关系？主要有两种方式，分别是**内存分段和内存分页**</font>



### **30.4 内存分段**

> 分段就是将一个程序分成代码段、数据段和堆栈段等

1. 程序是由若干个逻辑分段组成的，如**可由代码段、数据段、栈段、堆段**组成。**不同的段是有不同的属性的，所以就用分段（Segmentation）的形式把这些段分离出来。**



<font color=blue>分段机制下，虚拟地址和物理地址是如何映射的？</font>

2. 分段机制下的虚拟地址由两部分组成，**段选择子**和**段内偏移量**

   - **段选择子**就保存在段寄存器里面。段选择子里面最重要的是**段号**，用作段表的索引。**段表**里面保存的是这个**段的基地址、段的界限和特权等级**等。

   - 虚拟地址中的**段内偏移量**应该位于 0 和段界限之间，如果段内偏移量是合法的，就将段基地址加上段内偏移量得到物理内存地址。
   - ![img](https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZfVYxicDjAjl4nMxlmyJk7rkTX5icicl09hKPabMh2LHcfiapeTumDtOUB3fydDdsIGuNKI0uUWia4k5oA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



3. 内存分段的缺陷
   - 第一个就是**内存碎片**的问题。
   - 第二个就是**内存交换的效率低**的问题。



### 30.5 内存分页

>  为了解决内存分段的内存碎片和内存交换效率低的问题，就出现了**内存分页**。

1. 什么是分页？

   <font color=blue>**分页是把整个虚拟和物理内存空间切成一段段固定尺寸的大小**。这样一个连续并且尺寸固定的内存空间，我们叫**页**（*Page*）。</font>

2. 分页机制下虚拟地址是如何映射到物理地址的?

   在分页机制下，虚拟地址分为两部分，**页号**和**页内偏移**。页号作为页表的索引，**页表**包含物理页每页所在**物理内存的基地址**，这个基地址与页内偏移的组合就形成了物理内存地址，见下图。

   ![img](https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZfVYxicDjAjl4nMxlmyJk7rkib51qUwtaEsS3asnE6jbeEuibuvlFr72mTPbiaGEs2E4S9ktuGs0NYziaQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

#### 30.5.1 缺页中断

当访问的虚拟地址不在页表中时，系统会产生一个缺页异常，这时就引发了一个缺页中断，操作系统会在外存中找到所缺的一页，将其调入内存。



### 30.6 段页式内存管理

段页式内存管理实现的方式：

- 先将程序划分为多个有逻辑意义的段，也就是前面提到的分段机制；
- 接着再把每个段划分为多个页，也就是对分段划分出来的连续空间，再划分固定大小的页；

这样，地址结构就由**段号、段内页号和页内位移**三部分组成。用于段页式地址变换的数据结构是每一个程序一张段表，每个段又建立一张页表，段表中的地址是页表的起始地址，而页表中的地址则为某页的物理页号，

段页式地址变换中要得到物理地址须经过三次内存访问：

- 第一次访问段表，得到页表起始地址；
- 第二次访问页表，得到物理页号；
- 第三次将物理页号与页内位移组合，得到物理地址。

![img](https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZfVYxicDjAjl4nMxlmyJk7rkibwZfO6ibiaiaoRoiaCSu16NoWkpEVUVG0hHbBVJKdsveIL4J1446ZIc6vw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

### 30.7 位图

> 1.[位图实现，处理大数据](https://blog.csdn.net/wenqiang1208/article/details/76724338)

位图法就是bitmap的缩写。所谓bitmap，就是用每一位来存放某种状态，适用于大规模数据，但数据状态又不是很多的情况。通常是用来判断某个数据存不存在的。

例如，要判断一千万个人的状态，每个人只有两种状态：男人，女人，可以用0，1表示。那么就可以开一个int数组，一个int有32个位，就可以表示32个人。操作的时候可以使用位操作。



#### **30.7.1 位图应用**

**1、给定100亿个整数，设计算法找到只出现一次的整数 。**

解决方法

将100亿个数分拆成1000份文件，再将每份文件里使用位图，并用两位bit表示数字出现的次数，00存出现0次的数，01存放出现1次的数，10存放出现多次的数，11舍弃，再将1000份中出现一次的数全部合并到一个文件里存放即可。

**2、给两个文件，分别有100亿个整数，我们只有1G内存，如何找到两个文件交集**

解决方法

将第一个文件里的数用哈希映射到1000个文件中，将第二个文件用同样的哈希映射到另1000个文件中，然后比较每个哈希映射相同的文件即

**3、1个文件有100亿个int，1G内存，设计算法找到出现次数不超过2次的所有整数**

解决方法：其实和问题1是一样的

将100亿个数分拆成1000份文件，再将每份文件里使用位图，并用两位bit表示数字出现的次数，00存出现0次的数，01存放出现1次的数，10存放出现2次的数，11舍弃，再将1000份中出现次数不超过二的数全部合并到一个文件里存放即可

**4、给40亿个不重复的unsigned int的整数，没排过序的，然后再给一个数，如何快速判断这个数是否在那40亿个数当中**

可以考虑使用位图bitmap，1个bit存储一个数字，那么40亿数据需要40亿bit 大约就是500M内存。
1M=1024*1024 * 8bit 大概8千万

用一个bit位来表示这个数据是否存在，1表示存在，0表示不存在。

**5、使用位图法进行整形数组排序**

首先遍历数组，得到数组的最大最小值，然后根据这个最大最小值来缩小bitmap的范围。这里需要注意对于int的负数，都要转化为unsigned int来处理，而且取位的时候，数字要减去最小值。



## 31. 文件系统

## 32. 什么是抢占

进程切换有自愿(Voluntary)和强制(Involuntary)之分，简单来说，自愿切换意味着进程需要等待某种资源，强制切换则与抢占(Preemption)有关。

抢占(Preemption)是指内核强行切换正在CPU上运行的进程，在抢占的过程中并不需要得到进程的配合，在随后的某个时刻被抢占的进程还可以恢复运行。发生抢占的原因主要有：进程的时间片用完了，或者优先级更高的进程来争夺CPU了。

抢占的过程分两步，第一步触发抢占，第二步执行抢占，这两步中间不一定是连续的，有些特殊情况下甚至会间隔相当长的时间：

1. 触发抢占：给正在CPU上运行的当前进程设置一个请求重新调度的标志(TIF_NEED_RESCHED)，仅此而已，此时进程并没有切换。
2. 执行抢占：在随后的某个时刻，内核会检查TIF_NEED_RESCHED标志并调用schedule()执行抢占。

抢占只在某些特定的时机发生，这是内核的代码决定的。



## 33. 操作系统的中断是什么

中断是指CPU对系统发生的某个事件做出的一种反应，CPU暂停正在执行的程序，保存现场后自动去执行相应的处理程序，处理完该事件后再返回中断处继续执行原来的程序。中断一般三类，**一种是由CPU外部引起的**，如I/O中断、时钟中断，**一种是来自CPU内部事件或程序执行中引起的中断**，例如程序非法操作，地址越界、浮点溢出），**最后一种是在程序中使用了系统调用引起的**。而中断处理一般分为中断响应和中断处理两个步骤，中断响应由硬件实施，中断处理主要由软件实施。

## 34. 什么时候使用多线程或者单线程

对于**处理时间短的服务**或者**启动频率高**的要用单线程，相反用多线程！无论什么情况下单线程能达到要求就不用多线程



## 35. 单核CPU上实现多线程程序对否要考虑加锁

在单核机器上写多线程程序，仍然需要线程锁。因为线程锁通常用来实现线程的同步和通信。在单核机器上的多线程程序，仍然存在线程同步的问题。因为在抢占式操作系统中，通常为每个线程分配一个时间片，当某个线程时间片耗尽时，操作系统会将其挂起，然后运行另一个线程。如果这两个线程共享某些数据，不使用线程锁的前提下，可能会导致共享数据修改引起冲突。

## 36. 操作系统中程序的内存结构

- 程序的内存结构包括**BSS段、数据段、代码段、栈区、堆区**
- 一个程序本质上都是由**BSS段、数据段、代码段**三个组成的
- BSS段
  使用来存放未初始化的全局变量和静态变量的一块内存区域。BSS段属于一块静态分配，程序结束后静态变量资源由系统自动释放。
- 数据段
  用来存放已经初始化的全局变量。
- 代码区
  存放程序执行代码的一块内存区域。这一块区域是只读区域。
- 栈区
  由编译器自动释放，存放函数的参数值、局部变量等。
- 堆区
  用于动态分配内存。由程序员申请分配和释放

## 37. pthread.h（多线程实现）常用API

1、创建

int pthread_create( pthread_t *tid, const pthread_attr_t *attr, void *(* func) (void *), void *arg );

attr: 线程属性包括：优先级、初始栈大小，是否应该成为一个守护线程。

缺省设置，NULL

后面是线程要执行的函数和参数

成功返回 0

2、等待一个给定线程终止

int pthread_join( pthread_t tid, void **status);

statues返回等待线程的返回值

3、得到自身的pid

pthread_t pthread_self(void);

4、pthread_detach函数

int pthread_detach( pthread_t pid );

把指定的线程转变为脱离状态

一个线程或者是可汇合的（joinable，缺省值），或者是脱离的（detached）。当一个可汇合的线程终止时，它的线程ID和退出状态将留到另一个线程对它调用pthread_join。脱离线程却象守护进程：当它们终止的时，所有相关资源都被释放，我们不能等待它们终止。如果一个线程需要知道另一个线程什么时候终止，那就最好好吃第二个线程的可汇合状态。

本函数通常由想让自己脱离的线程调用，如下语句

pthread_detach( pthread_self() );

5、终止一个线程

void pthread_exit( void *statue );

指针sttus不能指向局部于调用对象，因为线程终止时这样的对象也消失